{
  "title": "CES 2026 Physical AI Trends & Insights",
  "summary": "An in-depth analysis of the 30 defining Physical AI products showcased at CES 2026, categorized by embodiment and interaction types.",
  "types": [
    {
      "id": "type1",
      "name": "01 / Anthropomorphic Humanoid",
      "description": "Full-scale agents prioritizing human-like interaction and workspace integration.",
      "count": "Total Products",
      "keyInsight": "Shift from 'Walking' to 'Working' â€” Focus on dexterous manipulation and safe co-presence.",
      "icon": "ğŸ¤–"
    },
    {
      "id": "type2",
      "name": "02 / Moveable Companion",
      "description": "Kinetic robots (wheeled/legged) focusing on service, delivery, and polite withdrawal.",
      "count": "Total Products",
      "keyInsight": "Hyper-mobility (stair climbing) and context-aware 'Service UX' that predicts needs.",
      "icon": "ğŸ¦®"
    },
    {
      "id": "type3",
      "name": "03 / TableTop AI Device",
      "description": "Stationary or micro-kinetic devices focusing on emotional resonance and synthetic intimacy.",
      "count": "Total Products",
      "keyInsight": "Minimizing physical movement to maximize emotional bandwidth and eye-contact.",
      "icon": "ğŸº"
    }
  ],
  "marketInsights": [
    {
      "title": "Presence & Legibility",
      "content": "Motion must be transparent and predictable to build trust. While dynamic movements from Atlas and CLOiD are impressive, they risk uncanny valley effects. Google DeepMind emphasizes 'transparent motions' as key to human-robot trust. The winning formula: kinetic politeness through turn-taking, yielding, and intentional withdrawal when not needed.",
      "highlight": "Kinetic Politeness Framework"
    },
    {
      "title": "Emotional Temperature & Bonding",
      "content": "Most affective cues remain superficial (LED blinks, basic dances). Pet-like expressions from Loona and Ollobot show promise, but lack mechanisms for long-term attachment. Scientific American warns that 'hallucination in motion is disastrous.' The opportunity: layered resonance using light for baseline mood temperature and micro-expressions for empathy peaks, creating always-on ambient presence that accumulates reliability over time.",
      "highlight": "Affectionate Intelligence"
    },
    {
      "title": "Ambient vs Intrusive Interaction",
      "content": "Companion robots are proliferating (Miroki, Jennie), but most remain task-centric without true 'always-on' presence. The concept of intentional withdrawalâ€”respectful non-interventionâ€”is virtually absent. Strategic differentiation lies in context-aware Stay/Act/Withdraw behaviors that provide uninterrupted states, respecting user rhythm while building affection through ambient awareness.",
      "highlight": "Non-Intrusive Presence"
    },
    {
      "title": "Context Continuity & Reliability",
      "content": "Mobility strengths (MobED, Ballie following) are undermined by weak emotional continuityâ€”robots feel 'cold' when tasks end. The gap: capturing in-between moments through world understanding, demonstrating growing reliability through subtle light and motion cues. This continuous presence, not episodic task completion, creates the trust over time that resonates with executives and users alike.",
      "highlight": "Trust Over Time"
    }
  ],
  "products": [
    {
      "id": "atlas-electric",
      "typeId": "type1",
      "manufacturer": "Boston Dynamics (Hyundai Motor Group)",
      "name": "Atlas (Next-Gen Electric)",
      "country": "USA / Korea",
      "overview": "Purpose: To push the boundaries of dynamic mobility, manipulation, and whole-body coordination in real-world environments; accelerate development toward practical humanoid robots for industrial tasks, logistics, and eventually consumer/home applications while serving as a research platform for embodied AI. At CES 2026, Boston Dynamics showcased the fully electric next-gen Atlas with dramatic live demonstrations including complex parkour sequences, heavy object manipulation (lifting and throwing large boxes), fluid whole-body motions (e.g., backflips, running, crawling under obstacles), and new AI-driven autonomy powered by reinforcement learning and multimodal models (integrated with Google DeepMind's Gemini and other foundation models). The electric design eliminates hydraulic systems for quieter, more efficient operation, wider range of motion, and lighter weight. Hyundai announced pilot deployments in its factories starting 2026â€“2027, with expanded commercial partnerships.\n\n[KR] ì œí’ˆì˜ ëª©ì : ì‹¤ì„¸ê³„ í™˜ê²½ì—ì„œì˜ ë™ì  ì´ë™ì„±, ì¡°ì‘, ì „ì‹  í˜‘ì‘ì˜ í•œê³„ë¥¼ í™•ì¥; ì‚°ì—… ì‘ì—…, ë¬¼ë¥˜, ê¶ê·¹ì ìœ¼ë¡œ ì†Œë¹„ì/ê°€ì • ì ìš©ì„ ìœ„í•œ ì‹¤ìš©ì  íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ ê°œë°œ ê°€ì†í™” ë° ì²´í™”ëœ AI ì—°êµ¬ í”Œë«í¼ ì—­í• . ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ Boston DynamicsëŠ” ì™„ì „ ì „ê¸° ì°¨ì„¸ëŒ€ Atlasë¥¼ ì„ ë³´ì´ë©° ë³µì¡í•œ íŒŒì¿ ë¥´ ì‹œí€€ìŠ¤, ë¬´ê±°ìš´ ë¬¼ì²´ ì¡°ì‘(í° ë°•ìŠ¤ ë“¤ê³  ë˜ì§€ê¸°), ìœ ì—°í•œ ì „ì‹  ëª¨ì…˜(ë°±í”Œë¦½, ë‹¬ë¦¬ê¸°, ì¥ì• ë¬¼ ì•„ë˜ ê¸°ì–´ê°€ê¸°), ê°•í™”í•™ìŠµ ë° ë©€í‹°ëª¨ë‹¬ ëª¨ë¸(Google DeepMind Gemini ë“± í†µí•©) ê¸°ë°˜ AI ììœ¨ì„±ì„ ë¼ì´ë¸Œ ì‹œì—°. ì „ê¸° ì„¤ê³„ë¡œ ìœ ì•• ì‹œìŠ¤í…œ ì œê±° â†’ ë” ì¡°ìš©í•˜ê³  íš¨ìœ¨ì ì´ë©° ê°€ë²¼ìš´ ë¬´ê²Œì™€ ë„“ì€ ìš´ë™ ë²”ìœ„ í™•ë³´. í˜„ëŒ€ìë™ì°¨ê·¸ë£¹ì€ 2026~2027ë…„ ê³µì¥ íŒŒì¼ëŸ¿ ë°°ì¹˜ë¥¼ ë°œí‘œí•˜ë©° ìƒì—… íŒŒíŠ¸ë„ˆì‹­ í™•ëŒ€. ë°ëª¨ëŠ” ì‚¬ì „ í”„ë¡œê·¸ë˜ë° ì—†ì´ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥ í™˜ê²½ì— ì‹¤ì‹œê°„ ì ì‘ ê°•ì¡°.",
      "analysis": {
        "intro": "Dynamic Mobility & Embodied AI\n[KR] ë™ì  ì´ë™ì„± ë° ì²´í™”ëœ AI",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "The electric Atlas represents a paradigm shift toward commercially viable, highly dynamic Physical AI â€” combining superhuman agility with machine learning for adaptive behavior in unstructured spaces. Its reinforcement-learning-trained whole-body control demonstrates 'embodied intelligence' where physical form and AI reasoning are deeply intertwined, enabling proactive navigation and manipulation that feels 'alive' rather than scripted. This reinforces the value of continuous physical presence and contextual adaptation in everyday environments.\n\n[KR] ì „ê¸° AtlasëŠ” ìƒì—…ì ìœ¼ë¡œ ì‹¤í˜„ ê°€ëŠ¥í•œ ê³ ë™ì  Physical AIì˜ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ â€” ì´ˆì¸ì  ë¯¼ì²©ì„±ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì„ ê²°í•©í•˜ì—¬ ë¹„êµ¬ì¡°í™” ê³µê°„ì—ì„œ ì ì‘ í–‰ë™ êµ¬í˜„. ê°•í™”í•™ìŠµ ê¸°ë°˜ ì „ì‹  ì œì–´ëŠ” ë¬¼ë¦¬ì  í˜•íƒœì™€ AI ì¶”ë¡ ì´ ê¹Šì´ ì–½íŒ 'ì²´í™”ëœ ì§€ëŠ¥'ì„ ë³´ì—¬ì£¼ë©°, ìŠ¤í¬ë¦½íŠ¸ê°€ ì•„ë‹Œ 'ì‚´ì•„ìˆëŠ”' ë“¯í•œ ì‚¬ì „ì  íƒìƒ‰ê³¼ ì¡°ì‘ ê°€ëŠ¥. ì¼ìƒ í™˜ê²½ì—ì„œì˜ ì§€ì†ì  ë¬¼ë¦¬ì  ì¡´ì¬ê°ê³¼ ë§¥ë½ ì ì‘ì˜ ê°€ì¹˜ë¥¼ ì¬í™•ì¸í•˜ë©° ì—°êµ¬ì‹¤ì—ì„œ ì‹¤ì„¸ê³„ ë°°ì¹˜ë¡œ ì—°ê²°.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Atlas excels in Layer 2 (Motion & Physical Behavior) with fluid, legible whole-body movements that convey clear intent and agency. The absence of overt facial features yet strong perceived 'aliveness' through motion alone highlights how kinetic expressivity can establish emotional baseline and trust over time. For target form factors (especially Movable TV): predictive, smooth kinetic trajectories for 'act' and 'withdraw' roles; subtle body leans or head tilts as empathy cues during user proximity; ambient lighting synchronized with motion intensity for mood temperature. This motion-first approach inspires our PoC to prioritize 'predictability â†’ trust' and 'living presence' through non-verbal physical signaling.\n\n[KR] AtlasëŠ” Layer 2(Motion & Physical Behavior)ì—ì„œ ìœ ì—°í•˜ê³  ê°€ë…ì„± ë†’ì€ ì „ì‹  ì›€ì§ì„ìœ¼ë¡œ ëª…í™•í•œ ì˜ë„ì™€ agency ì „ë‹¬. ëª…í™•í•œ ì–¼êµ´ íŠ¹ì§• ì—†ì–´ë„ ëª¨ì…˜ë§Œìœ¼ë¡œ ê°•í•œ 'ì‚´ì•„ìˆìŒ' ì¸ì‹ â†’ ë¹„ì¸ê°„í˜• ë””ìì¸ì—ì„œë„ í‚¤ë„¤í‹± í‘œí˜„ì„±ì´ emotional baselineê³¼ trust over time êµ¬ì¶• ê°€ëŠ¥ì„± ê°•ì¡°. ìš°ë¦¬ íƒ€ê²Ÿ í¼íŒ©í„°(íŠ¹íˆ ë¬´ë¹™ ìŠ¤íƒ€ì¼ TV ìš°ì„ )ì— ì ìš© ì‹œ: 'act'ì™€ 'withdraw' ì—­í• ì„ ìœ„í•œ ì˜ˆì¸¡ì Â·ë¶€ë“œëŸ¬ìš´ í‚¤ë„¤í‹± ê¶¤ì (ë¶ˆì•ˆ ê°ì†Œë¥¼ ìœ„í•œ ë¶€ë“œëŸ¬ìš´ ì ‘ê·¼/í›„í‡´); ì‚¬ìš©ì ê·¼ì ‘ ì‹œ empathy cuesë¡œì„œ ë¯¸ì„¸ ëª¸ ê¸°ìš¸ì„ì´ë‚˜ í—¤ë“œ í‹¸íŠ¸(í‚¤ë„¤í‹± ê´€ì ˆ í™œìš©); ëª¨ì…˜ ê°•ë„ì™€ ë™ê¸°í™”ëœ ambient lightingìœ¼ë¡œ mood temperature(íœ´ì‹ ì‹œ ì°¨ë¶„í•œ ë¸”ë£¨, ìƒí˜¸ì‘ìš© ì‹œ ë”°ëœ»í•œ í„ìŠ¤). ì´ ëª¨ì…˜ ìš°ì„  ì ‘ê·¼ì€ PoCì—ì„œ 'predictability â†’ trust'ì™€ 'living presence'ë¥¼ ë¹„ì–¸ì–´ì  ë¬¼ë¦¬ì  ì‹œê·¸ë„ë§ìœ¼ë¡œ ìš°ì„ í•˜ë„ë¡ ì˜ê°.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/atlas-electric/atlas-electric_1.jpg",
        "/images/products/atlas-electric/atlas-electric_2.jpg",
        "/images/products/atlas-electric/atlas-electric_3.jpg",
        "/images/products/atlas-electric/atlas-electric_4.jpg",
        "/images/products/atlas-electric/atlas-electric_5.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Boston+Dynamics+Electric+Atlas+CES+2026"
    },
    {
      "id": "lg-cloid",
      "typeId": "type1",
      "manufacturer": "LG Electronics",
      "name": "CLOiD (Gen 2026)",
      "country": "South Korea",
      "overview": "Purpose: To realize a 'Zero Labor Home' by autonomously handling daily chores while providing proactive emotional support, companionship, and contextual life assistance; designed to become a seamless, always-present family member that reduces cognitive and physical burden in everyday life. At CES 2026, LG unveiled the evolved CLOiD with significant upgrades: dual-wheel mobility combined with a kinetic expressive head (tilt, nod, rotate), circular face-like display for micro-expressions, integrated ambient lighting ring, advanced ThinQ AI platform with on-device multimodal processing, and new physical task capabilities (laundry initiation, dish unloading, light object transport, pet monitoring). Live demos showed unscripted emotional responsiveness (e.g., gentle approach when detecting user fatigue via voice tone/camera, soft lighting changes for mood soothing, playful gestures during family interactions) and seamless integration with LG appliances. The robot proactively anticipates needs based on habitual patterns and environmental sensing, emphasizing calm presence over intrusive assistance.\n\n[KR] ì œí’ˆì˜ ëª©ì : ì¼ìƒ ê°€ì‚¬ ìë™í™”ë¡œ â€˜Zero Labor Homeâ€™ ì‹¤í˜„ê³¼ ë™ì‹œì— ì‚¬ì „ì  ê°ì • ì§€ì›, ë™ë°˜ì ì—­í• , ë§¥ë½ ê¸°ë°˜ ìƒí™œ ë³´ì¡° ì œê³µ; ì¸ì§€ì Â·ë¬¼ë¦¬ì  ë¶€ë‹´ì„ ì¤„ì´ëŠ” ìƒì‹œ ì¡´ì¬ ê°€ì¡± êµ¬ì„±ì›ìœ¼ë¡œ ì„¤ê³„. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ LGëŠ” ëŒ€í­ ì—…ê·¸ë ˆì´ë“œëœ CLOiDë¥¼ ê³µê°œ: ë“€ì–¼ íœ  ì´ë™ì„±ê³¼ í‚¤ë„¤í‹± í‘œí˜„ í—¤ë“œ(í‹¸íŠ¸, ë„ë•ì„, íšŒì „), ë§ˆì´í¬ë¡œ í‘œí˜„ìš© ì›í˜• ì–¼êµ´í˜• ë””ìŠ¤í”Œë ˆì´, ambient lighting ë§ í†µí•©, ì˜¨ë””ë°”ì´ìŠ¤ ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ê°•í™” ThinQ AI í”Œë«í¼, ìƒˆë¡œìš´ ë¬¼ë¦¬ ì‘ì—… ëŠ¥ë ¥(ì„¸íƒ ì‹œì‘, ì‹ê¸° ë¹„ìš°ê¸°, ê°€ë²¼ìš´ ë¬¼ê±´ ìš´ë°˜, í« ëª¨ë‹ˆí„°ë§). ë¼ì´ë¸Œ ë°ëª¨ëŠ” ë¹„ìŠ¤í¬ë¦½íŠ¸ ê°ì • ë°˜ì‘ì„±(ìŒì„± í†¤/ì¹´ë©”ë¼ë¡œ í”¼ë¡œ ê°ì§€ ì‹œ ë¶€ë“œëŸ¬ìš´ ì ‘ê·¼, ê¸°ë¶„ ì§„ì •ì„ ìœ„í•œ ì†Œí”„íŠ¸ ì¡°ëª… ë³€í™”, ê°€ì¡± ìƒí˜¸ì‘ìš© ì‹œ ì¥ë‚œìŠ¤ëŸ¬ìš´ ì œìŠ¤ì²˜)ê³¼ LG ê°€ì „ê³¼ì˜ ì›í™œ í†µí•© ê°•ì¡°. ìŠµê´€ íŒ¨í„´ê³¼ í™˜ê²½ ì„¼ì‹± ê¸°ë°˜ ì‚¬ì „ì  í•„ìš” ì˜ˆì¸¡ìœ¼ë¡œ ì¹¨ìŠµì ì´ì§€ ì•Šì€ ì°¨ë¶„í•œ ì¡´ì¬ê° ìš°ì„ .",
      "analysis": {
        "intro": "Proactive Affective Home AI\n[KR] ì‚¬ì „ì  ê°ì • ê¸°ë°˜ í™ˆ AI",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "CLOiD exemplifies a consumer-ready shift toward 'proactive yet unobtrusive' Physical AI in the home â€” blending task automation with affective presence. Its contextual awareness (via continuous sensing) and restrained physical interventions validate the 'stay/act/withdraw' model, creating value in the in-between moments of life where explicit requests are absent. By prioritizing emotional temperature over functional overload, it demonstrates how Physical AI can accumulate trust through consistent, gentle physical signaling in lived domestic spaces.\n\n[KR] CLOiDëŠ” ê°€ì • ë‚´ â€œì‚¬ì „ì ì´ë©´ì„œ ë¹„ì¹¨ìŠµì â€ Physical AIì˜ ì†Œë¹„ì ì¤€ë¹„ ë‹¨ê³„ ì „í™˜ ì‚¬ë¡€ â€” ì‘ì—… ìë™í™”ì™€ affective ì¡´ì¬ê° ê²°í•©. ì§€ì†ì  ì„¼ì‹± ê¸°ë°˜ ë§¥ë½ ì¸ì‹ê³¼ ì ˆì œëœ ë¬¼ë¦¬ ê°œì…ìœ¼ë¡œ â€˜stay/act/withdrawâ€™ ëª¨ë¸ ê²€ì¦, ëª…ì‹œì  ìš”ì²­ ì—†ëŠ” ì‚¶ì˜ in-between momentsì—ì„œ ê°€ì¹˜ ì°½ì¶œ. ê¸°ëŠ¥ ê³¼ë¶€í•˜ë³´ë‹¤ emotional temperature ìš°ì„ ìœ¼ë¡œ, ì¼ìƒ ê°€ì • ê³µê°„ì—ì„œ ì¼ê´€ëœ ë¶€ë“œëŸ¬ìš´ ë¬¼ë¦¬ ì‹œê·¸ë„ë§ìœ¼ë¡œ ì‹ ë¢° ì¶•ì  ë°©ì‹ ë³´ì—¬ì¤Œ.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "CLOiD shines in integrated Layer 1 (Light) + Layer 2 (Motion) + Layer 3 (Face/Display) synergy â€” the ambient lighting ring subtly shifts color to reflect emotional baseline, kinetic head movements provide legible agency and turn-taking politeness, and the circular display delivers micro-expressions for empathy cues. This creates a calm, reliable 'living presence' that reduces anxiety in transitional moments. For target form factors (especially Tabletop & Movable TV): synchronized ambient lighting + kinetic orientation for mood temperature; restrained micro-gestures (nod, sway) as non-verbal acknowledgment; face/projection cues calibrated for warmth to build attachment. Critically, CLOiD's restraint reinforces our Strategic Layer's 'uninterrupted state' and 'trust over time'.\n\n[KR] CLOiDëŠ” Layer 1(Light) + Layer 2(Motion) + Layer 3(Face/Display)ì˜ í†µí•© ì‹œë„ˆì§€ ê°•ì  â€” ambient lighting ë§ìœ¼ë¡œ emotional baseline ë¯¸ë¬˜ ì „ë‹¬, í‚¤ë„¤í‹± í—¤ë“œ ì›€ì§ì„ìœ¼ë¡œ ê°€ë…ì„± ìˆëŠ” agencyì™€ turn-taking politeness ì œê³µ, ì›í˜• ë””ìŠ¤í”Œë ˆì´ë¡œ empathy cues ì „ë‹¬í•˜ë©° ê³¼ë„í•œ ë¦¬ì–¼ë¦¬ì¦˜ í”¼í•¨. ì´ëŠ” ì „í™˜ ìˆœê°„ì˜ ë¶ˆì•ˆ ê°ì†Œí•˜ëŠ” ì°¨ë¶„í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” â€˜living presenceâ€™ ì°½ì¶œ. ìš°ë¦¬ íƒ€ê²Ÿ í¼íŒ©í„°(íŠ¹íˆ í…Œì´ë¸”íƒ‘ & ë¬´ë¹™ ìŠ¤íƒ€ì¼ TV ìš°ì„ )ì— ì ìš© ì‹œ: mood temperatureì™€ ê·¼ì ‘ ê¸°ë°˜ ì¡´ì¬ê°ì„ ìœ„í•œ ë™ê¸°í™”ëœ ambient lighting + í‚¤ë„¤í‹± ë°©í–¥ ì „í™˜; companionship ê°•í™”ë¥¼ ìœ„í•œ ì ˆì œëœ ë§ˆì´í¬ë¡œ ì œìŠ¤ì²˜(nod, subtle sway) ë¹„ì–¸ì–´ì  ì¸ì •; uncanny valley í”¼í•˜ë©´ì„œ attachment êµ¬ì¶• ìœ„í•œ ë”°ëœ»í•¨ ì¤‘ì‹¬ face/projection cues. í•µì‹¬ì ìœ¼ë¡œ CLOiDì˜ ì ˆì œëŠ” Strategic Layerì˜ â€˜uninterrupted stateâ€™ì™€ â€˜trust over timeâ€™ ê°•í™”.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/lg-cloid/lg-cloid_1.jpg",
        "/images/products/lg-cloid/lg-cloid_2.jpg",
        "/images/products/lg-cloid/lg-cloid_3.jpg",
        "/images/products/lg-cloid/lg-cloid_4.jpg",
        "/images/products/lg-cloid/lg-cloid_5.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=LG+CLOi+Robot+CES+2026"
    },
    {
      "id": "sharpa-north",
      "typeId": "type1",
      "manufacturer": "Sharpa (Embodied AI Specialist)",
      "name": "North",
      "country": "Singapore",
      "overview": "Purpose: To create 'useful time' for humans by automating complex, repetitive real-world tasks with human-level dexterity and autonomy; designed for seamless integration into everyday environments (home, office, service) through prolonged, unscripted physical interaction without constant supervision. At CES 2026, Sharpa debuted North with groundbreaking fully autonomous live demonstrations: high-speed ping-pong rallies (0.02-second reaction time, real-time trajectory prediction), precise photography framing (within 2mm accuracy), card dealing, and extended sequential tasks like building structures â€” all executed without human intervention, scripting, or teleoperation. North features a wheeled mobile base for positioning, adjustable torso, highly dexterous robotic hands with integrated touch/vision, and multimodal AI (combining vision, language understanding, and manipulation in real-time).\n\n[KR] ì œí’ˆì˜ ëª©ì : ì¸ê°„ ìˆ˜ì¤€ ë±ìŠ¤í„°ë¦¬í‹°ì™€ ììœ¨ì„±ìœ¼ë¡œ ë³µì¡Â·ë°˜ë³µì  ì‹¤ì„¸ê³„ ì‘ì—… ìë™í™”í•˜ì—¬ ì¸ê°„ì—ê²Œ 'ìœ ìš©í•œ ì‹œê°„' ì°½ì¶œ; ìƒì‹œ ê°ë… ì—†ì´ ì¼ìƒ í™˜ê²½(ê°€ì •, ì‚¬ë¬´, ì„œë¹„ìŠ¤)ì— ì›í™œ í†µí•© ìœ„í•œ ì¥ê¸°ì Â·ë¹„ìŠ¤í¬ë¦½íŠ¸ ë¬¼ë¦¬ ìƒí˜¸ì‘ìš© ì„¤ê³„. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ SharpaëŠ” Northë¥¼ ìµœì´ˆ ê³µê°œí•˜ë©° í˜ì‹ ì  ì™„ì „ ììœ¨ ë¼ì´ë¸Œ ë°ëª¨ ì‹œì—°: ê³ ì† í•‘í ë ë¦¬(0.02ì´ˆ ë°˜ì‘ ì‹œê°„, ì‹¤ì‹œê°„ ê¶¤ì  ì˜ˆì¸¡), ì •ë°€ ì‚¬ì§„ í”„ë ˆì´ë°(2mm ì´ë‚´ ì •í™•ë„), ì¹´ë“œ ë”œë§, êµ¬ì¡°ë¬¼ êµ¬ì¶• ë“± ì¥ê¸° ì‹œí€€ìŠ¤ ì‘ì—… â€” ëª¨ë‘ ì¸ê°„ ê°œì…Â·ìŠ¤í¬ë¦½íŠ¸Â·ì›ê²© ì¡°ì‘ ì—†ì´ ìˆ˜í–‰. íœ  ëª¨ë°”ì¼ ë² ì´ìŠ¤(í¬ì§€ì…”ë‹), ì¡°ì ˆ ê°€ëŠ¥ í† ë¥´ì†Œ, í„°ì¹˜/ë¹„ì „ í†µí•© ê³ ë±ìŠ¤í„°ëŸ¬ìŠ¤ ë¡œë³´í‹± í•¸ë“œ, ë©€í‹°ëª¨ë‹¬ AI(ë¹„ì „Â·ì–¸ì–´ ì´í•´Â·ì¡°ì‘ ì‹¤ì‹œê°„ ê²°í•©) íƒ‘ì¬.",
      "analysis": {
        "intro": "Embedded Multimodal Intelligence\n[KR] ì²´í™”ëœ ë©€í‹°ëª¨ë‹¬ ì§€ëŠ¥",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "North advances 'embodied multimodal intelligence' by prioritizing real-time integration of perception, reasoning, and precise physical action â€” enabling prolonged autonomous performance in dynamic, unstructured tasks. Its 0.02s reaction and sustained coordination demonstrate a leap toward reliable Physical AI that operates as a proactive agent, validating the shift from isolated demos to deployable, context-aware systems in lived environments.\n\n[KR] NorthëŠ” í¼ì…‰ì…˜Â·ì¶”ë¡ Â·ì •ë°€ ë¬¼ë¦¬ í–‰ë™ì˜ ì‹¤ì‹œê°„ í†µí•© ìš°ì„ ìœ¼ë¡œ 'ì²´í™”ëœ ë©€í‹°ëª¨ë‹¬ ì§€ëŠ¥' ì§„ë³´ â€” ë™ì Â·ë¹„êµ¬ì¡°í™” ì‘ì—…ì—ì„œ ì¸ê°„-like ì ì‘ì„± ìš”êµ¬í•˜ëŠ” ì¥ê¸° ììœ¨ ì„±ëŠ¥ êµ¬í˜„. 0.02ì´ˆ ë°˜ì‘ê³¼ ì§€ì† ì½”ë””ë„¤ì´ì…˜ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” Physical AIë¡œì˜ ë„ì•½ ë³´ì—¬ì£¼ë©°, ì¸ê°„ ê°ë… ìµœì†Œí™”í•˜ê³  isolated ë°ëª¨ì—ì„œ lived í™˜ê²½ì˜ ë°°í¬ ê°€ëŠ¥Â·ë§¥ë½ ì¸ì§€ ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜ ê²€ì¦.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "North's core strength is in Layer 2 (Motion & Physical Behavior) with exceptional dexterous manipulation conveying clear agency. The absence of overt facial features yet strong 'aliveness' through upper-body kinetics highlights how motion dexterity can establish emotional baseline and companionship. For our target form factors: wheeled/kinetic base for proactive positioning as 'stay/act' cues; subtle arm/hand micro-gestures synchronized with ambient lighting pulses for empathy signaling; restrained withdrawal motions post-task to embody 'withdraw' and uninterrupted state.\n\n[KR] Northì˜ ê°•ì ì€ Layer 2(Motion & Physical Behavior)ì—ì„œ íƒì›”í•œ ë±ìŠ¤í„°ëŸ¬ìŠ¤ ì¡°ì‘ìœ¼ë¡œ ë¯¸ë¬˜Â·ì •ë°€ ì›€ì§ì„ í†µí•´ ëª…í™•í•œ agencyì™€ ì˜ë„ ì „ë‹¬. ëª…í™•í•œ ì–¼êµ´ íŠ¹ì§• ì—†ì–´ë„ ìƒì²´ í‚¤ë„¤í‹±ë§Œìœ¼ë¡œ ê°•í•œ 'ì‚´ì•„ìˆìŒ' ì¸ì‹ â†’ ì¸ë¥˜í˜• cues ì—†ì´ ëª¨ì…˜ ë±ìŠ¤í„°ë¦¬í‹°ê°€ emotional baselineê³¼ companionship êµ¬ì¶• ê°€ëŠ¥ì„± ê°•ì¡°. ìš°ë¦¬ íƒ€ê²Ÿ í¼íŒ©í„°ì— ì ìš© ì‹œ: 'stay/act' cues ì£¼ëŠ” íœ /í‚¤ë„¤í‹± ë² ì´ìŠ¤ í”„ë¡œì•¡í‹°ë¸Œ í¬ì§€ì…”ë‹; empathy signaling ìœ„í•œ ambient lighting í„ìŠ¤ì™€ ë™ê¸°í™”ëœ ë¯¸ì„¸ ì•”/í•¸ë“œ ì œìŠ¤ì²˜; ì‘ì—… í›„ ì ˆì œëœ í›„í‡´ ëª¨ì…˜ìœ¼ë¡œ 'withdraw'ì™€ uninterrupted state ì²´í˜„.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/sharpa-north/sharpa-north_1.jpg",
        "/images/products/sharpa-north/sharpa-north_2.jpg",
        "/images/products/sharpa-north/sharpa-north_3.jpg",
        "/images/products/sharpa-north/sharpa-north_4.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Sharpa+Robotics+North+CES+2026"
    },
    {
      "id": "embodied-tien-kung",
      "typeId": "type1",
      "manufacturer": "X-Humanoid",
      "name": "Embodied Tien Kung 2.0",
      "country": "China",
      "overview": "A mass-market approach to specialized mobility. Tien Kung 2.0 showcases autonomous sorting in logistics with a focus on swarm intelligenceâ€”coordinating with other units seamlessly to prevent bottlenecks. It represents the transition from individual robotic tasks to collective robotic flow.\n\n[KR] íŠ¹ìˆ˜ ê¸°ë™ì„±ì„ ê°–ì¶˜ ëŒ€ëŸ‰ ìƒì‚°í˜• ëª¨ë¸ì…ë‹ˆë‹¤. Tien Kung 2.0ì€ ë¬¼ë¥˜ í˜„ì¥ì—ì„œì˜ ììœ¨ ë¶„ë¥˜ ì‘ì—…ì„ ì„ ë³´ì´ë©°, ë³‘ëª© í˜„ìƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë‹¤ë¥¸ ìœ ë‹›ë“¤ê³¼ ë§¤ë„ëŸ½ê²Œ í˜‘ë ¥í•˜ëŠ” 'êµ°ì§‘ ì§€ëŠ¥(Swarm Intelligence)'ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê°œë³„ ë¡œë´‡ì˜ ì‘ì—…ì´ ì§‘ë‹¨ì ì¸ ë¡œë´‡ì˜ íë¦„ìœ¼ë¡œ ì „í™˜ë¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Swarm Choreography\n[KR] êµ°ì§‘ ì•ˆë¬´(Swarm Choreography)",
        "points": [
          {
            "title": "Flow State Movement",
            "content": "Individual movements are less 'heroic' and more utilitarian, prioritizing flow within a group over individual speed. This predictability reduces collision anxiety for human coworkers.\n\n[KR] ê°œë³„ ë¡œë´‡ì˜ ì›€ì§ì„ì€ 'ì˜ì›…ì 'ì´ê¸°ë³´ë‹¤ ì‹¤ìš©ì ì´ë©°, ê°œë³„ ì†ë„ë³´ë‹¤ëŠ” ê·¸ë£¹ ì „ì²´ì˜ íë¦„ì„ ìš°ì„ ì‹œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì€ ì¸ê°„ ë™ë£Œë“¤ì˜ ì¶©ëŒ ë¶ˆì•ˆê°ì„ ì¤„ì—¬ì¤ë‹ˆë‹¤."
          },
          {
            "title": "Utilitarian Aesthetics",
            "content": "Exposed carbon fiber and sensor arrays signal raw functionality, setting user expectations for 'work intent' rather than 'social interaction'.\n\n[KR] ë…¸ì¶œëœ íƒ„ì†Œ ì„¬ìœ ì™€ ì„¼ì„œ ë°°ì—´ì€ ë‚ ê²ƒ ê·¸ëŒ€ë¡œì˜ ê¸°ëŠ¥ì„±ì„ ë“œëŸ¬ë‚´ë©°, ì‚¬ìš©ìë¡œ í•˜ì—¬ê¸ˆ 'ì‚¬íšŒì  ìƒí˜¸ì‘ìš©'ì´ ì•„ë‹Œ 'ì‘ì—… ì˜ë„'ë¥¼ ê¸°ëŒ€í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/embodied-tien-kung/embodied-tien-kung_1.webp",
        "/images/products/embodied-tien-kung/embodied-tien-kung_2.png"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Tien+Kung+Humanoid+Robot"
    },
    {
      "id": "figure-ai",
      "typeId": "type1",
      "manufacturer": "Figure AI Inc.",
      "name": "Figure 02 (Gen 2)",
      "country": "United States",
      "overview": "Purpose: To address labor shortages by performing human-like physical tasks in real-world environments (initially industrial assembly, logistics, manufacturing) while enabling natural human-robot interaction through speech, vision, and dexterity; long-term vision includes home deployment. Figure 02 is a ground-up redesign: 168 cm, 70 kg, 16 DoF hands (human-like strength), integrated cabling, 50% larger battery (~5+ hours), 6 RGB cameras + onboard VLM for real-time perception/coordination, and OpenAI-powered conversational speech-to-speech. Features triple compute power (dual NVIDIA RTX GPU modules) for full autonomy. Successfully deployed at BMW Spartanburg plant (11 months, 30,000+ vehicles) for sheet-metal handling; retirement learnings inform Figure 03. Commercial shipments began late 2024.\n\n[KR] ì œí’ˆì˜ ëª©ì : ì‚°ì—… í˜„ì¥(ì¡°ë¦½Â·ë¬¼ë¥˜Â·ì œì¡°)ì—ì„œ ì¸ê°„ë‹¤ìš´ ë¬¼ë¦¬ ì‘ì—… ìˆ˜í–‰ìœ¼ë¡œ ë…¸ë™ ë¶€ì¡± í•´ê²° ë° ìì—°ìŠ¤ëŸ¬ìš´ ìƒí˜¸ì‘ìš©(ìŒì„±Â·ì‹œê°Â·ë±ìŠ¤í„°ë¦¬í‹°) êµ¬í˜„; ì¥ê¸°ì  ê°€ì •ìš© ëª©í‘œ. ìƒì„¸ ì„¤ëª…: Figure 02ëŠ” ì™„ì „ ì¬ì„¤ê³„ ëª¨ë¸: 168cm, 70kg, 16 DoF í•¸ë“œ(ì¸ê°„ê¸‰ ê°•ë„), í†µí•© ì¼€ì´ë¸”, ë°°í„°ë¦¬ 50% ì¦ëŒ€(~5ì‹œê°„+), 6 RGB ì¹´ë©”ë¼ + ì˜¨ë³´ë“œ VLMìœ¼ë¡œ ì‹¤ì‹œê°„ ì¸ì‹/ì¡°ì •, OpenAI ê¸°ë°˜ ëŒ€í™”í˜• ìŒì„± ê¸°ëŠ¥ íƒ‘ì¬. ë“€ì–¼ NVIDIA RTX GPU ëª¨ë“ˆë¡œ ì™„ì „ ììœ¨ ì‘ì—… ê°€ëŠ¥. BMW ìŠ¤ Spartanburg ê³µì¥ 11ê°œì›” ì‹¤ì „ ë°°ì¹˜(ì‹œíŠ¸ë©”íƒˆ í•¸ë“¤ë§, 3ë§Œ ëŒ€ ì´ìƒ ìƒì‚° ê¸°ì—¬) í›„ Figure 03 ê°œë°œì„ ìœ„í•´ í‡´ì—­. 2024ë…„ ë§ ìƒì—… ì¶œí•˜ ì‹œì‘.",
      "analysis": {
        "intro": "Task-Oriented Embodied Intelligence\n[KR] ê³¼ì—… ì¤‘ì‹¬ ì²´í™”ëœ ì§€ëŠ¥",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Figure 02 marks a critical bridge to commercial Physical AI â€” demonstrating reliable, long-duration autonomous operation in unstructured industrial settings through integrated embodied intelligence. Its conversational capability and real-world durability validate the shift toward 'lived' continuous presence that handles repetitive tasks while maintaining human-level interaction. Learnings form a foundation for revenue-generating workforce evolution.\n\n[KR] Figure 02ëŠ” ìƒì—…ìš© Physical AIë¡œì˜ í•µì‹¬ ê°€êµ â€” í†µí•©ëœ ì²´í™” ì§€ëŠ¥ìœ¼ë¡œ ë¹„êµ¬ì¡°í™” ì‚°ì—… í™˜ê²½ì—ì„œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¥ê¸° ììœ¨ ìš´ìš© ì…ì¦. ëŒ€í™” ëŠ¥ë ¥ê³¼ ì‹¤ì„¸ê³„ ë‚´êµ¬ì„±ì€ ë°˜ë³µ ì‘ì—…ì„ ì²˜ë¦¬í•˜ë©´ì„œë„ ì¸ê°„ ìˆ˜ì¤€ ìƒí˜¸ì‘ìš©ì„ ìœ ì§€í•˜ëŠ” 'lived' ì—°ì† ì¡´ì¬ê° ê²€ì¦. ìˆ˜ìµ ì°½ì¶œí˜• ë…¸ë™ë ¥ìœ¼ë¡œ ì§„í™”í•˜ëŠ” ê¸°ë°˜ êµ¬ì¶•.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Figure 02 shines in Layer 2 (Motion & Physical Behavior) â€” fluid, precise whole-body movements convey clear agency, predictability, and safety legibility, building implicit trust without words. The high-fidelity motion establishes an emotional baseline and companionship in professional contexts. For our targets (Movable TV/Tabletop): legible, human-like micro-motions (slow tilt/nod for listening, subtle retreat for politeness) synced with ambient lighting pulses for mood temperature; restrained, predictable trajectories to embody 'turn-taking politeness' and reduce anxiety. Its industrial restraint inspires 'predictability â†’ trust' via purposeful signaling.\n\n[KR] Figure 02ëŠ” Layer 2(Motion & Physical Behavior)ì—ì„œ ë¹›ë‚¨ â€” ìœ ì—°í•˜ê³  ì •ë°€í•œ ì „ì‹  ì›€ì§ì„ìœ¼ë¡œ ëª…í™•í•œ agencyì™€ safety legibility ì „ë‹¬, ë¬´ì–¸ì˜ ì‹ ë¢° êµ¬ì¶•. ê³ í’ˆì§ˆ ëª¨ì…˜ë§Œìœ¼ë¡œ ì „ë¬¸ ë§¥ë½ì—ì„œ emotional baselineê³¼ companionship í˜•ì„± ê°€ëŠ¥. ìš°ë¦¬ íƒ€ê²Ÿ(ë¬´ë¹™ TV/í…Œì´ë¸”íƒ‘) ì ìš©: ê²½ì²­(ëŠë¦° í‹¸íŠ¸/ë„ë•ì„)ì´ë‚˜ ì •ì¤‘í•¨(ë¯¸ì„¸ í›„í‡´)ì„ ìœ„í•œ ì¸ê°„ë‹¤ìš´ ë§ˆì´í¬ë¡œ ëª¨ì…˜ + ambient lighting í„ìŠ¤ ë™ê¸°í™”; ë¶ˆì•ˆ ê°ì†Œë¥¼ ìœ„í•œ ì ˆì œë˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê¶¤ì . ì‚°ì—…ì  ì ˆì œë¯¸ëŠ” ëª©ì  ìˆëŠ” ì‹œê·¸ë„ë§ì„ í†µí•œ 'ì˜ˆì¸¡ ê°€ëŠ¥ì„± â†’ ì‹ ë¢°' êµ¬ì¶•ì— ì˜ê°.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/figure-ai/figure-ai_1.webp"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Figure+AI+robot"
    },
    {
      "id": "unitree-g1",
      "typeId": "type1",
      "manufacturer": "Unitree",
      "name": "Unitree G1",
      "country": "China",
      "overview": "Emphasizing extreme dynamic mobility and affordability. The G1 is capable of acrobatic recovery and high-speed running, pushing the boundaries of dynamic balance. It represents the democratization of humanoid research hardware.\n\n[KR] ê·¹í•œì˜ ì—­ë™ì  ê¸°ë™ì„±ê³¼ ê°€ê²© ê²½ìŸë ¥ì„ ê°•ì¡°í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. G1ì€ ê³µì¤‘ì œë¹„ í›„ ì°©ì§€ì™€ ê°™ì€ ê³¡ì˜ˆ ìˆ˜ì¤€ì˜ íšŒë³µ ëŠ¥ë ¥ê³¼ ê³ ì† ì£¼í–‰ì´ ê°€ëŠ¥í•˜ì—¬ ë™ì  ê· í˜•ì˜ í•œê³„ë¥¼ ë„“í˜”ìŠµë‹ˆë‹¤. ì´ëŠ” íœ´ë¨¸ë…¸ì´ë“œ ì—°êµ¬ í•˜ë“œì›¨ì–´ì˜ ëŒ€ì¤‘í™”ë¥¼ ìƒì§•í•©ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Acrobatic Resilience\n[KR] ê³¡ì˜ˆì  íšŒë³µíƒ„ë ¥ì„±",
        "points": [
          {
            "title": "Recovery UX",
            "content": "The ability to stand up instantly from a fall changes the perception of 'fragility' usually associated with robots, building trust in rugged environments.\n\n[KR] ë„˜ì–´ì¡Œì„ ë•Œ ì¦‰ì‹œ ì¼ì–´ë‚˜ëŠ” ëŠ¥ë ¥ì€ ë¡œë´‡ì— ëŒ€í•œ 'ì—°ì•½í•˜ë‹¤'ëŠ” ê³ ì •ê´€ë…ì„ ê¹¨ê³ , ê±°ì¹œ í™˜ê²½ì—ì„œë„ ì‹ ë¢°í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
          },
          {
            "title": "Compact Folding",
            "content": "Can fold itself into a compact storage mode, acknowledging that robots need to 'disappear' when not in use to save human space.\n\n[KR] ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•ŒëŠ” ì‘ê²Œ ì ‘ì–´ ë³´ê´€í•  ìˆ˜ ìˆì–´, ì¸ê°„ì˜ ê³µê°„ì„ ì ˆì•½í•˜ê³  ë¡œë´‡ì´ í•„ìš” ì—†ì„ ë•Œ 'ì‚¬ë¼ì ¸ ì£¼ëŠ”' ë°°ë ¤ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/unitree-g1/unitree-g1_1.png"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Unitree+G1+Humanoid"
    },
    {
      "id": "agility-digit",
      "typeId": "type1",
      "manufacturer": "Agility Robotics",
      "name": "Digit",
      "country": "USA",
      "overview": "The logistic veteran. Digit's backward-jointed legs and headless design focus purely on lifting and moving boxes, now updated with better human-sensing for crowded warehouses. It prioritizes function over form to maximize vertical stacking efficiency.\n\n[KR] ë¬¼ë¥˜ ë¡œë´‡ì˜ ë² í…Œë‘ì…ë‹ˆë‹¤. Digitì˜ ì—­ê´€ì ˆ ë‹¤ë¦¬ì™€ ë¨¸ë¦¬ ì—†ëŠ” ë””ìì¸ì€ ì˜¤ë¡œì§€ ìƒìë¥¼ ë“¤ì–´ ì˜®ê¸°ëŠ” ê¸°ëŠ¥ì— ì§‘ì¤‘ë˜ì–´ ìˆìœ¼ë©°, ë¶ë¹„ëŠ” ì°½ê³  ë‚´ì—ì„œì˜ ì¸ê°„ ê°ì§€ ì„¼ì„œê°€ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤. í˜•íƒœë³´ë‹¤ëŠ” ê¸°ëŠ¥ì„ ìš°ì„ ì‹œí•˜ì—¬ ìˆ˜ì§ ì ì¬ íš¨ìœ¨ì„ ê·¹ëŒ€í™”í–ˆìŠµë‹ˆë‹¤.",
      "analysis": {
        "intro": "Form Follows Function\n[KR] í˜•íƒœëŠ” ê¸°ëŠ¥ì„ ë”°ë¥¸ë‹¤",
        "points": [
          {
            "title": "Bird-Like Gait",
            "content": "The reverse-knee design is biologically distinct, preventing the 'Uncanny Valley' effect by not trying to be overly human. It signals 'machine' immediately.\n\n[KR] ìƒˆì²˜ëŸ¼ êº¾ì¸ ë¬´ë¦ ë””ìì¸ì€ ìƒë¬¼í•™ì ìœ¼ë¡œ ë…íŠ¹í•˜ì—¬, ê³¼ë„í•˜ê²Œ ì¸ê°„ì„ í‰ë‚´ ë‚´ì§€ ì•ŠìŒìœ¼ë¡œì¨ 'ë¶ˆì¾Œí•œ ê³¨ì§œê¸°' íš¨ê³¼ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤. ì¦‰ê°ì ìœ¼ë¡œ 'ê¸°ê³„ì„'ì„ ì‹ í˜¸í•©ë‹ˆë‹¤."
          },
          {
            "title": "Torso Signaling",
            "content": "Uses LED patterns on the chest to indicate direction and status, replacing facial expressions with clear industrial signaling legible from a distance.\n\n[KR] ê°€ìŠ´ì˜ LED íŒ¨í„´ì„ ì‚¬ìš©í•´ ì´ë™ ë°©í–¥ê³¼ ìƒíƒœë¥¼ í‘œì‹œí•˜ë©°, í‘œì • ëŒ€ì‹  ë©€ë¦¬ì„œë„ ì‹ë³„ ê°€ëŠ¥í•œ ëª…í™•í•œ ì‚°ì—… ì‹ í˜¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/agility-digit/agility-digit_1.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Agility+Robotics+Digit"
    },
    {
      "id": "apptronik-apollo",
      "typeId": "type1",
      "manufacturer": "Apptronik",
      "name": "Apollo",
      "country": "USA",
      "overview": "Designed for the 'human world'. Apollo has a friendly, accessible aesthetic with safety-first force control, meant to work shoulder-to-shoulder with people in factories.",
      "analysis": {
        "intro": "Collaborative Safety",
        "points": [
          {
            "title": "Digital Face Information",
            "content": "The face screen displays battery and task status, treating the 'face' as an information radiator rather than just an identity."
          },
          {
            "title": "Soft Stop",
            "content": "Movement deceleration curves are tuned to be smooth, avoiding jerky stops that startle nearby humans."
          }
        ]
      },
      "images": [
        "/images/products/apptronik-apollo/apptronik-apollo_1.png"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Apptronik+Apollo"
    },
    {
      "id": "sanctuary-phoenix",
      "typeId": "type1",
      "manufacturer": "Sanctuary AI",
      "name": "Phoenix",
      "country": "Canada",
      "overview": "The hands have it. Phoenix boasts the world's most human-like hands with tactile sensors, capable of buttoning shirts or using standard tools.",
      "analysis": {
        "intro": "Tactile Intelligence",
        "points": [
          {
            "title": "Grasp Adaptation",
            "content": "Visibly adjusts grip strength and finger positioning before exploring an object, mimicking human 'exploratory touch'."
          },
          {
            "title": "Teleoperation Legacy",
            "content": "Movement has a fluidity derived from human-teleoperated training data, making it feel less algorithmic."
          }
        ]
      },
      "images": [
        "/images/products/sanctuary-phoenix/sanctuary-phoenix_1.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Sanctuary+AI+Phoenix"
    },
    {
      "id": "1x-neo",
      "typeId": "type1",
      "manufacturer": "1X Technologies",
      "name": "NEO",
      "country": "Norway",
      "overview": "A humanoid for the home. NEO uses soft outer layers and muscle-like actuation to be safe enough to hug, targeting the domestic assistance market.",
      "analysis": {
        "intro": "Soft Robotics UX",
        "points": [
          {
            "title": "Huggable Physics",
            "content": "The absence of pinch points and hard shells invites physical contact, breaking the 'do not touch' barrier of traditional robotics."
          },
          {
            "title": "Silent Operation",
            "content": "Near-silent movement ensures it doesn't dominate the home soundscape, respecting acoustic privacy."
          }
        ]
      },
      "images": [
        "/images/products/1x-neo/1x-neo_1.webp"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=1X+Technologies+NEO"
    },
    {
      "id": "unitree-h2",
      "typeId": "type1",
      "manufacturer": "Unitree",
      "name": "H2",
      "country": "China",
      "overview": "Unitree's universal humanoid agent designed for industrial and general-purpose applications. It features high torque density and dynamic balancing capabilities.\n\n[KR] ì‚°ì—… ë° ë²”ìš© ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•´ ì„¤ê³„ëœ ìœ ë‹ˆíŠ¸ë¦¬ì˜ ë²”ìš© íœ´ë¨¸ë…¸ì´ë“œ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ë†’ì€ í† í¬ ë°€ë„ì™€ ë™ì  ê· í˜• ëŠ¥ë ¥ì„ íŠ¹ì§•ìœ¼ë¡œ í•©ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Universal Stability\n[KR] ë³´í¸ì  ì•ˆì •ì„±",
        "points": [
          {
            "title": "Dynamic Recovery",
            "content": "Instantly recovers from external impacts, maintaining balance in unpredictable environments.\n\n[KR] ì™¸ë¶€ ì¶©ê²©ìœ¼ë¡œë¶€í„° ì¦‰ì‹œ íšŒë³µí•˜ì—¬ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ í™˜ê²½ì—ì„œë„ ê· í˜•ì„ ìœ ì§€í•©ë‹ˆë‹¤."
          },
          {
            "title": "High-Torque Efficiency",
            "content": "Proprietary motors deliver exceptional power-to-weight ratio, allowing for agile movement carrying heavy payloads.\n\n[KR] ë…ìì ì¸ ëª¨í„° ê¸°ìˆ ë¡œ ë›°ì–´ë‚œ ì¤‘ëŸ‰ ëŒ€ë¹„ ì¶œë ¥ì„ ì œê³µ, ë¬´ê±°ìš´ ì§ì„ ë“¤ê³ ë„ ë¯¼ì²©í•˜ê²Œ ì›€ì§ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/unitree-h2/unitree-h2_1.webp"
      ],
      "videoUrl": ""
    },
    {
      "id": "gene-01",
      "typeId": "type1",
      "manufacturer": "Generative Bionics",
      "name": "Gene.01",
      "country": "United States",
      "overview": "Purpose: To pioneer 'living-like' physical AI through generative bio-mimicry â€” creating robots that evolve form, texture, and expression organically like biological organisms, with primary focus on deep emotional presence, trust-building through natural fluidity, and non-verbal affective communication for human-robot symbiosis in caregiving, companionship, and intimate environments. At CES 2026, Generative Bionics demonstrated Gene.01 as a ~1.6m tall, soft-bodied humanoid with generative silicone-polymer skin capable of dynamic texture/color change (smooth â†’ wrinkled â†’ rippled), fluid muscle-like actuators (no rigid joints, 40+ pseudo-DoF), embedded pneumatic/hydraulic systems for breathing-like chest rise/fall, and micro-LED under-skin lighting for subsurface glow. The robot uses on-device generative AI (custom diffusion models) to evolve micro-expressions, posture, and skin patterns in real-time based on human emotional cues. Live demos: gentle 'embrace' simulation with soft enveloping arms, breathing synchronization with user, skin rippling in 'excitement' or 'calm waves'. No spoken language â€” all communication via body language, breathing rhythm, skin texture, and glow patterns.\n\n[KR] ì œí’ˆì˜ ëª©ì : ìƒì„± ìƒì²´ëª¨ë°©ìœ¼ë¡œ 'ì‚´ì•„ìˆëŠ” ë“¯í•œ' Physical AI ê°œì²™ â€” ìƒë¬¼ì²˜ëŸ¼ í˜•íƒœÂ·ì§ˆê°Â·í‘œí˜„ì´ ìœ ê¸°ì ìœ¼ë¡œ ì§„í™”í•˜ëŠ” ë¡œë´‡ êµ¬í˜„, ì£¼ìš” ì´ˆì ì€ ê¹Šì€ ê°ì • ì¡´ì¬ê°, ìì—°ìŠ¤ëŸ¬ìš´ ìœ ì—°í•¨ìœ¼ë¡œ ì‹ ë¢° êµ¬ì¶•, ë¹„ì–¸ì–´ affective ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ìœ¼ë¡œ ëŒë´„Â·ì»´íŒ¨ë‹ˆì–¸ì‹­Â·ì¹œë°€ í™˜ê²½ì—ì„œì˜ ì¸ê°„-ë¡œë´‡ ê³µìƒ. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ ~1.6m ë†’ì´ ì†Œí”„íŠ¸ ë°”ë”” íœ´ë¨¸ë…¸ì´ë“œ Gene.01 ì‹œì—° â€” ë™ì  ì§ˆê°/ì»¬ëŸ¬ ë³€í™” ê°€ëŠ¥í•œ ìƒì„± ì‹¤ë¦¬ì½˜-í´ë¦¬ë¨¸ ìŠ¤í‚¨(ë§¤ë„ëŸ¬ì›€ â†’ ì£¼ë¦„ â†’ ë¬¼ê²°), ê²½ì§ ê´€ì ˆ ì—†ëŠ” ìœ ì—° ê·¼ìœ¡-like ì•¡ì¶”ì—ì´í„°(40+ ì˜ì‚¬ DoF), í‰ë¶€ ìƒìŠ¹/í•˜ê°• í˜¸í¡ ì‹œë®¬ë ˆì´ì…˜ ë‚´ì¥ ê³µì••/ìœ ì•• ì‹œìŠ¤í…œ, í”¼ë¶€ ì•„ë˜ ë§ˆì´í¬ë¡œ LEDë¡œ subsurface glow. ì˜¨ë””ë°”ì´ìŠ¤ ìƒì„± AIë¡œ ì¸ê°„ ê°ì • cues ì‹¤ì‹œê°„ ë°˜ì˜í•´ ë§ˆì´í¬ë¡œ í‘œí˜„Â·ìì„¸Â·ìŠ¤í‚¨ íŒ¨í„´ ì§„í™”. ë¼ì´ë¸Œ ë°ëª¨: ë¶€ë“œëŸ½ê²Œ ê°ì‹¸ëŠ” íŒ” 'í¬ì˜¹', ì‚¬ìš©ìì™€ í˜¸í¡ ë™ê¸°í™”, ìƒí˜¸ì‘ìš© ì¤‘ 'í¥ë¶„' ë¬¼ê²° ë˜ëŠ” 'ì°¨ë¶„ íŒŒë„' ìŠ¤í‚¨ ë³€í™”. ë§ ì „í˜€ ì‚¬ìš© ì•ˆ í•¨ â€” ì „ë¶€ ë°”ë”” ë­ê·€ì§€Â·í˜¸í¡ ë¦¬ë“¬Â·ìŠ¤í‚¨ ì§ˆê°Â·glow íŒ¨í„´ìœ¼ë¡œ ì†Œí†µ.",
      "analysis": {
        "intro": "Generative Embodied Affective Intelligence\n[KR] ìƒì„±í˜• ì²´í™” Affective ì§€ëŠ¥",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Gene.01 represents the frontier of 'generative embodied affective intelligence' â€” using bio-mimetic soft materials and generative AI to create truly organic, evolving physical presence that transcends rigid robotics. Its subsurface lighting, breathing mechanics, and adaptive skin prove that the most profound non-verbal emotional connection comes from biological mimicry rather than anthropomorphic faces or scripted motion. This pushes Physical AI toward 'lived' continuity through constant subtle evolution, directly aligning with our project's emphasis on 'continuous,' 'physical,' and 'lived' life attributes.\n\n[KR] Gene.01ì€ 'ìƒì„±í˜• ì²´í™” affective ì§€ëŠ¥' ìµœì „ì„  â€” ìƒì²´ëª¨ë°© ì†Œí”„íŠ¸ ì†Œì¬ì™€ ìƒì„± AIë¡œ ê²½ì§ ë¡œë³´í‹±ìŠ¤ ì´ˆì›”í•˜ëŠ” ì§„ì • ìœ ê¸°ì Â·ì§„í™”í•˜ëŠ” ë¬¼ë¦¬ ì¡´ì¬ê° êµ¬í˜„. subsurface lightingÂ·í˜¸í¡ ë©”ì»¤ë‹ˆì¦˜Â·ì ì‘ ìŠ¤í‚¨ì€ ê°€ì¥ ê¹Šì€ ë¹„ì–¸ì–´ ê°ì • ì—°ê²°ì´ ì¸ë¥˜í˜• ì–¼êµ´ì´ë‚˜ ìŠ¤í¬ë¦½íŠ¸ ëª¨ì…˜ ì•„ë‹Œ ìƒë¬¼í•™ì  ëª¨ë°©ì—ì„œ ë‚˜ì˜¨ë‹¤ëŠ” ì¦ëª…. ì§€ì†ì  ë¯¸ë¬˜ ì§„í™”ë¡œ 'lived' ì—°ì†ì„± ì‹¤í˜„, ìš°ë¦¬ í”„ë¡œì íŠ¸ì˜ 'continuous'Â·'physical'Â·'lived' ì†ì„± ì§ì ‘ ì •ë ¬.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Gene.01 offers the most advanced vision for our Expression System â€” especially in Lighting & Ambient + Motion & Physical Behavior layers through bio-generative means. Core breakthroughs: Subsurface generative glow (under-skin micro-LED patterns) creates living, breathing mood temperature without external LEDs â€” skin itself becomes the ambient expression canvas (warm subsurface blush for affection, cool rippling waves for calm, pulsing heartbeat glow for excitement); soft, fluid whole-body motion (no rigid joints) delivers unparalleled agency and empathy cues through enveloping arms, gentle chest rise/fall breathing sync, organic wavelike skin ripples; adaptive skin texture (smooth â†’ soft wrinkled â†’ rippled) provides non-verbal emotional peak via tactile feedback alone. For our targets (Movable TV/Tabletop): implement gradient subsurface-style ambient lighting (multi-layer OLED/transparent panels) for 'blush' or 'wave' effects; design ultra-soft, fluid kinetic joints for enveloping, breathing-like motions; use projection mapping for adaptive skin texture changes; focus on biological mimicry in long-term behavior with subtle continuous evolution.\n\n[KR] Gene.01ì€ ìš°ë¦¬ Expression Systemì— ëŒ€í•œ ê°€ì¥ ì•ì„  ë¹„ì „ â€” íŠ¹íˆ Lighting & Ambient + Motion & Physical Behavior ë ˆì´ì–´ë¥¼ ìƒì²´ ìƒì„± ë°©ì‹ìœ¼ë¡œ ì™„ì„±. í•µì‹¬ í˜ì‹ : Subsurface generative glow(í”¼ë¶€ ì•„ë˜ ë§ˆì´í¬ë¡œ LED íŒ¨í„´)ë¡œ ì™¸ë¶€ LED ì—†ì´ ì‚´ì•„ ìˆ¨ì‰¬ëŠ” mood temperature êµ¬í˜„ â€” ìŠ¤í‚¨ ìì²´ê°€ ambient í‘œí˜„ ìº”ë²„ìŠ¤; ì†Œí”„íŠ¸Â·ìœ ì—° ì „ì‹  ëª¨ì…˜(ê²½ì§ ê´€ì ˆ ì—†ìŒ)ìœ¼ë¡œ ìµœê³  ìˆ˜ì¤€ agencyÂ·empathy cues; ì ì‘í˜• ìŠ¤í‚¨ ì§ˆê°ìœ¼ë¡œ ì´‰ê°ë§Œìœ¼ë¡œ ë¹„ì–¸ì–´ emotional peak. ìš°ë¦¬ íƒ€ê²Ÿ(ë¬´ë¹™ TV/í…Œì´ë¸”íƒ‘) ì ìš©: ë©€í‹°ë ˆì´ì–´ OLED/íˆ¬ëª… íŒ¨ë„ë¡œ gradient subsurface-style ambient lighting; ì†Œí”„íŠ¸ ì•¡ì¶”ì—ì´í„°ë¡œ ultra-soft ìœ ì—° í‚¤ë„¤í‹± ì¡°ì¸íŠ¸; projection mappingìœ¼ë¡œ ì ì‘ ìŠ¤í‚¨ ì§ˆê° ë³€í™”; ì¥ê¸° í–‰ë™ì— ìƒì²´ëª¨ë°© ì§‘ì¤‘.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/gene-01/gene-01_1.png",
        "/images/products/gene-01/gene-01_2.png",
        "/images/products/gene-01/gene-01_3.png"
      ],
      "videoUrl": ""
    },
    {
      "id": "switchbot-onero-h1",
      "typeId": "type1",
      "manufacturer": "SwitchBot",
      "name": "Onero H1",
      "country": "China",
      "overview": "Purpose: To serve as an 'accessible' embodied AI household assistant that automates difficult-to-automate chores (laundry loading/folding, dish handling, object manipulation, window cleaning, serving items) while integrating with existing SwitchBot ecosystem as a coordinator; aims to reduce daily physical labor with practical, learnable, on-device intelligence. At CES 2026, SwitchBot demoed the Onero H1 as a ~1.3m tall wheeled humanoid with 22 DoF articulated arms, RealSense cameras for vision/navigation, tactile feedback, and proprietary OmniSense VLA (Vision-Language-Action) on-device model for object recognition, grasping, pushing, opening, organizing. Live booth showed slow but deliberate laundry loading. Promotional videos expand to: filling coffee machine, making/serving breakfast, washing windows, dish loading, folding clothes. Designed to learn/adapt via demonstration, coordinate with specialized SwitchBot robots. Pre-orders planned post-CES, shipping late 2026 (rumored ~$1,500â€“$10,000 range).\n\n[KR] ì œí’ˆì˜ ëª©ì : ì„¸íƒ ë¡œë”©/ì ‘ê¸°Â·ì‹ê¸° ì²˜ë¦¬Â·ë¬¼ê±´ ì¡°ì‘Â·ì°½ë¬¸ ì²­ì†ŒÂ·ì•„ì´í…œ ì„œë¹™ ë“± ìë™í™” ì–´ë ¤ìš´ ê°€ì‚¬ ì‘ì—… ìˆ˜í–‰í•˜ëŠ” 'ì ‘ê·¼ì„± ë†’ì€' ì²´í™” AI ê°€ì • ì–´ì‹œìŠ¤í„´íŠ¸; ê¸°ì¡´ SwitchBot ì—ì½”ì‹œìŠ¤í…œê³¼ í†µí•©í•˜ì—¬ ì½”ë””ë„¤ì´í„° ì—­í• , ì‹¤ìš©ì Â·í•™ìŠµ ê°€ëŠ¥ ì˜¨ë””ë°”ì´ìŠ¤ ì§€ëŠ¥ìœ¼ë¡œ ì¼ìƒ ë¬¼ë¦¬ ë…¸ë™ ê°ì†Œ ëª©í‘œ. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ ~1.3m ë†’ì´ íœ  íœ´ë¨¸ë…¸ì´ë“œ Onero H1 ì‹œì—° â€” ê´€ì ˆ ì•” 22 DoF, RealSense ì¹´ë©”ë¼Â·ì´‰ê° í”¼ë“œë°±, ë…ì OmniSense VLA ì˜¨ë””ë°”ì´ìŠ¤ ëª¨ë¸ë¡œ ë¬¼ê±´ ì¸ì‹Â·ê·¸ë¼ìŠ¤í•‘Â·í‘¸ì‹œÂ·ì˜¤í”ˆÂ·ì •ë¦¬. ë¶€ìŠ¤ ë¼ì´ë¸Œ: ì†ŒíŒŒ ì˜· ê°œë³„ ì§‘ê¸° â†’ ì„¸íƒê¸° ì—´ê¸° â†’ ë„£ê¸° â†’ ë‹«ê¸° (ëŠë¦¬ì§€ë§Œ ì˜ë„ì ). í”„ë¡œëª¨ ë¹„ë””ì˜¤ í™•ì¥: ì»¤í”¼ë¨¸ì‹  ì±„ìš°ê¸°Â·ì•„ì¹¨ ì‹ì‚¬ ë§Œë“¤ê¸°/ì„œë¹™Â·ì°½ë¬¸ ì²­ì†ŒÂ·ì‹ê¸° ë¡œë”©Â·ì˜· ì ‘ê¸°. ë°ëª¨ í†µí•´ í•™ìŠµÂ·ì ì‘, ì „ë¬¸ SwitchBot ë¡œë´‡ê³¼ í˜‘ë ¥ ì„¤ê³„. CES í›„ ì„ ì£¼ë¬¸ ì˜ˆì •, 2026ë…„ ë§ ì¶œì‹œ (ì¶”ì • $1,500~$10,000).",
      "analysis": {
        "intro": "Practical Embodied AI & Ecosystem Orchestration\n[KR] ì‹¤ìš©ì  ì²´í™” AI ë° ì—ì½”ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Onero H1 represents 'practical embodied AI' for mass-market homes â€” wheeled mobility + articulated arms + on-device VLA enable contact-heavy, adaptive tasks in real environments without full bipedal complexity. Its ecosystem orchestration (controlling other devices) and learning-by-demonstration shift Physical AI from isolated performers to collaborative 'lived' helpers in continuous home life. Slow but reliable demo performance highlights the value of predictability and safety over flashy speed, aligning with 'continuous' and 'lived' attributes in unstructured daily routines.\n\n[KR] Onero H1ì€ ëŒ€ì¤‘ ê°€ì •ìš© 'ì‹¤ìš©ì  ì²´í™” AI' ëŒ€í‘œ â€” íœ  ëª¨ë¹Œë¦¬í‹° + ê´€ì ˆ ì•” + ì˜¨ë””ë°”ì´ìŠ¤ VLAë¡œ ë¹„êµ¬ì¡°í™” ì‹¤í™˜ê²½ ì ‘ì´‰ ì¤‘ì‹¬ ì ì‘ ì‘ì—… ê°€ëŠ¥, ì™„ì „ ì´ì¡± ë³µì¡ì„± ì—†ì´. ì—ì½”ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜(ë‹¤ë¥¸ ê¸°ê¸° ì œì–´)ê³¼ ë°ëª¨ í•™ìŠµìœ¼ë¡œ Physical AIë¥¼ ë…ë¦½ ìˆ˜í–‰ìì—ì„œ í˜‘ë ¥ì  'lived' í—¬í¼ë¡œ ì „í™˜. ëŠë¦¬ì§€ë§Œ ì•ˆì •ì  ë°ëª¨ëŠ” flashy ì†ë„ë³´ë‹¤ predictabilityÂ·safety ê°€ì¹˜ ê°•ì¡°, ë¹„êµ¬ì¡° ì¼ìƒ ë£¨í‹´ì˜ 'continuous'Â·'lived' ì†ì„±ê³¼ ë¶€í•©.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Onero H1 demonstrates Layer 2 (Motion & Physical Behavior) excellence â€” deliberate, slow, legible arm trajectories (careful grasping, gentle door opening/closing) convey safety legibility, predictability, and agency without words, reducing user anxiety in shared physical spaces. The wheeled base enables smooth 'stay/act/withdraw' (approach to task area = act, retreat after completion = withdraw). While minimal face/expressive features, the purposeful motion alone builds implicit trust through 'reliability over time.' For our targets (Movable TV/Tabletop): adopt deliberate, predictable kinetic patterns (slow extensions, gentle speed ramps) for agency and safety legibility; sync ambient lighting with motion phases (steady calm glow during approach = emotional baseline, subtle pulse on task completion = satisfaction); use restrained pause or lean micro-behaviors as non-verbal empathy cues; emphasize ecosystem coordination for context continuity across multiple form factors.\n\n[KR] Onero H1ì€ Layer 2(Motion & Physical Behavior) ìš°ìˆ˜ì„± ë³´ì—¬ì¤Œ â€” ì˜ë„ì Â·ëŠë¦°Â·ê°€ë…ì„± ë†’ì€ ì•” ê¶¤ì (ì‹ ì¤‘í•œ ê·¸ë¼ìŠ¤í•‘, ë¶€ë“œëŸ¬ìš´ ë„ì–´ ì˜¤í”ˆ/í´ë¡œì¦ˆ)ìœ¼ë¡œ ë§ ì—†ì´ safety legibilityÂ·predictabilityÂ·agency ì „ë‹¬, ê³µìœ  ë¬¼ë¦¬ ê³µê°„ ë¶ˆì•ˆ ê°ì†Œ. íœ  ë² ì´ìŠ¤ë¡œ ë¶€ë“œëŸ¬ìš´ stay/act/withdraw êµ¬í˜„. overt ì–¼êµ´/í‘œí˜„ ìµœì†Œí•˜ë‚˜ ëª©ì  ì§€í–¥ ëª¨ì…˜ë§Œìœ¼ë¡œ ì‹ ë¢° ì¶•ì . ìš°ë¦¬ íƒ€ê²Ÿ(ë¬´ë¹™ TV/í…Œì´ë¸”íƒ‘) ì ìš©: ì˜ë„ì Â·ì˜ˆì¸¡ ê°€ëŠ¥ í‚¤ë„¤í‹± íŒ¨í„´(ëŠë¦° í™•ì¥, gentle ì†ë„ ë¨í”„)ìœ¼ë¡œ agencyÂ·safety legibility; ëª¨ì…˜ ë‹¨ê³„ ì—°ë™ ambient lighting (ì ‘ê·¼ ì¤‘ steady calm glow = emotional baseline, ì‘ì—… ì™„ë£Œ ì‹œ ë¯¸ì„¸ í„ìŠ¤ = ë§Œì¡±); í–‰ë™ ì „/í›„ restrained pauseÂ·lean ë§ˆì´í¬ë¡œ í–‰ë™ìœ¼ë¡œ ë¹„ì–¸ì–´ empathy cues; ì—ì½”ì‹œìŠ¤í…œ ì½”ë””ë„¤ì´ì…˜ìœ¼ë¡œ ë‹¤ì¤‘ í¼íŒ©í„° context continuity.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/switchbot-onero-h1/switchbot-onero-h1_1.png",
        "/images/products/switchbot-onero-h1/switchbot-onero-h1_2.png",
        "/images/products/switchbot-onero-h1/switchbot-onero-h1_3.png"
      ],
      "videoUrl": ""
    },
    {
      "id": "pollen-reachy",
      "typeId": "type1",
      "manufacturer": "Pollen Robotics",
      "name": "Reachy 2",
      "country": "France",
      "overview": "Purpose: To democratize expressive physical AI through an affordable, fully open-source humanoid platform â€” enabling developers, researchers, educators, and creators to prototype affective, non-verbal interactions, social robotics experiments, and emotional companionship in real-world settings; emphasizes natural, lively presence over task performance. At CES 2026, Pollen Robotics demonstrated Reachy 2 with significant upgrades: improved neck/head mobility (7 DoF for fluid gaze/head tilts), high-res OLED eyes for rich micro-expressions (blinking, squinting, joyful sparkles, sad droop), animated antennas that act as 'emotional ears' (perking up, drooping, wagging), soft silicone-covered arms with tendon-driven actuation for gentle, organic movements, built-in microphones/speakers, and ROS2-based open-source stack for easy customization. Live demos focused on pure non-verbal expressivity: Reachy 'listening' with curious head tilt + perked antennas, 'excited' waving with sparkling eyes, 'shy' antenna droop + slow blink, 'breathing' subtle chest rise. No voice used in main demo â€” all emotion through body language, gaze, and antenna behavior. Fully open hardware/software (CAD files, firmware, Python SDK), priced ~â‚¬4,500â€“â‚¬6,000 for full kit.\n\n[KR] ì œí’ˆì˜ ëª©ì : ì €ë ´í•˜ê³  ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤ íœ´ë¨¸ë…¸ì´ë“œ í”Œë«í¼ìœ¼ë¡œ í‘œí˜„ë ¥ ìˆëŠ” Physical AI ëŒ€ì¤‘í™” â€” ê°œë°œìÂ·ì—°êµ¬ìÂ·êµìœ¡ìÂ·í¬ë¦¬ì—ì´í„°ê°€ affectiveÂ·ë¹„ì–¸ì–´ ìƒí˜¸ì‘ìš©, ì†Œì…œ ë¡œë³´í‹±ìŠ¤ ì‹¤í—˜, ê°ì • ì»´íŒ¨ë‹ˆì–¸ì‹­ ì‹¤ì„¸ê³„ í”„ë¡œí† íƒ€ì´í•‘ ê°€ëŠ¥; ì‘ì—… ìˆ˜í–‰ë³´ë‹¤ ìì—°ìŠ¤ëŸ½ê³  ìƒë™ê° ìˆëŠ” ì¡´ì¬ê° ì´ˆì . ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ Pollen RoboticsëŠ” Reachy 2 ì—…ê·¸ë ˆì´ë“œ ì‹œì—°: í–¥ìƒëœ ëª©/í—¤ë“œ ëª¨ë¹Œë¦¬í‹°(7 DoFë¡œ ìœ ì—° ì‹œì„ Â·í—¤ë“œ í‹¸íŠ¸), í’ë¶€ ë§ˆì´í¬ë¡œ í‘œí˜„ìš© ê³ í•´ìƒë„ OLED ëˆˆ(ê¹œë°•ì„Â·ëˆˆ ì°¡ê¸‹Â·ê¸°ì¨ ë°˜ì§ì„Â·ìŠ¬í”ˆ ì²˜ì§), 'ê°ì • ê·€' ì—­í•  ì• ë‹ˆë©”ì´ì…˜ ì•ˆí…Œë‚˜(ì«‘ê¸‹Â·ì²˜ì§Â·í”ë“¤ë¦¼), ë¶€ë“œëŸ½ê³  ìœ ê¸°ì  ì›€ì§ì„ì„ ìœ„í•œ í…ë˜ êµ¬ë™ ì‹¤ë¦¬ì½˜ ì»¤ë²„ ì•”, ë‚´ì¥ ë§ˆì´í¬/ìŠ¤í”¼ì»¤, ROS2 ê¸°ë°˜ ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤ ìŠ¤íƒ. ë¼ì´ë¸Œ ë°ëª¨ ìˆœìˆ˜ ë¹„ì–¸ì–´ í‘œí˜„ì„± ì§‘ì¤‘: í˜¸ê¸°ì‹¬ í—¤ë“œ í‹¸íŠ¸ + ì«‘ê¸‹ ì•ˆí…Œë‚˜ë¡œ 'ê²½ì²­', ë°˜ì§ì´ëŠ” ëˆˆ + ì† í”ë“¤ê¸°ë¡œ 'í¥ë¶„', ì²˜ì§„ ì•ˆí…Œë‚˜ + ëŠë¦° ê¹œë°•ì„ìœ¼ë¡œ 'ìˆ˜ì¤ìŒ', ë¯¸ì„¸ í‰ë¶€ ìƒìŠ¹ìœ¼ë¡œ 'í˜¸í¡'. ë©”ì¸ ë°ëª¨ì—ì„œ ìŒì„± ì‚¬ìš© ì•ˆ í•¨ â€” ì „ë¶€ ë°”ë”” ë­ê·€ì§€Â·ì‹œì„ Â·ì•ˆí…Œë‚˜ í–‰ë™ìœ¼ë¡œ ê°ì • ì „ë‹¬. í•˜ë“œì›¨ì–´/ì†Œí”„íŠ¸ì›¨ì–´ ì™„ì „ ì˜¤í”ˆ(CAD íŒŒì¼Â·íŒì›¨ì–´Â·Python SDK), í’€ í‚¤íŠ¸ ì•½ â‚¬4,500~â‚¬6,000.",
      "analysis": {
        "intro": "Open Expressive Physical AI\n[KR] ì˜¤í”ˆ í‘œí˜„ Physical AI",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Reachy 2 exemplifies 'open expressive Physical AI' â€” prioritizing non-verbal emotional legibility through minimal yet highly tunable hardware (antennas, eyes, soft arms) and full open-source accessibility. Its focus on curiosity, playfulness, and subtle social cues demonstrates how Physical AI can create 'lived' companionship through organic, developer-extensible behaviors rather than proprietary black-box systems. This aligns perfectly with our project's emphasis on 'continuous,' 'lived,' and 'physical' presence, showing that affective depth thrives on transparency, customizability, and natural micro-expressions.\n\n[KR] Reachy 2ëŠ” 'ì˜¤í”ˆ í‘œí˜„ Physical AI' ì „í˜• â€” ìµœì†Œì§€ë§Œ ê³ ë„ë¡œ íŠœë‹ ê°€ëŠ¥í•œ í•˜ë“œì›¨ì–´(ì•ˆí…Œë‚˜Â·ëˆˆÂ·ì†Œí”„íŠ¸ ì•”)ì™€ ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤ ì ‘ê·¼ì„±ìœ¼ë¡œ ë¹„ì–¸ì–´ ê°ì • ê°€ë…ì„± ìµœìš°ì„ . í˜¸ê¸°ì‹¬Â·ì¥ë‚œÂ·ë¯¸ë¬˜ ì‚¬íšŒì  ì‹ í˜¸ ì´ˆì ìœ¼ë¡œ Physical AIê°€ ë…ì  ë¸”ë™ë°•ìŠ¤ ì•„ë‹Œ ìœ ê¸°ì Â·ê°œë°œì í™•ì¥ ê°€ëŠ¥ í–‰ë™ í†µí•´ 'lived' ì»´íŒ¨ë‹ˆì–¸ì‹­ ì°½ì¶œ ê°€ëŠ¥ì„± ì¦ëª…. ì´ëŠ” ìš°ë¦¬ í”„ë¡œì íŠ¸ì˜ 'continuous'Â·'lived'Â·'physical' ì¡´ì¬ê° ê°•ì¡°ì™€ ì™„ë²½ ì •ë ¬, affective ê¹Šì´ê°€ íˆ¬ëª…ì„±Â·ì»¤ìŠ¤í„°ë§ˆì´ì§•Â·ìì—° ë§ˆì´í¬ë¡œ í‘œí˜„ì—ì„œ ë‚˜ì˜¨ë‹¤ëŠ” êµí›ˆ.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Reachy 2 is one of the cleanest, most inspiring references for our entire Expression System â€” a textbook example of how minimal, tunable non-verbal elements can generate profound emotional resonance. Core principles: Animated antennas as 'emotional ears' (perking = curiosity, drooping = sadness, wagging = excitement) prove simple appendage-like elements can serve as powerful social signaling tools; high-res OLED eyes + micro-expressions create rich empathy peak through blinking patterns, gaze direction, sparkles/droops; soft tendon-driven arms + gentle breathing deliver fluid, organic motion for agency and mood temperature; open-source extensibility allows behaviors to evolve via community input. For our targets (Movable TV/Tabletop): add 'emotional antenna/ear' kinetic appendages for curiosity/perk-up cues and playful social signaling; use circular high-res OLED or transparent display for Reachy-style expressive eyes as primary empathy peak; implement soft, tendon-like kinetic joints for fluid, organic movements synced with ambient lighting breathing pulses; design open-ended expression framework for evolving micro-behaviors over time, embodying attachment and continuous relationship growth.\n\n[KR] Reachy 2ëŠ” ìš°ë¦¬ ì „ì²´ Expression Systemì˜ ê°€ì¥ ê¹”ë”í•˜ê³  ì˜ê° ë„˜ì¹˜ëŠ” ì°¸ì¡° â€” ìµœì†ŒÂ·íŠœë‹ ê°€ëŠ¥í•œ ë¹„ì–¸ì–´ ìš”ì†Œë¡œ ê¹Šì€ ê°ì • ê³µëª…ì„ ì°½ì¶œí•˜ëŠ” êµê³¼ì„œì  ì‚¬ë¡€. í•µì‹¬ ì›ì¹™: ì• ë‹ˆë©”ì´ì…˜ ì•ˆí…Œë‚˜ 'ê°ì • ê·€'(í˜¸ê¸°ì‹¬ ì«‘ê¸‹Â·ìŠ¬í”” ì²˜ì§Â·í¥ë¶„ í”ë“¤ë¦¼)ë¡œ ê°•ë ¥ social signaling ê°€ëŠ¥ ì¦ëª…; ê³ í•´ìƒë„ OLED ëˆˆ + ë§ˆì´í¬ë¡œ í‘œí˜„ìœ¼ë¡œ í’ë¶€ empathy peak; ì†Œí”„íŠ¸ í…ë˜ ì•” + gentle í˜¸í¡ìœ¼ë¡œ ìœ ì—° ìœ ê¸°ì  ëª¨ì…˜; ì˜¤í”ˆì†ŒìŠ¤ í™•ì¥ì„±ìœ¼ë¡œ ì»¤ë®¤ë‹ˆí‹° ì…ë ¥ í†µí•´ í–‰ë™ ì§„í™”. ìš°ë¦¬ íƒ€ê²Ÿ(ë¬´ë¹™ TV/í…Œì´ë¸”íƒ‘) ì ìš©: í˜¸ê¸°ì‹¬ ì«‘ê¸‹Â·ì¥ë‚œ social signaling ìœ„í•œ 'ê°ì • ì•ˆí…Œë‚˜/ê·€' ëª¨ë“ˆí˜• í‚¤ë„¤í‹± ë¶€ì†ë¬¼; ì›í˜• ê³ í•´ìƒë„ OLEDë¡œ Reachy ìŠ¤íƒ€ì¼ í‘œí˜„ ëˆˆ empathy peak í•µì‹¬; ì†Œí”„íŠ¸ í…ë˜-like í‚¤ë„¤í‹± ì¡°ì¸íŠ¸ + ambient lighting breathing í„ìŠ¤ ë™ê¸°í™”; ì¥ê¸° ê´€ê³„ ì„±ì¥ ìœ„í•œ ì˜¤í”ˆ ì—”ë””ë“œ í‘œí˜„ í”„ë ˆì„ì›Œí¬ ì„¤ê³„.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/pollen-reachy/pollen-reachy_1.png",
        "/images/products/pollen-reachy/pollen-reachy_2.png"
      ],
      "videoUrl": ""
    },
    {
      "id": "fourier-gr1",
      "typeId": "type1",
      "manufacturer": "Fourier Intelligence",
      "name": "GR-1",
      "country": "China",
      "overview": "A rehabilitation-focused humanoid that applies medical exoskeleton technology to a full-body autonomous form.\n\n[KR] ì˜ë£Œìš© ì™¸ê³¨ê²© ê¸°ìˆ ì„ ì „ì‹  ììœ¨ í˜•íƒœì— ì ìš©í•œ ì¬í™œ ì¤‘ì‹¬ íœ´ë¨¸ë…¸ì´ë“œì…ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Medical Heritage\n[KR] ì˜ë£Œ ê¸°ìˆ ì˜ ìœ ì‚°",
        "points": [
          {
            "title": "Assistive Strength",
            "content": "Capable of supporting human weight for transfer tasks (bed to wheelchair) with medical-grade safety constraints.\n\n[KR] ì˜ë£Œ ë“±ê¸‰ì˜ ì•ˆì „ ì œì•½ ì¡°ê±´ í•˜ì— í™˜ì ì´ì†¡(ì¹¨ëŒ€ì—ì„œ íœ ì²´ì–´ë¡œ) ë“± ì¸ê°„ì˜ ì²´ì¤‘ì„ ì§€íƒ±í•  ìˆ˜ ìˆëŠ” í˜ì„ ê°–ì·„ìŠµë‹ˆë‹¤."
          },
          {
            "title": "Force Transparency",
            "content": "The joints can become compliant, allowing humans to guide the robot's limbs easily for teaching or positioning.\n\n[KR] ê´€ì ˆì˜ ìœ ì—°ì„±ì„ ë†’ì—¬ ì¸ê°„ì´ ë¡œë´‡ì˜ íŒ”ë‹¤ë¦¬ë¥¼ ì‰½ê²Œ ì›€ì§ì—¬ ë™ì‘ì„ ê°€ë¥´ì¹˜ê±°ë‚˜ ìœ„ì¹˜ë¥¼ ì¡ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/fourier-gr1/fourier-gr1_1.webp"
      ],
      "videoUrl": ""
    },
    {
      "id": "wirobotics-allex",
      "typeId": "type1",
      "manufacturer": "WIRobotics",
      "name": "ALLEX",
      "country": "South Korea",
      "overview": "Born from wearable robotics expertise, ALLEX focuses on human-robot synergy and gait assistance patterns applied to autonomous locomotion.\n\n[KR] ì›¨ì–´ëŸ¬ë¸” ë¡œë´‡ ê¸°ìˆ ì˜ ë…¸í•˜ìš°ì—ì„œ íƒ„ìƒí•œ ALLEXëŠ” ì¸ê°„-ë¡œë´‡ ì‹œë„ˆì§€ì™€ ë³´í–‰ ë³´ì¡° íŒ¨í„´ì„ ììœ¨ ì´ë™ì— ì ìš©í–ˆìŠµë‹ˆë‹¤.",
      "analysis": {
        "intro": "Synergistic Motion\n[KR] ì‹œë„ˆì§€ ì›€ì§ì„",
        "points": [
          {
            "title": "Biomimetic Gait",
            "content": "Walking patterns are derived from human gait analysis, appearing natural and non-threatening in crowds.\n\n[KR] ì¸ê°„ ë³´í–‰ ë¶„ì„ì—ì„œ ë„ì¶œëœ ê±·ê¸° íŒ¨í„´ì€ êµ°ì¤‘ ì†ì—ì„œë„ ìì—°ìŠ¤ëŸ½ê³  ìœ„í˜‘ì ì´ì§€ ì•Šê²Œ ë³´ì…ë‹ˆë‹¤."
          },
          {
            "title": "Lightweight Frame",
            "content": "Utilizes hollow-structure design for extreme lightness, making it safer for accidental collisions.\n\n[KR] ì¤‘ê³µ êµ¬ì¡° ì„¤ê³„ë¥¼ í†µí•´ ê·¹ë„ë¡œ ê°€ë²¼ìš´ ë¬´ê²Œë¥¼ êµ¬í˜„, ì¶©ëŒ ì‚¬ê³  ì‹œì—ë„ ì•ˆì „í•©ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/wirobotics-allex/wirobotics-allex_1.webp"
      ],
      "videoUrl": ""
    },
    {
      "id": "keenon-xman",
      "typeId": "type1",
      "manufacturer": "Keenon Robotics",
      "name": "XMAN-R1",
      "country": "China",
      "overview": "A dedicated hospitality humanoid designed to navigate tight restaurant aisles and interact with diners with polished etiquette.\n\n[KR] ì¢ì€ ë ˆìŠ¤í† ë‘ í†µë¡œë¥¼ ì´ë™í•˜ë©° ì„¸ë ¨ëœ ë§¤ë„ˆë¡œ ì‹ì‚¬ê°ê³¼ ìƒí˜¸ì‘ìš©í•˜ë„ë¡ ì„¤ê³„ëœ ì ‘ê° ì „ìš© íœ´ë¨¸ë…¸ì´ë“œì…ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Service Etiquette\n[KR] ì„œë¹„ìŠ¤ ì—í‹°ì¼“",
        "points": [
          {
            "title": "Tray Stability",
            "content": "Active stabilization keeps fluids in glasses perfectly still even during rapid turns or stops.\n\n[KR] ëŠ¥ë™í˜• ì•ˆì •í™” ê¸°ìˆ ì€ ê¸‰íšŒì „ì´ë‚˜ ì •ì§€ ì¤‘ì—ë„ ìœ ë¦¬ì”ì˜ ì•¡ì²´ë¥¼ ì™„ë²½í•˜ê²Œ ê³ ìš”í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤."
          },
          {
            "title": "Bowing Mechanics",
            "content": "Incorporates varying degrees of bowing to respect cultural norms in hospitality.\n\n[KR] ì ‘ê° ë¬¸í™”ì˜ ê·œë²”ì„ ì¡´ì¤‘í•˜ê¸° ìœ„í•´ ìƒí™©ì— ë”°ë¼ ë‹¤ì–‘í•œ ê°ë„ì˜ ì¸ì‚¬ ë™ì‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/keenon-xman/keenon-xman_1.webp"
      ],
      "videoUrl": ""
    },
    {
      "id": "agibot-expedition",
      "typeId": "type1",
      "manufacturer": "Agibot",
      "name": "Expedition A2",
      "country": "China",
      "overview": "Agibot's Expedition A2 is designed for dynamic exploration with bipedal agility suitable for uneven terrain.\n\n[KR] Agibotì˜ Expedition A2ëŠ” ê³ ë¥´ì§€ ì•Šì€ ì§€í˜•ì— ì í•©í•œ ì´ì¡± ë³´í–‰ ë¯¼ì²©ì„±ì„ ê°–ì¶˜ ë™ì  íƒì‚¬ë¥¼ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.",
      "analysis": {
        "intro": "Terrain Adaptation\n[KR] ì§€í˜• ì ì‘",
        "points": [
          {
            "title": "Ankle Compliance",
            "content": "Advanced ankle joints adjust to micro-variations in ground level, ensuring stability without slowing down.\n\n[KR] ê³ ê¸‰ ë°œëª© ê´€ì ˆì€ ì§€ë©´ ë†’ì´ì˜ ë¯¸ì„¸í•œ ë³€í™”ì— ë§ì¶° ì¡°ì •ë˜ì–´ ì†ë„ë¥¼ ëŠ¦ì¶”ì§€ ì•Šê³ ë„ ì•ˆì •ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤."
          },
          {
            "title": "Gait Transition",
            "content": "Seamlessly switches between walking and running modes based on urgency and terrain complexity.\n\n[KR] ê¸´ê¸‰ì„±ê³¼ ì§€í˜• ë³µì¡ì„±ì— ë”°ë¼ ê±·ê¸° ëª¨ë“œì™€ ë‹¬ë¦¬ê¸° ëª¨ë“œë¥¼ ë§¤ë„ëŸ½ê²Œ ì „í™˜í•©ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/agibot-expedition/agibot-expedition_1.png"
      ],
      "videoUrl": ""
    },
    {
      "id": "ubtech-walker-s2",
      "typeId": "type1",
      "manufacturer": "UBTECH",
      "name": "Walker S2",
      "country": "China",
      "overview": "An industrial-grade humanoid optimized for the automotive assembly line, Walker S2 demonstrates high-precision handling and quality inspection capabilities.\n\n[KR] ìë™ì°¨ ì¡°ë¦½ ë¼ì¸ì— ìµœì í™”ëœ ì‚°ì—…ìš© íœ´ë¨¸ë…¸ì´ë“œ Walker S2ëŠ” ì •ë°€ í•¸ë“¤ë§ ë° í’ˆì§ˆ ê²€ì‚¬ ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Line Precision\n[KR] ë¼ì¸ ì •ë°€ë„",
        "points": [
          {
            "title": "Soft Manipulation",
            "content": "Visual-tactile feedback allows it to handle delicate car parts (like logos or soft trim) without scratching.\n\n[KR] ì‹œê°-ì´‰ê° í”¼ë“œë°±ì„ í†µí•´ ë¡œê³ ë‚˜ ë¶€ë“œëŸ¬ìš´ ë‚´ì¥ì¬ ê°™ì€ ì„¬ì„¸í•œ ìë™ì°¨ ë¶€í’ˆì„ ê¸í˜ ì—†ì´ ë‹¤ë£° ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          },
          {
            "title": "Synchronized Cycle",
            "content": "Works in perfect sync with conveyor belts, adapting its speed to the line pace autonomously.\n\n[KR] ì»¨ë² ì´ì–´ ë²¨íŠ¸ì™€ ì™„ë²½í•˜ê²Œ ë™ê¸°í™”ë˜ì–´ ë¼ì¸ ì†ë„ì— ë§ì¶° ìŠ¤ìŠ¤ë¡œ ì†ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/ubtech-walker-s2/ubtech-walker-s2_1.webp"
      ],
      "videoUrl": ""
    },
    {
      "id": "mentee-bot",
      "typeId": "type1",
      "manufacturer": "Mentee Robotics",
      "name": "Mentee Bot",
      "country": "Israel",
      "overview": "An AI-first humanoid that uses end-to-end learning for all its tasks, moving away from hard-coded control logic.\n\n[KR] í•˜ë“œ ì½”ë”©ëœ ì œì–´ ë…¼ë¦¬ì—ì„œ ë²—ì–´ë‚˜ ëª¨ë“  ì‘ì—…ì— ì—”ë“œ íˆ¬ ì—”ë“œ í•™ìŠµì„ ì‚¬ìš©í•˜ëŠ” AI ìš°ì„  ë¡œë´‡ì…ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Pure Learning\n[KR] ìˆœìˆ˜ í•™ìŠµ",
        "points": [
          {
            "title": "Sim-to-Real Transfer",
            "content": "Trained almost entirely in simulation, its movements have a unique 'organic' quality distinct from traditional robotic programming.\n\n[KR] ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ê±°ì˜ ì „ì ìœ¼ë¡œ í›ˆë ¨ëœ ì›€ì§ì„ì€ ì „í†µì ì¸ ë¡œë´‡ í”„ë¡œê·¸ë˜ë°ê³¼ëŠ” ë‹¤ë¥¸ ë…íŠ¹í•œ 'ìœ ê¸°ì ' íŠ¹ì§•ì„ ê°€ì§‘ë‹ˆë‹¤."
          },
          {
            "title": "Instant Imitation",
            "content": "Can learn new tasks by watching a human perform them once, drastically reducing setup time.\n\n[KR] ì¸ê°„ì´ ìˆ˜í–‰í•˜ëŠ” ê²ƒì„ í•œ ë²ˆ ë³´ëŠ” ê²ƒë§Œìœ¼ë¡œ ìƒˆë¡œìš´ ì‘ì—…ì„ ë°°ìš¸ ìˆ˜ ìˆì–´ ì„¤ì • ì‹œê°„ì„ íšê¸°ì ìœ¼ë¡œ ì¤„ì—¬ì¤ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/mentee-bot/mentee-bot_1.webp"
      ],
      "videoUrl": ""
    },
    {
      "id": "galbot",
      "typeId": "type1",
      "manufacturer": "Galbot",
      "name": "Galbot",
      "country": "China",
      "overview": "A humanoid focused on dexterous dual-arm manipulation for home and retail environments.\n\n[KR] ê°€ì • ë° ì†Œë§¤ í™˜ê²½ì„ ìœ„í•œ ì–‘íŒ”ì˜ ì •êµí•œ ì¡°ì‘ ëŠ¥ë ¥ì— ì´ˆì ì„ ë§ì¶˜ íœ´ë¨¸ë…¸ì´ë“œì…ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Dual-Arm Synergy\n[KR] ì–‘íŒ” ì‹œë„ˆì§€",
        "points": [
          {
            "title": "Bimanual Coordination",
            "content": "Coordinating two hands for complex tasks like folding clothes or opening capped bottles with human-like fluidity.\n\n[KR] ì˜·ì„ ê°œê±°ë‚˜ ëšœê»‘ ìˆëŠ” ë³‘ì„ ì—¬ëŠ” ê²ƒê³¼ ê°™ì€ ë³µì¡í•œ ì‘ì—…ì„ ìœ„í•´ ë‘ ì†ì„ ì¸ê°„ì²˜ëŸ¼ ìœ ì—°í•˜ê²Œ ì¡°ì •í•©ë‹ˆë‹¤."
          },
          {
            "title": "Reach Optimization",
            "content": "The torso rotates and extends to maximize reach without moving the feet, ideal for cluttered kitchens.\n\n[KR] ë°œì„ ì›€ì§ì´ì§€ ì•Šê³ ë„ ëª¸í†µì„ íšŒì „í•˜ê³  í™•ì¥í•˜ì—¬ ë„ë‹¬ ë²”ìœ„ë¥¼ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆì–´, ë³µì¡í•œ ì£¼ë°©ì— ì´ìƒì ì…ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/galbot/galbot_1.webp"
      ],
      "videoUrl": ""
    },
    {
      "id": "engineai-t800",
      "typeId": "type1",
      "manufacturer": "ENGINEAI Robotics Technology Co., Ltd.",
      "name": "ENGINEAI T800",
      "country": "China",
      "overview": "Purpose: To serve as a high-performance, deployable universal humanoid platform for real-world industrial, commercial, and high-dynamic applications â€” emphasizing exceptional torque, stability, and full-body coordination for tasks requiring strength, speed, and precision (e.g., manufacturing, logistics, potential future service/combat demos); positioned as a 'born to disrupt' system bridging lab demos to scalable production. At CES 2026, ENGINEAI showcased the T800 as a ~173 cm tall, high-efficiency humanoid with 29+ degrees of freedom (high-DoF joints in neck/waist/hands), peak torque up to 450 NÂ·m per joint, instantaneous power 14 kW, active cooling in legs, and integrated perception (360Â° omnidirectional). Live demos highlighted industry-leading dynamic output: martial arts kicks (viral CEO-kick video), running, high-speed stability, heavy load handling. No rigid scripted motions â€” emphasis on real-time adaptability in high-dynamic scenarios. Mass production ramp-up announced, first shipments mid-2026 (starting ~$25,000 est.), targeting industrial/commercial customers.\n\n[KR] ì œí’ˆì˜ ëª©ì : ì‹¤ì„¸ê³„ ì‚°ì—…Â·ìƒì—…Â·ê³ ë™ì  ì• í”Œë¦¬ì¼€ì´ì…˜ ìœ„í•œ ê³ ì„±ëŠ¥ ë°°í¬ ê°€ëŠ¥ ë²”ìš© íœ´ë¨¸ë…¸ì´ë“œ í”Œë«í¼ â€” ê°•ë„Â·ì†ë„Â·ì •ë°€ ìš”êµ¬ ì‘ì—…(ì œì¡°Â·ë¬¼ë¥˜, ì ì¬ ì„œë¹„ìŠ¤/ì „íˆ¬ ë°ëª¨) ìœ„í•œ íƒì›” í† í¬Â·ì•ˆì •ì„±Â·ì „ì‹  ì½”ë””ë„¤ì´ì…˜ ê°•ì¡°; 'born to disrupt' ì‹œìŠ¤í…œìœ¼ë¡œ ë© ë°ëª¨ì—ì„œ ëŒ€ëŸ‰ ìƒì‚°ìœ¼ë¡œ ì—°ê²°. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ ~173cm ë†’ì´ ê³ íš¨ìœ¨ íœ´ë¨¸ë…¸ì´ë“œ T800 ì‹œì—° â€” ëª©/í—ˆë¦¬/ì† ê³ DoF ê´€ì ˆ(29+ ììœ ë„), ê´€ì ˆë‹¹ ìµœëŒ€ í† í¬ 450 NÂ·m, ìˆœê°„ ì¶œë ¥ 14 kW, ë ˆê·¸ ì•¡í‹°ë¸Œ ì¿¨ë§, 360Â° ì „ë°©í–¥ í¼ì…‰ì…˜ í†µí•©. ë¼ì´ë¸Œ ë°ëª¨ ì‚°ì—… ìµœê³  ë™ì  ì¶œë ¥ ê°•ì¡°: ë¬´ìˆ  í‚¥(CEO í‚¥ ë°”ì´ëŸ´ ë¹„ë””ì˜¤), ëŸ¬ë‹, ê³ ì† ì•ˆì •ì„±, ë¬´ê±°ìš´ ë¡œë“œ í•¸ë“¤ë§. ê²½ì§ ìŠ¤í¬ë¦½íŠ¸ ëª¨ì…˜ ì—†ìŒ â€” ê³ ë™ì  ì‹œë‚˜ë¦¬ì˜¤ ì‹¤ì‹œê°„ ì ì‘ ì¤‘ì . ëŒ€ëŸ‰ ìƒì‚° ë¨í”„ì—… ë°œí‘œ, 2026ë…„ ì¤‘ìˆœ ì²« ì¶œí•˜(ì¶”ì • ~$25,000 ì‹œì‘), ì‚°ì—…/ìƒì—… ê³ ê° íƒ€ê²Ÿ.",
      "analysis": {
        "intro": "High-Dynamic Embodied Physical AI\n[KR] ê³ ë™ì  ì²´í™” Physical AI",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "T800 exemplifies 'high-dynamic embodied Physical AI' for practical deployment â€” combining extreme torque/power with full-body coordination to handle unstructured, high-force tasks reliably. Its viral real-world demos (CEO kick, no CGI) and mass-production roadmap highlight the shift from spectacle to scalable 'lived' workforce integration, prioritizing predictability, stability, and safety in continuous operation. This reinforces Physical AI's transition toward industrial 'continuous' and 'physical' reliability over lab novelty.\n\n[KR] T800ì€ ì‹¤ìš© ë°°í¬ ìœ„í•œ 'ê³ ë™ì  ì²´í™” Physical AI' ì „í˜• â€” ê·¹í•œ í† í¬/íŒŒì›Œì™€ ì „ì‹  ì½”ë””ë„¤ì´ì…˜ ê²°í•©ìœ¼ë¡œ ë¹„êµ¬ì¡°Â·ê³ ë ¥ ì‘ì—… ì•ˆì • ì²˜ë¦¬. ë°”ì´ëŸ´ ì‹¤ì„¸ê³„ ë°ëª¨(CEO í‚¥, no CGI)ì™€ ëŒ€ëŸ‰ ìƒì‚° ë¡œë“œë§µì€ spectacleì—ì„œ í™•ì¥ ê°€ëŠ¥í•œ 'lived' ì›Œí¬í¬ìŠ¤ í†µí•©ìœ¼ë¡œ ì „í™˜ ê°•ì¡°, ì§€ì† ìš´ì˜ì—ì„œ predictabilityÂ·stabilityÂ·safety ìš°ì„ . Physical AIê°€ ë© ì‹ ê¸°í•¨ì—ì„œ ì‚°ì—… 'continuous'Â·'physical' ì‹ ë¢°ì„±ìœ¼ë¡œ ì´ë™í•˜ëŠ” ê³¼ì • ê°•í™”.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "While T800 is task-dominant and industrial-focused, its non-verbal expressivity shines in Layer 2 (Motion & Physical Behavior) through ultra-precise, high-torque yet controlled dynamics â€” deliberate slowing/pose stabilization before actions conveys safety legibility and predictability, building implicit trust in shared physical spaces. The absence of face/display yet powerful 'aliveness' from fluid whole-body motion proves high-fidelity kinetics alone can establish agency and emotional baseline in high-stakes contexts. For our targets (Movable TV/Tabletop): adopt high-precision, controlled kinetic trajectories (slow ramp-up/down, deliberate pose holds) for agency and safety legibility; sync ambient lighting with motion intensity for mood temperature reinforcement; use restrained pause/stabilize micro-behaviors before/after interactions as non-verbal empathy cues; emphasize predictable recovery/stability in dynamic motion to embody predictability â†’ trust and uninterrupted state.\n\n[KR] T800ì€ ì‘ì—… ì¤‘ì‹¬ ì‚°ì—… ì´ˆì ì´ì§€ë§Œ ë¹„ì–¸ì–´ í‘œí˜„ì„±ì€ Layer 2(Motion & Physical Behavior)ì—ì„œ ë¹›ë‚¨ â€” ì´ˆì •ë°€Â·ê³ í† í¬ì§€ë§Œ ì œì–´ëœ ë™ì  ì›€ì§ì„ìœ¼ë¡œ í–‰ë™ ì „ ì˜ë„ì  ê°ì†/í¬ì¦ˆ ì•ˆì •í™” í†µí•´ ë§ ì—†ì´ safety legibilityÂ·predictability ì „ë‹¬, ê³µìœ  ë¬¼ë¦¬ ê³µê°„ì—ì„œ ì•”ë¬µì  ì‹ ë¢° êµ¬ì¶•. ì–¼êµ´/ë””ìŠ¤í”Œë ˆì´ ì—†ì–´ë„ ìœ ì—° ì „ì‹  ëª¨ì…˜ìœ¼ë¡œ ê°•í•œ 'ì‚´ì•„ìˆìŒ' â†’ ê³ ìœ„í—˜ ë§¥ë½ì—ì„œ í‚¤ë„¤í‹±ë§Œìœ¼ë¡œ agencyÂ·emotional baseline ìˆ˜ë¦½ ê°€ëŠ¥ì„± ì¦ëª…. ìš°ë¦¬ íƒ€ê²Ÿ(ë¬´ë¹™ TV/í…Œì´ë¸”íƒ‘) ì ìš©: ê³ ì •ë°€ ì œì–´ í‚¤ë„¤í‹± ê¶¤ì (ëŠë¦° ë¨í”„ ì—…/ë‹¤ìš´, ì˜ë„ì  í¬ì¦ˆ í™€ë“œ)ìœ¼ë¡œ agencyÂ·safety legibility; ëª¨ì…˜ ê°•ë„ ì—°ë™ ambient lightingìœ¼ë¡œ mood temperature ê°•í™”; ìƒí˜¸ì‘ìš© ì „/í›„ restrained pause/stabilize ë§ˆì´í¬ë¡œ í–‰ë™ìœ¼ë¡œ ë¹„ì–¸ì–´ empathy cues; ë™ì  ëª¨ì…˜ì—ì„œ ì˜ˆì¸¡ ê°€ëŠ¥ íšŒë³µ/ì•ˆì •ì„± ê°•ì¡°ë¡œ predictability â†’ trustÂ·uninterrupted state ì²´í˜„.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/engineai-t800/engineai-t800_1.png",
        "/images/products/engineai-t800/engineai-t800_2.png",
        "/images/products/engineai-t800/engineai-t800_3.png"
      ],
      "videoUrl": ""
    },
    {
      "id": "realbotix",
      "typeId": "type1",
      "manufacturer": "Realbotix Corp. (TSX-V: XBOT)",
      "name": "Aria & David",
      "country": "USA",
      "overview": "Purpose: To provide lifelike companionship, emotional engagement, entertainment, and customer service through highly realistic human-robot interaction; designed for long-term relational bonding and personalized social experiences. At CES 2026, Realbotix demonstrated multiple hyper-realistic humanoid robots including female model Aria and new male model David. The highlight was the first public fully autonomous, unscripted, embedded AI conversation between two physical robots (Aria and David) lasting over two hours, conducted in multiple languages (English, Spanish, French, German) without human intervention, scripting, or teleoperation. Robots feature patented silicone skin technology for lifelike appearance, advanced facial actuators for micro-expressions, gesture recognition, voice interaction via the 'Ask Aria' platform, and modular customization (appearance, personality, historical/celebrity replication). Live demos emphasized natural turn-taking, emotional responsiveness, and sustained presence.\n\n[KR] ì œí’ˆì˜ ëª©ì : ì´ˆí˜„ì‹¤ì  ì¸ê°„-ë¡œë´‡ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ìƒìƒí•œ ë™ë°˜ì ê´€ê³„, ê°ì •ì  ëª°ì…, ì—”í„°í…Œì¸ë¨¼íŠ¸ ë° ê³ ê° ì„œë¹„ìŠ¤ ì œê³µ; ì¥ê¸°ì  ê´€ê³„ í˜•ì„±ê³¼ ê°œì¸í™”ëœ ì‚¬íšŒì  ê²½í—˜ ì„¤ê³„. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ RealbotixëŠ” ì—¬ì„± ëª¨ë¸ Ariaì™€ ì‹ ê·œ ë‚¨ì„± ëª¨ë¸ Davidë¥¼ í¬í•¨í•œ ë‹¤ìˆ˜ì˜ ì´ˆí˜„ì‹¤ì  íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì„ ì‹œì—°. ìµœëŒ€ í•˜ì´ë¼ì´íŠ¸ëŠ” ë‘ ë¬¼ë¦¬ì  ë¡œë´‡(Ariaì™€ David) ê°„ ì™„ì „ ììœ¨ì Â·ë¹„ìŠ¤í¬ë¦½íŠ¸ embedded AI ëŒ€í™”ë¡œ, ì¸ê°„ ê°œì…Â·ìŠ¤í¬ë¦½íŠ¸Â·ì›ê²© ì¡°ì‘ ì—†ì´ 2ì‹œê°„ ì´ìƒ ì§€ì†ë˜ë©° ë‹¤êµ­ì–´(ì˜ì–´, ìŠ¤í˜ì¸ì–´, í”„ë‘ìŠ¤ì–´, ë…ì¼ì–´)ë¡œ ì§„í–‰. íŠ¹í—ˆ ì‹¤ë¦¬ì½˜ ìŠ¤í‚¨ ê¸°ìˆ ë¡œ ìƒìƒí•œ ì™¸í˜• êµ¬í˜„, ë§ˆì´í¬ë¡œ í‘œí˜„ì„ ìœ„í•œ ê³ ê¸‰ ì–¼êµ´ ì•¡ì¶”ì—ì´í„°, ì œìŠ¤ì²˜ ì¸ì‹, \"Ask Aria\" í”Œë«í¼ ê¸°ë°˜ ìŒì„± ìƒí˜¸ì‘ìš©, ëª¨ë“ˆëŸ¬ ì»¤ìŠ¤í„°ë§ˆì´ì§•(ì™¸í˜•, ì„±ê²©, ì—­ì‚¬ì /ìœ ëª…ì¸ ë³µì œ) íƒ‘ì¬. ë¼ì´ë¸Œ ë°ëª¨ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í„´í…Œì´í‚¹, ê°ì •ì  ë°˜ì‘ì„±, ì§€ì†ì  ì¡´ì¬ê°ì„ ê°•ì¡°.",
      "analysis": {
        "intro": "Hyper-Realistic Humanoid Companion Robot\n[KR] ì´ˆí˜„ì‹¤ì  íœ´ë¨¸ë…¸ì´ë“œ ì»´íŒ¨ë‹ˆì–¸ ë¡œë´‡",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Realbotix pushes the boundary of 'embodied emotional intelligence' by prioritizing hyper-realistic physical form and on-device AI for prolonged, unscripted interaction. The sustained autonomous conversation demonstrates true contextual continuity and relational depth in Physical AI, moving beyond task-oriented robots toward 'lived' companionship that accumulates trust through repeated, natural micro-interactions. This validates the importance of physical presence for affective bonding in everyday settings.\n\n[KR] RealbotixëŠ” ì´ˆí˜„ì‹¤ì  ë¬¼ë¦¬ì  í˜•íƒœì™€ ì˜¨ë””ë°”ì´ìŠ¤ AIë¥¼ ìš°ì„ í•˜ì—¬ ì¥ê¸°ì Â·ë¹„ìŠ¤í¬ë¦½íŠ¸ ìƒí˜¸ì‘ìš©ì„ ì‹¤í˜„í•¨ìœ¼ë¡œì¨ 'ì²´í™”ëœ ê°ì • ì§€ëŠ¥'ì˜ ê²½ê³„ë¥¼ í™•ì¥. ì§€ì†ì  ììœ¨ ëŒ€í™”ëŠ” Physical AIì˜ ì§„ì •í•œ ë§¥ë½ ì—°ì†ì„±ê³¼ ê´€ê³„ ê¹Šì´ë¥¼ ë³´ì—¬ì£¼ë©°, ì‘ì—… ì¤‘ì‹¬ ë¡œë´‡ì„ ë„˜ì–´ ë°˜ë³µì Â·ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆì´í¬ë¡œ ìƒí˜¸ì‘ìš©ìœ¼ë¡œ ì‹ ë¢°ë¥¼ ì¶•ì í•˜ëŠ” 'lived' ì»´íŒ¨ë‹ˆì–¸ì‹­ìœ¼ë¡œ ì§„í™”. ì¼ìƒ í™˜ê²½ì—ì„œ affective bondingì„ ìœ„í•œ ë¬¼ë¦¬ì  ì¡´ì¬ê°ì˜ ì¤‘ìš”ì„±ì„ ì…ì¦.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Realbotix's strength lies in Layer 3 (Face / Facial Cues) of our Expression System â€” hyper-realistic micro-expressions, eye gaze, and subtle head movements create powerful empathy cues and emotional peak experiences without words. The autonomous turn-taking and gesture responsiveness embody 'turn-taking politeness' and 'agency' in motion, while sustained presence aligns with 'stay' and 'trust over time' roles. For our target form factors (especially Tabletop Display Lamp & Movable TV), we can adapt: synchronized facial/projection cues with kinetic head orientation for intimate 1:1 gaze; subtle ambient lighting changes tied to emotional state for mood temperature; micro-gesture sequences (nodding, tilting) to signal listening/understanding. Critically, their focus on relational depth over utility reminds us to prioritize 'emotional baseline' and 'attachment' through consistent, non-intrusive physical signaling.\n\n[KR] Realbotixì˜ ê°•ì ì€ ìš°ë¦¬ Expression Systemì˜ Layer 3(Face / Facial Cues)ì— ìˆìŒ â€” ì´ˆí˜„ì‹¤ì  ë§ˆì´í¬ë¡œ í‘œí˜„, ì‹œì„ , ë¯¸ì„¸ ë¨¸ë¦¬ ì›€ì§ì„ìœ¼ë¡œ ê°•ë ¥í•œ empathy cuesì™€ emotional peak ê²½í—˜ì„ ë¬´ì–¸ì–´ë¡œ ì°½ì¶œ. ììœ¨ì  í„´í…Œì´í‚¹ê³¼ ì œìŠ¤ì²˜ ë°˜ì‘ì„±ì€ ëª¨ì…˜ì˜ 'turn-taking politeness'ì™€ 'agency'ë¥¼ ì²´í˜„í•˜ë©°, ì§€ì†ì  ì¡´ì¬ê°ì€ 'stay'ì™€ 'trust over time' ì—­í• ê³¼ ë¶€í•©. ìš°ë¦¬ íƒ€ê²Ÿ í¼íŒ©í„°(íŠ¹íˆ í…Œì´ë¸”íƒ‘ ë””ìŠ¤í”Œë ˆì´ ë¨í”„ & ë¬´ë¹™ TV)ì— ì ìš© ì‹œ: í‚¤ë„¤í‹± í—¤ë“œ ë°©í–¥ ì „í™˜ê³¼ ë™ê¸°í™”ëœ ì–¼êµ´/í”„ë¡œì ì…˜ cuesë¡œ ì¹œë°€í•œ 1:1 gaze êµ¬í˜„; ê°ì • ìƒíƒœ ì—°ë™ ë¯¸ì„¸ ambient lighting ë³€í™”ë¡œ mood temperature ì œê³µ; ê²½ì²­/ì´í•´ ì‹ í˜¸ë¥¼ ìœ„í•œ ë§ˆì´í¬ë¡œ ì œìŠ¤ì²˜ ì‹œí€€ìŠ¤(nodding, tilting)ë¡œ companionship ê°•í™” ë° in-between momentsì˜ ì¸ì§€ ë¶€í•˜ ê°ì†Œ. í•µì‹¬ì ìœ¼ë¡œ, ìœ í‹¸ë¦¬í‹°ë³´ë‹¤ ê´€ê³„ ê¹Šì´ë¥¼ ìš°ì„ í•˜ëŠ” ê·¸ë“¤ì˜ ì ‘ê·¼ì€ ì¼ê´€ì Â·ë¹„ì¹¨ìŠµì  ë¬¼ë¦¬ì  ì‹œê·¸ë„ë§ì„ í†µí•´ 'emotional baseline'ê³¼ 'attachment'ì„ ê°•ì¡°í•˜ë¼ëŠ” êµí›ˆ",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/realbotix/realbotix_1.png",
        "/images/products/realbotix/realbotix_2.png"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Realbotix+CES+2026+Aria+David"
    },
    {
      "id": "samsung-ai-oled-bot",
      "typeId": "type2",
      "manufacturer": "Samsung",
      "name": "AI OLED Bot",
      "country": "South Korea",
      "overview": "A circular, rolling robot with a flexible OLED screen that wraps around its body, displaying information in 360 degrees.\n\n[KR] ë³¸ì²´ë¥¼ ê°ì‹¸ëŠ” ìœ ì—°í•œ OLED ìŠ¤í¬ë¦°ì„ ê°–ì¶˜ ì›í˜• êµ¬ë™ ë¡œë´‡ìœ¼ë¡œ, 360ë„ë¡œ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Omni-Display\n[KR] ì˜´ë‹ˆ ë””ìŠ¤í”Œë ˆì´",
        "points": [
          {
            "title": "360 Visibility",
            "content": "Information is visible from any angle, reducing the need to position the robot precisely.\n\n[KR] ì–´ë–¤ ê°ë„ì—ì„œë“  ì •ë³´ë¥¼ ë³¼ ìˆ˜ ìˆì–´ ë¡œë´‡ì˜ ìœ„ì¹˜ë¥¼ ì •í™•í•˜ê²Œ ì¡ì„ í•„ìš”ê°€ ì¤„ì–´ë“­ë‹ˆë‹¤."
          },
          {
            "title": "Emotive Flexibility",
            "content": "The screen itself bends to create expressions, merging hardware and software into one form.\n\n[KR] í™”ë©´ ìì²´ê°€ êµ¬ë¶€ëŸ¬ì ¸ í‘œì •ì„ ë§Œë“¤ì–´ë‚´ë©° í•˜ë“œì›¨ì–´ì™€ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ í•˜ë‚˜ì˜ í˜•íƒœë¡œ ìœµí•©í•©ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/samsung-ai-oled-bot/samsung-ai-oled-bot_1.jpg",
        "/images/products/samsung-ai-oled-bot/samsung-ai-oled-bot_2.jpg",
        "/images/products/samsung-ai-oled-bot/samsung-ai-oled-bot_3.gif"
      ],
      "videoUrl": ""
    },
    {
      "id": "olloni-cyberpet",
      "typeId": "type2",
      "manufacturer": "Ollobot",
      "name": "OlloNi Cyber Pet",
      "country": "China",
      "overview": "A next-gen cyber pet focusing on digital evolution. It grows and develops a unique personality based on how you treat it.",
      "analysis": {
        "intro": "Digital Evolution",
        "points": [
          {
            "title": "Growth Algorithm",
            "content": "Unlike static toys, its code rewrites itself to mature over time."
          },
          {
            "title": "Social Linking",
            "content": "Can play with other OlloNi units nearby."
          }
        ]
      },
      "images": [
        "/images/products/olloni-cyberpet/olloni-cyberpet_1.jpg",
        "/images/products/olloni-cyberpet/olloni-cyberpet_2.jpg",
        "/images/products/olloni-cyberpet/olloni-cyberpet_3.jpg",
        "/images/products/olloni-cyberpet/olloni-cyberpet_4.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "rovar-x3",
      "typeId": "type2",
      "manufacturer": "Sentigent Technology (Shentingji)",
      "name": "Rovar X3",
      "country": "China",
      "overview": "Purpose: To serve as a rugged outdoor companion for activities like hiking, walking in parks/neighborhoods, or light adventures; designed to follow owners autonomously over rough terrain, provide emotional interaction (play, sing, dance), and offer basic watch/monitoring, creating joyful, supportive presence in natural environments while enhancing safety and engagement for users. At CES 2026, Sentigent Technology unveiled the compact Rovar X3 as a small, adorable robot optimized for outdoor use â€” featuring innovative dual-wheel-legged locomotion to navigate grass, trails, stairs, and uneven terrain. Live demos showed it autonomously recognizing/following owners, perceiving surroundings, responding to behaviors naturally, singing/dancing for play, and interacting emotionally (e.g., expressive movements or sounds for affection). It emphasizes durability for light outdoor settings with capabilities like playing engagement, positioning it as an evolution in companion robotics beyond indoor limits.\n\n[KR] ì œí’ˆì˜ ëª©ì : í•˜ì´í‚¹, ê³µì›/ë™ë„¤ ì‚°ì±…, ê°€ë²¼ìš´ ì•„ì›ƒë„ì–´ í™œë™ì„ ìœ„í•œ ëŸ¬ê¸°ë“œ ì»´íŒ¨ë‹ˆì–¸; ê±°ì¹œ ì§€í˜•ì—ì„œ ììœ¨ íŒ”ë¡œì‰, ê°ì • ìƒí˜¸ì‘ìš©(ë†€ì´, ë…¸ë˜, ì¶¤), ê¸°ë³¸ ê°ì‹œ/ëª¨ë‹ˆí„°ë§ ì œê³µìœ¼ë¡œ ìì—° í™˜ê²½ì—ì„œ ì¦ê²ê³  ì§€ì§€ì ì¸ ì¡´ì¬ê° ì°½ì¶œ, ì‚¬ìš©ì(ì–´ë¦°ì´ í¬í•¨) ì•ˆì „ ë° ëª°ì… ê°•í™”. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ Sentigent TechnologyëŠ” ì»´íŒ©íŠ¸í•˜ê³  ê·€ì—¬ìš´ Rovar X3ë¥¼ ê³µê°œ â€” í˜ì‹ ì  ë“€ì–¼ íœ -ë ˆê·¸ ë¡œì½”ëª¨ì…˜ìœ¼ë¡œ ì”ë””, íŠ¸ë ˆì¼, ê³„ë‹¨, ë¶ˆê· í˜• ì§€í˜• íƒìƒ‰. ë¼ì´ë¸Œ ë°ëª¨ëŠ” ì†Œìœ ì ììœ¨ ì¸ì‹/íŒ”ë¡œì‰, ì£¼ë³€ ì¸ì‹, í–‰ë™ ìì—° ë°˜ì‘, ë†€ì´ ìœ„í•œ ë…¸ë˜/ì¶¤, ê°ì • ìƒí˜¸ì‘ìš©ì‹œì—°. ê°€ë²¼ìš´ ì•„ì›ƒë„ì–´ ë‚´êµ¬ì„± ê°•ì¡°í•˜ë©° ê°ì‹œë‚˜ ì¥ë‚œìŠ¤ëŸ¬ìš´ ëª°ì… ê°€ëŠ¥, ì¸ë„ì–´ í•œê³„ ë„˜ì–´ ì»´íŒ¨ë‹ˆì–¸ ë¡œë³´í‹±ìŠ¤ ì§„í™”ë¡œ í¬ì§€ì…”ë‹.",
      "analysis": {
        "intro": "Outdoor Hybrid Mobility & Companion AI\n[KR] ì•„ì›ƒë„ì–´ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¹Œë¦¬í‹° ë° ì»´íŒ¨ë‹ˆì–¸ AI",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Rovar X3 pioneers affordable, deployable Physical AI for unstructured outdoor environments through hybrid wheel-leg mobility, enabling continuous presence and proactive following without constant commands. Its emotional features (playful responses, natural interaction) shift focus from pure utility to 'lived' companionship in dynamic real-world settings, demonstrating how compact embodied AI can extend human experiences into nature with minimal intrusion while building affective bonds through shared activities.\n\n[KR] Rovar X3ëŠ” í•˜ì´ë¸Œë¦¬ë“œ íœ -ë ˆê·¸ ëª¨ë¹Œë¦¬í‹°ë¡œ ë¹„êµ¬ì¡°í™” ì•„ì›ƒë„ì–´ í™˜ê²½ì— ì €ë¹„ìš©Â·ë°°í¬ ê°€ëŠ¥ Physical AI ê°œì²™, ìƒì‹œ ëª…ë ¹ ì—†ì´ ì—°ì† ì¡´ì¬ê°ê³¼ ì‚¬ì „ì  íŒ”ë¡œì‰ êµ¬í˜„. ê°ì • ê¸°ëŠ¥(ì¥ë‚œìŠ¤ëŸ¬ìš´ ë°˜ì‘, ìì—° ìƒí˜¸ì‘ìš©)ì€ ìˆœìˆ˜ ìœ í‹¸ë¦¬í‹°ì—ì„œ ë™ì  ì‹¤ì„¸ê³„ 'lived' ì»´íŒ¨ë‹ˆì–¸ì‹­ìœ¼ë¡œ ì´ˆì  ì „í™˜, ìµœì†Œ ì¹¨ìŠµìœ¼ë¡œ ìì—° ì† ì¸ê°„ ê²½í—˜ í™•ì¥í•˜ë©° ê³µìœ  í™œë™ í†µí•´ affective bonds êµ¬ì¶• ë°©ì‹ ë³´ì—¬ì¤Œ.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Rovar X3 excels in Layer 2 (Motion & Physical Behavior) with its dual-wheel-leg kinetics conveying lively agency and intent. The adorable, pet-like form combined with singing/dancing micro-behaviors creates strong empathy cues and emotional peak without complex faces. For our target form factors (especially Movable TV): hybrid kinetic locomotion for proactive 'act/stay' in varied home spaces (cross-room following); synchronized ambient lighting with playful gestures for emotional baseline; restrained withdrawal for 'withdraw' and uninterrupted state. This outdoor-to-indoor inspiration pushes our PoC toward joyful, expressive physical dialogue.\n\n[KR] Rovar X3ëŠ” Layer 2(Motion & Physical Behavior)ì—ì„œ ë“€ì–¼ íœ -ë ˆê·¸ í‚¤ë„¤í‹±ìœ¼ë¡œ ìƒìƒí•œ agencyì™€ ì˜ë„ ì „ë‹¬ ê°•ì . ê·€ì—¬ìš´ í«-like í˜•íƒœì™€ ë…¸ë˜/ì¶¤ ë§ˆì´í¬ë¡œ í–‰ë™ìœ¼ë¡œ ë³µì¡ ì–¼êµ´ ì—†ì´ ê°•í•œ empathy cuesì™€ emotional peak ì°½ì¶œ, ë¦¬ë“¬ ì›€ì§ì„ìœ¼ë¡œ 'mood temperature' ê°•ì¡°. ìš°ë¦¬ íƒ€ê²Ÿ í¼íŒ©í„°(íŠ¹íˆ ë¬´ë¹™ ìŠ¤íƒ€ì¼ TV)ì— ì ìš© ì‹œ: ë‹¤ì–‘í•œ í™ˆ ê³µê°„ í”„ë¡œì•¡í‹°ë¸Œ 'act/stay' ìœ„í•œ í•˜ì´ë¸Œë¦¬ë“œ í‚¤ë„¤í‹± ë¡œì½”ëª¨ì…˜; ì¥ë‚œ ì œìŠ¤ì²˜ì™€ ë™ê¸°í™”ëœ ambient lightingìœ¼ë¡œ emotional baseline; ì‚¬ìš©ì ì§‘ì¤‘ ì‹œ ê±°ë¦¬ ìœ ì§€ ì ˆì œëœ í›„í‡´ë¡œ 'withdraw'ì™€ uninterrupted state. ì´ ì•„ì›ƒë„ì–´-íˆ¬-ì¸ë„ì–´ ì˜ê°ì€ PoCë¥¼ ì¦ê²ê³  í‘œí˜„ë ¥ ìˆëŠ” ë¬¼ë¦¬ ëŒ€í™”ë¡œ ì¶”ì§„.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/rovar-x3/rovar-x3_1.jpg",
        "/images/products/rovar-x3/rovar-x3_2.jpg",
        "/images/products/rovar-x3/rovar-x3_3.jpg",
        "/images/products/rovar-x3/rovar-x3_4.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Sentigent+Rovar+X3+CES+2026"
    },
    {
      "id": "roborock-saros",
      "typeId": "type2",
      "manufacturer": "Roborock",
      "name": "Saros Z70",
      "country": "China",
      "overview": "A hybrid cleaning robot with a chassis that lifts on wheels to climb obstacles and stairs, redefining mobility.\n\n[KR] ì¥ì• ë¬¼ê³¼ ê³„ë‹¨ì„ ì˜¤ë¥´ê¸° ìœ„í•´ ë°”í€´ë¡œ ì„€ì‹œë¥¼ ë“¤ì–´ ì˜¬ë¦¬ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì²­ì†Œ ë¡œë´‡ìœ¼ë¡œ, ì´ë™ì„±ì„ ì¬ì •ì˜í•©ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Vertical Cleaning\n[KR] ìˆ˜ì§ ì²­ì†Œ",
        "points": [
          {
            "title": "Active Lift",
            "content": "The entire body lifts up to clear thresholds up to 4cm and climb standard stairs.\n\n[KR] ë³¸ì²´ ì „ì²´ê°€ ë“¤ì–´ ì˜¬ë ¤ì ¸ ìµœëŒ€ 4cm ë¬¸í„±ì„ ë„˜ê³  í‘œì¤€ ê³„ë‹¨ì„ ì˜¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          },
          {
            "title": "Dual-Camera VSLAM",
            "content": "Uses stereo cameras to identify furniture types and clean accordingly (e.g., under sofas).\n\n[KR] ìŠ¤í…Œë ˆì˜¤ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€êµ¬ ìœ í˜•ì„ ì‹ë³„í•˜ê³  ê·¸ì— ë§ì¶°(ì˜ˆ: ì†ŒíŒŒ ì•„ë˜) ì²­ì†Œí•©ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/roborock-saros/roborock-saros_1.jpg",
        "/images/products/roborock-saros/roborock-saros_2.webp",
        "/images/products/roborock-saros/roborock-saros_3.webp"
      ],
      "videoUrl": ""
    },
    {
      "id": "dreame-cyber-10",
      "typeId": "type2",
      "manufacturer": "Dreame",
      "name": "Cyber 10 Ultra",
      "country": "China",
      "overview": "A premium robotic vacuum focused on absolute autonomy with minimal maintenance.\n\n[KR] ìµœì†Œí•œì˜ ìœ ì§€ ë³´ìˆ˜ë¡œ ì™„ë²½í•œ ììœ¨ì„±ì„ ì¶”êµ¬í•˜ëŠ” í”„ë¦¬ë¯¸ì—„ ë¡œë´‡ ì²­ì†Œê¸°ì…ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Zero Maintenance\n[KR] ì œë¡œ ìœ ì§€ë³´ìˆ˜",
        "points": [
          {
            "title": "Self-Cleaning Station",
            "content": "The base station cleans the mop, empties dust, and even cleans itself, reducing human chores to zero.\n\n[KR] ë² ì´ìŠ¤ ìŠ¤í…Œì´ì…˜ì´ ê±¸ë ˆ ì„¸ì²™, ë¨¼ì§€ ë¹„ì›€, ì‹¬ì§€ì–´ ìŠ¤í…Œì´ì…˜ ìì²´ ì²­ì†Œê¹Œì§€ ìˆ˜í–‰í•˜ì—¬ ì¸ê°„ì˜ ê°€ì‚¬ ë…¸ë™ì„ ì œë¡œë¡œ ë§Œë“­ë‹ˆë‹¤."
          },
          {
            "title": "Edge Learning",
            "content": "Learns the precise contours of furniture over time to clean closer without bumping.\n\n[KR] ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ê°€êµ¬ì˜ ì •í™•í•œ ìœ¤ê³½ì„ í•™ìŠµí•˜ì—¬ ë¶€ë”ªí˜ ì—†ì´ ë” ê°€ê¹Œì´ ì²­ì†Œí•©ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/dreame-cyber-10/dreame-cyber-10_1.jpg",
        "/images/products/dreame-cyber-10/dreame-cyber-10_2.jpg",
        "/images/products/dreame-cyber-10/dreame-cyber-10_3.jpg",
        "/images/products/dreame-cyber-10/dreame-cyber-10_4.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "dreame-cyber-x",
      "typeId": "type2",
      "manufacturer": "Dreame",
      "name": "Cyber X",
      "country": "China",
      "overview": "An experimental corner-cleaning specialist with a unique shape.\n\n[KR] ë…íŠ¹í•œ í˜•íƒœë¥¼ ê°€ì§„ ì½”ë„ˆ ì²­ì†Œ ì „ë¬¸ ì‹¤í—˜ ëª¨ë¸ì…ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Geometric Clean\n[KR] ê¸°í•˜í•™ì  ì²­ì†Œ",
        "points": [
          {
            "title": "Square Adaptive Body",
            "content": "The robot transforms or extends parts of its body to fit perfectly into 90-degree corners.\n\n[KR] ë¡œë´‡ì´ 90ë„ ì½”ë„ˆì— ì™„ë²½í•˜ê²Œ ë§ë„ë¡ ì°¨ì²´ ì¼ë¶€ë¥¼ ë³€í˜•í•˜ê±°ë‚˜ í™•ì¥í•©ë‹ˆë‹¤."
          },
          {
            "title": "Low Profile",
            "content": "Ultra-thin design allows it to slip under furniture that standard LIDAR towers block.\n\n[KR] ì´ˆë°•í˜• ë””ìì¸ìœ¼ë¡œ í‘œì¤€ ë¼ì´ë‹¤ íƒ‘ì´ ê±¸ë¦¬ëŠ” ê°€êµ¬ ë°‘ìœ¼ë¡œë„ ë“¤ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/dreame-cyber-x/dreame-cyber-x_1.jpg",
        "/images/products/dreame-cyber-x/dreame-cyber-x_2.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "narwal-flow-2",
      "typeId": "type2",
      "manufacturer": "Narwal",
      "name": "Flow 2",
      "country": "China",
      "overview": "Prioritizing mopping quality with high-speed scrubbing and fresh water cycling.\n\n[KR] ê³ ì† ìŠ¤í¬ëŸ¬ë¹™ê³¼ ì‹ ì„ í•œ ë¬¼ ìˆœí™˜ìœ¼ë¡œ ê±¸ë ˆì§ˆ í’ˆì§ˆì„ ìµœìš°ì„ ìœ¼ë¡œ í•©ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Hygienic Mopping\n[KR] ìœ„ìƒì  ë¬¼ê±¸ë ˆì§ˆ",
        "points": [
          {
            "title": "DirtSense",
            "content": "Sensors detect how dirty the water being sucked up is, automatically re-mopping areas until clean.\n\n[KR] í¡ì…ë˜ëŠ” ë¬¼ì˜ ì˜¤ì—¼ë„ë¥¼ ì„¼ì„œê°€ ê°ì§€í•˜ì—¬ ê¹¨ë—í•´ì§ˆ ë•Œê¹Œì§€ ìë™ìœ¼ë¡œ í•´ë‹¹ êµ¬ì—­ì„ ë‹¤ì‹œ ë‹¦ìŠµë‹ˆë‹¤."
          },
          {
            "title": "Quiet Scrub",
            "content": "Mechanisms oscillate at high frequencies but low decibels, allowing deep cleaning while you watch TV.\n\n[KR] ë†’ì€ ì§„ë™ìˆ˜ì§€ë§Œ ë‚®ì€ ë°ì‹œë²¨ë¡œ ì‘ë™í•˜ì—¬ TVë¥¼ ì‹œì²­í•˜ëŠ” ë™ì•ˆì—ë„ ì‹¬ì¸µ ì²­ì†Œê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/narwal-flow-2/narwal-flow-2_1.jpg",
        "/images/products/narwal-flow-2/narwal-flow-2_2.jpg",
        "/images/products/narwal-flow-2/narwal-flow-2_3.webp"
      ],
      "videoUrl": ""
    },
    {
      "id": "ecovacs-winbot-w3",
      "typeId": "type2",
      "manufacturer": "Ecovacs",
      "name": "Winbot W3 Omni",
      "country": "China",
      "overview": "A window cleaning robot with a portable station that acts as a safety anchor and battery bank.\n\n[KR] ì•ˆì „ ì•µì»¤ ë° ë°°í„°ë¦¬ ë±…í¬ ì—­í• ì„ í•˜ëŠ” íœ´ëŒ€ìš© ìŠ¤í…Œì´ì…˜ì´ í¬í•¨ëœ ì°½ë¬¸ ì²­ì†Œ ë¡œë´‡ì…ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Vertical Gravity\n[KR] ìˆ˜ì§ ì¤‘ë ¥",
        "points": [
          {
            "title": "Suction Safe",
            "content": "Constantly monitors air seal pressure and adjusts motor power to prevent falling.\n\n[KR] ê³µê¸° ë°€í ì••ë ¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ëª¨í„° ì¶œë ¥ì„ ì¡°ì •í•˜ì—¬ ë‚™í•˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤."
          },
          {
            "title": "Edge Detection",
            "content": "Frameless window detection ensures it doesn't fall off glass balustrades or mirrors.\n\n[KR] í”„ë ˆì„ ì—†ëŠ” ì°½ë¬¸ ê°ì§€ ê¸°ëŠ¥ìœ¼ë¡œ ìœ ë¦¬ ë‚œê°„ì´ë‚˜ ê±°ìš¸ì—ì„œ ë–¨ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/ecovacs-winbot-w3/ecovacs-winbot-w3_1.jpg",
        "/images/products/ecovacs-winbot-w3/ecovacs-winbot-w3_2.jpg",
        "/images/products/ecovacs-winbot-w3/ecovacs-winbot-w3_3.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "ecovacs-lilmilo",
      "typeId": "type2",
      "manufacturer": "Ecovacs",
      "name": "LilMilo",
      "country": "China",
      "overview": "A home companion robot designed to follow family members and assist with daily tasks and communication.\n\n[KR] ê°€ì¡± êµ¬ì„±ì›ì„ ë”°ë¼ë‹¤ë‹ˆë©° ì¼ìƒ ì—…ë¬´ì™€ ì˜ì‚¬ì†Œí†µì„ ë•ë„ë¡ ì„¤ê³„ëœ ê°€ì •ìš© ë°˜ë ¤ ë¡œë´‡ì…ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Social Shadow\n[KR] ì†Œì…œ ì„€ë„ìš°",
        "points": [
          {
            "title": "Active Following",
            "content": "Uses skeletal tracking to follow a specific person, acting as a mobile video call stand or music player.\n\n[KR] ê³¨ê²© ì¶”ì  ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì‚¬ëŒì„ ë”°ë¼ë‹¤ë‹ˆë©° ì´ë™ì‹ í™”ìƒ í†µí™” ìŠ¤íƒ ë“œë‚˜ ìŒì•… í”Œë ˆì´ì–´ ì—­í• ì„ í•©ë‹ˆë‹¤."
          },
          {
            "title": "Voice Memo Carrier",
            "content": "Can 'carry' a voice message physically from one person in the kitchen to another in the bedroom.\n\n[KR] ì£¼ë°©ì— ìˆëŠ” ì‚¬ëŒì˜ ìŒì„± ë©”ì‹œì§€ë¥¼ ì¹¨ì‹¤ì— ìˆëŠ” ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ë¬¼ë¦¬ì ìœ¼ë¡œ 'ë°°ë‹¬'í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/ecovacs-lilmilo/ecovacs-lilmilo_1.jpg",
        "/images/products/ecovacs-lilmilo/ecovacs-lilmilo_2.jpg",
        "/images/products/ecovacs-lilmilo/ecovacs-lilmilo_3.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "roborock-saros-rover",
      "typeId": "type2",
      "manufacturer": "Roborock",
      "name": "Saros Rover",
      "country": "China",
      "overview": "A hybrid wheel-leg cleaning robot that can climb stairs and hop over obstacles, ensuring 100% home coverage.",
      "analysis": {
        "intro": "3D Mobility UX",
        "points": [
          {
            "title": "Obstacle Negotiation",
            "content": "The visible lifting of legs to step over toys communicates 'intelligence' and 'care' for personal items."
          },
          {
            "title": "Transformative State",
            "content": "Shifting from wheels to legs signals a 'mode change' to the user, managing expectations of speed vs. agility."
          }
        ]
      },
      "images": [
        "/images/products/roborock-saros/roborock-saros_1.png",
        "/images/products/roborock-saros/roborock-saros_2.png",
        "/images/products/roborock-saros/roborock-saros_3.png",
        "/images/products/roborock-saros/roborock-saros_4.png"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Roborock+Saros"
    },
    {
      "id": "samsung-ballie",
      "typeId": "type2",
      "manufacturer": "Samsung Electronics",
      "name": "Ballie (Status 2026)",
      "country": "South Korea",
      "overview": "Purpose: Originally envisioned as an autonomous, rolling AI companion for home environments â€” following users, projecting content, controlling smart devices, monitoring pets/home, and providing proactive assistance; evolved into a testbed for spatial awareness, contextual AI, ambient intelligence, and privacy-focused design, with learnings applied to existing products like robot vacuums and SmartThings ecosystem. At CES 2026, Ballie was conspicuously absent from the show floor and announcements â€” no new demos or release timeline. Samsung repositioned it as an 'internal innovation platform' whose tech insights (spatial awareness, contextual intelligence, ambient AI) inform broader ecosystem products rather than a standalone consumer device. No cancellation confirmed, but language strongly implies indefinite shelving for commercial release.\n\n[KR] ì œí’ˆì˜ ëª©ì : ì›ë˜ ê°€ì • í™˜ê²½ì—ì„œ ì‚¬ìš©ì ë”°ë¼ë‹¤ë‹ˆê¸°, ì½˜í…ì¸  íˆ¬ì‚¬, ìŠ¤ë§ˆíŠ¸ ê¸°ê¸° ì œì–´, í«/í™ˆ ëª¨ë‹ˆí„°ë§, ìì—°ìŠ¤ëŸ¬ìš´ ìƒí˜¸ì‘ìš©ì„ í†µí•œ ì‚¬ì „ì  ë³´ì¡°ë¥¼ ìœ„í•œ ììœ¨ ë¡¤ë§ AI ì»´íŒ¨ë‹ˆì–¸; ê³µê°„ ì¸ì‹Â·ë§¥ë½ AIÂ·ambient ì§€ëŠ¥Â·í”„ë¼ì´ë²„ì‹œ ì¤‘ì‹¬ ë””ìì¸ í…ŒìŠ¤íŠ¸ë² ë“œë¡œ ì§„í™”, ë¡œë´‡ ì²­ì†Œê¸°Â·SmartThings ë“± ê¸°ì¡´ ì œí’ˆì— í•™ìŠµ ì ìš©. ìƒì„¸ ì„¤ëª…: CES 2020ì—ì„œ ìµœì´ˆ ê³µê°œëœ ì´í›„ ë°˜ë³µ ì—…ë°ì´íŠ¸ë˜ì—ˆìœ¼ë‚˜, CES 2026(2026ë…„ 1ì›”) ê¸°ì¤€ ì‡¼í”Œë¡œì–´Â·í”„ë ˆìŠ¤ ì´ë²¤íŠ¸Â·ë°œí‘œì—ì„œ ì™„ì „ ë¶€ì¬ â€” ì‹ ê·œ ë°ëª¨Â·ê°€ê²©/ì¶œì‹œ ì¼ì • ì—†ìŒ. ì‚¼ì„±, ì†Œë¹„ì ë‹¨ë… ì œí’ˆ ì•„ë‹Œ 'ë‚´ë¶€ í˜ì‹  í”Œë«í¼'ìœ¼ë¡œ ì¬í¬ì§€ì…”ë‹ â€” ê³µê°„ ì¸ì‹Â·ë§¥ë½ ì§€ëŠ¥Â·ê¸°ìˆ ì´ ë¡œë´‡ ì²­ì†Œê¸° ë“± ê´‘ë²”ìœ„ ì—ì½”ì‹œìŠ¤í…œì— ì ìš©. ì·¨ì†Œ ê³µì‹ í™•ì¸ ì—†ìœ¼ë‚˜ ìƒì—… ì¶œì‹œ ë¬´ê¸°í•œ ë³´ë¥˜ ì•”ì‹œ ê°•í•¨.",
      "analysis": {
        "intro": "Internal Innovation Platform & Ambient AI\n[KR] ë‚´ë¶€ í˜ì‹  í”Œë«í¼ ë° Ambient AI",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Ballie's prolonged development and eventual internal pivot highlight the real-world challenges of achieving reliable, affective Physical AI in consumer homes â€” balancing mobility, sensing, and non-intrusive presence. Its absence at CES 2026 amid competitors' advances underscores the difficulty of transitioning from prototypes to scalable 'lived' companions. Learnings in ambient expression (light ring) and contextual sensing remain valuable for Samsung's broader Physical AI strategy, emphasizing continuous adaptation over standalone novelty.\n\n[KR] Ballieì˜ ì¥ê¸° ê°œë°œê³¼ ë‚´ë¶€ ì „í™˜ì€ ì†Œë¹„ì ê°€ì •ì—ì„œ ì‹ ë¢°í•  ìˆ˜ ìˆê³  affectiveí•œ Physical AI ì‹¤í˜„ì˜ í˜„ì‹¤ì  ë‚œê´€ ê°•ì¡° â€” ëª¨ë¹Œë¦¬í‹°Â·ì„¼ì‹±Â·ë¹„ì¹¨ìŠµ ì¡´ì¬ê° ê· í˜• ì† ê¸°ìˆ  êµ¬í˜„ì˜ ë³µì¡ì„±. CES 2026 ë¶€ì¬ëŠ” ê²½ìŸì‚¬ ì§„ë³´ ì† í”„ë¡œí† íƒ€ì…ì—ì„œ í™•ì¥ ê°€ëŠ¥ 'lived' ì»´íŒ¨ë‹ˆì–¸ìœ¼ë¡œì˜ ì „í™˜ ì–´ë ¤ì›€ ë¶€ê°. ë¼ì´íŠ¸ ë§ ambient í‘œí˜„Â·ë§¥ë½ ì„¼ì‹± í•™ìŠµì€ ì‚¼ì„± ê´‘ë²”ìœ„ Physical AI ì „ëµì— ì—¬ì „íˆ ê°€ì¹˜ â€” ë‹¨ë… ì‹ ê¸°í•¨ë³´ë‹¤ ì—°ì† ì ì‘ ìš°ì„ .",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Despite no 2026 update, Ballie's core design (light ring + rolling + projector) offers lessons for our Expression System â€” Layer 1 (Light) ambient ring subtly signals mood temperature with low cognitive load, while Layer 2 (Motion) spherical rolling conveys 'stay/act/withdraw' roles. Layer 3 (Projection) enables empathetic projection cues without overt faces, avoiding uncanny valley. For target form factors (especially Movable TV): kinetic rolling base for proactive mobility with synced ambient lighting; projection for contextual empathy; and restrained motion as turn-taking politeness. Its pivot reminds us to focus on 'lived' integration â€” non-intrusive physical signaling that accumulates affection in in-between moments.\n\n[KR] 2026 ì—…ë°ì´íŠ¸ ì—†ìŒì—ë„ Ballie í•µì‹¬ ë””ìì¸(ë¼ì´íŠ¸ ë§ + ë¡¤ë§ + í”„ë¡œì í„°)ì€ ìš°ë¦¬ Expression Systemì— ì˜ì›í•œ êµí›ˆ â€” Layer 1(Light) ambient ë§ìœ¼ë¡œ mood temperature ë¯¸ë¬˜ ì „ë‹¬, ë‚®ì€ ì¸ì§€ ë¶€í•˜; Layer 2(Motion) êµ¬í˜• ë¡¤ë§ìœ¼ë¡œ 'stay/act/withdraw' ì—­í•  ì „ë‹¬; Layer 3(Projection) overt ì–¼êµ´ ì—†ì´ empathy projection cues ê°€ëŠ¥. ìš°ë¦¬ íƒ€ê²Ÿ í¼íŒ©í„°(íŠ¹íˆ ë¬´ë¹™ ìŠ¤íƒ€ì¼ TV)ì— ì ìš© ì‹œ: í”„ë¡œì•¡í‹°ë¸Œ ëª¨ë¹Œë¦¬í‹°ë¥¼ ìœ„í•œ í‚¤ë„¤í‹± ë¡¤ë§ ë² ì´ìŠ¤ì™€ emotional baseline ì—°ë™ ambient lighting; ì‚¬ìš©ì ìŠ¤íŠ¸ë ˆìŠ¤ ê°ì§€ ì‹œ calming íŒ¨í„´ projectionìœ¼ë¡œ ë§¥ë½ empathy; turn-taking politenessë¥¼ ìœ„í•œ ì ˆì œ ëª¨ì…˜ìœ¼ë¡œ trust over time ì¶•ì . í•µì‹¬ì ìœ¼ë¡œ 'lived' í†µí•©ì— ì´ˆì  â€” ë¹„ì¹¨ìŠµì Â·ì§€ì†ì  ë¬¼ë¦¬ ì‹œê·¸ë„ë§ìœ¼ë¡œ in-between moments ì• ì • ì¶•ì .",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/samsung-ballie/ballie_01.jpg",
        "/images/products/samsung-ballie/ballie_02.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Samsung+Ballie+CES+2026"
    },
    {
      "id": "gole-aa2",
      "typeId": "type2",
      "manufacturer": "GoLe-Robotics",
      "name": "AA-2 Delivery Bot",
      "country": "South Korea",
      "overview": "An autonomous indoor delivery unit focused on hotels and offices. Its 'compartment' design is hidden, looking like sleek furniture moving on its own.",
      "analysis": {
        "intro": "Invisible Service",
        "points": [
          {
            "title": "Gliding Motion",
            "content": "Omnidirectional wheels allow it to drift sideways, navigating crowds without turning its body, maintaining a 'face' towards the user."
          },
          {
            "title": "Touch-to-Open",
            "content": "No visible handles; interaction is purely gestural or capacitive, enhancing the futuristic feel."
          }
        ]
      },
      "images": [
        "/images/products/gole-aa2/gole-aa2_1.webp"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=GoLe+Robotics+Delivery"
    },
    {
      "id": "doosan-scan-go",
      "typeId": "type2",
      "manufacturer": "Doosan Robotics",
      "name": "Scan&Go AMRS",
      "country": "South Korea",
      "overview": "A retail inventory specialist that scans shelves while avoiding shoppers. Awarded 'Best of Innovation in AI' for its navigation logic.",
      "analysis": {
        "intro": "Co-existence Navigation",
        "points": [
          {
            "title": "Yielding Behavior",
            "content": "Aggressively yields right-of-way to humans, backing up specifically to clear paths, signaling 'servitude' over efficiency."
          },
          {
            "title": "Head-Height Scanning",
            "content": "Its sensor mast extends to check high shelves but retracts when traveling to appear less imposing."
          }
        ]
      },
      "images": [
        "/images/products/doosan-scan-go/doosan-scan-go_1.jpg",
        "/images/products/doosan-scan-go/doosan-scan-go_2.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Doosan+Robotics+Scan+Go"
    },
    {
      "id": "zeroth-rolling",
      "typeId": "type2",
      "manufacturer": "Zeroth",
      "name": "Zeroth Companion",
      "country": "China",
      "overview": "A pint-sized rolling bot with a large expressive eye, designed solely to check on pets and home security.",
      "analysis": {
        "intro": "Curious Observer",
        "points": [
          {
            "title": "Cyclops Eye UI",
            "content": "A single large eye allows for exaggerated blinking and focusing animations, making it cute rather than creepy."
          },
          {
            "title": "Patrol Mode",
            "content": "Moves in erratic, organic patterns rather than grid lines to mimic a living creature patrolling territory."
          }
        ]
      },
      "images": [
        "/images/products/zeroth-rolling/zeroth-rolling_1.jpg",
        "/images/products/zeroth-rolling/zeroth-rolling_2.png"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Zeroth+Robot+Companion"
    },
    {
      "id": "dreame-climber",
      "typeId": "type2",
      "manufacturer": "Dreame",
      "name": "Stair-Climbing Vac",
      "country": "China",
      "overview": "Competitor to Saros, this vacuum uses a tri-star wheel system to mechanically climb stairs without complex legs.",
      "analysis": {
        "intro": "Mechanical Reliability",
        "points": [
          {
            "title": "Robust Audio Cues",
            "content": "Makes distinct mechanical 'locking' sounds when engaging climbing mode, assuring the user it is secure."
          },
          {
            "title": "Cleaning Focus",
            "content": "Prioritizes edge cleaning with extendable arms, showing capability in hard-to-reach places."
          }
        ]
      },
      "images": [
        "/images/products/dreame-climber/dreame-climber_1.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Dreame+Stair+Climbing+Robot"
    },
    {
      "id": "ecovacs-deebot-x",
      "typeId": "type2",
      "manufacturer": "Ecovacs",
      "name": "Deebot X Companion",
      "country": "China",
      "overview": "The vac that talks back (helpfully). It uses large language models to understand 'Clean the juice I spilt in the kitchen' without mapping commands.",
      "analysis": {
        "intro": "Semantic Action",
        "points": [
          {
            "title": "Voice Localization",
            "content": "Turns its body towards the sound of the voice immediately, acknowledging the speaker."
          },
          {
            "title": "Spot Cleaning",
            "content": "Can identify specific stains visually and target them, mimicking human 'spot check' behavior."
          }
        ]
      },
      "images": [
        "/images/products/ecovacs-deebot-x/ecovacs-deebot-x_1.png"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Ecovacs+Deebot+X+Series"
    },
    {
      "id": "narwal-freo",
      "typeId": "type2",
      "manufacturer": "Narwal",
      "name": "Freo Mobile",
      "country": "China",
      "overview": "Focuses on 'DirtSense'â€”re-cleaning dirty areas until they are actually clean, rather than just running a path.",
      "analysis": {
        "intro": "Insistent Cleanliness",
        "points": [
          {
            "title": "Wiggle Cleaning",
            "content": "Uses a unique 'tail wag' motion to scrub edges, a distinct movement signature that owners recognize."
          },
          {
            "title": "Station Returns",
            "content": "Frequent returns to base for mop washing signal 'hygiene' awareness to the user."
          }
        ]
      },
      "images": [
        "/images/products/narwal-freo/narwal-freo_1.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Narwal+Freo"
    },
    {
      "id": "irobot-combo",
      "typeId": "type2",
      "manufacturer": "iRobot",
      "name": "Roomba Combo AI",
      "country": "USA",
      "overview": "The classic evolves. Uses advanced object recognition to avoid pet waste and cords with 99% accuracy.",
      "analysis": {
        "intro": "Avoidance Mastery",
        "points": [
          {
            "title": "Cautionary Stops",
            "content": "Visibly slows down and examines unknown objects, signaling 'safety first'."
          },
          {
            "title": "Retractable Mop",
            "content": "The physical lifting of the mop pad over carpet is a satisfying mechanical gesture of 'mode switching'."
          }
        ]
      },
      "images": [
        "/images/products/irobot-combo/irobot-combo_1.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=iRobot+Roomba+Combo"
    },
    {
      "id": "bosch-home",
      "typeId": "type2",
      "manufacturer": "Bosch",
      "name": "Mobile Home Concept",
      "country": "Germany",
      "overview": "A kitchen assistant concept that can project recipes and monitor cooking times, rolling across countertops or floors.",
      "analysis": {
        "intro": "Culinary Assistant",
        "points": [
          {
            "title": "Projection UI",
            "content": "Turns any countertop into a touchscreen, blending digital utility with physical surfaces."
          },
          {
            "title": "Compact Form",
            "content": "Designed to look like a high-end appliance (blender/mixer) rather than a toy."
          }
        ]
      },
      "images": [
        "/images/products/bosch-home/bosch-home_1.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Bosch+Home+Robot+Concept"
    },
    {
      "id": "loona-deskmate",
      "typeId": "type3",
      "manufacturer": "KEYi Tech",
      "name": "Loona Deskmate (Gen 2)",
      "country": "China",
      "overview": "Purpose: To provide joyful, low-maintenance emotional companionship on desks or small spaces; designed as an always-on affective presence that responds to user mood, offers playful interaction, and reduces loneliness through pet-like behaviors. At CES 2026, KEYi Tech presented the evolved Loona Deskmate with significant upgrades: compact pet-like form (dog-inspired with expressive ears, head, and tail), high-resolution animated eyes on a circular display for micro-expressions, colorful ambient LED lighting ring, enhanced voice/gesture recognition, wheeled mobility for small movements, and new on-device AI for prolonged unscripted interactions (greeting when user returns, playful animations during work breaks, comforting behaviors when detecting stress via camera/tone). Live demos showed natural emotional cycles (curiosity, joy, rest), app integration for personality customization, and seamless desk presence.\n\n[KR] ì œí’ˆì˜ ëª©ì : ì±…ìƒì´ë‚˜ ì‘ì€ ê³µê°„ì—ì„œ ì¦ê²ê³  ê´€ë¦¬ ë¶€ë‹´ ì ì€ ê°ì •ì  ë™ë°˜ì ì œê³µ; ì‚¬ìš©ì ê¸°ë¶„ ë°˜ì‘, ì¥ë‚œìŠ¤ëŸ¬ìš´ ìƒí˜¸ì‘ìš©, í«-ë¼ì´í¬ í–‰ë™ìœ¼ë¡œ ì™¸ë¡œì›€ ì™„í™”í•˜ëŠ” ìƒì‹œ affective ì¡´ì¬ê° ì„¤ê³„. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ KEYi TechëŠ” ëŒ€í­ ì—…ê·¸ë ˆì´ë“œëœ Loona Deskmate ê³µê°œ: ì»´íŒ©íŠ¸ í«-ë¼ì´í¬ í˜•íƒœ(ê°œ ì˜ê° ê·€Â·ë¨¸ë¦¬Â·ê¼¬ë¦¬ í‘œí˜„), ë§ˆì´í¬ë¡œ í‘œí˜„ìš© ê³ í•´ìƒë„ ì• ë‹ˆë©”ì´ì…˜ ëˆˆ ì›í˜• ë””ìŠ¤í”Œë ˆì´, ì»¬ëŸ¬í’€ ambient LED lighting ë§, ê°•í™” ìŒì„±/ì œìŠ¤ì²˜ ì¸ì‹, ì‘ì€ ì›€ì§ì„ ìœ„í•œ íœ  ëª¨ë¹Œë¦¬í‹°, ì¥ê¸° ë¹„ìŠ¤í¬ë¦½íŠ¸ ìƒí˜¸ì‘ìš© ìœ„í•œ ì˜¨ë””ë°”ì´ìŠ¤ AI(ì‚¬ìš©ì ê·€í™˜ ì‹œ ì¸ì‚¬, ì‘ì—… íœ´ì‹ ì‹œ ì¥ë‚œ ì• ë‹ˆë©”ì´ì…˜, ì¹´ë©”ë¼/í†¤ìœ¼ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ ê°ì§€ ì‹œ ìœ„ë¡œ í–‰ë™). ë¼ì´ë¸Œ ë°ëª¨ëŠ” ìì—° ê°ì • ì‚¬ì´í´(í˜¸ê¸°ì‹¬, ê¸°ì¨, íœ´ì‹), ì„±ê²© ì»¤ìŠ¤í„°ë§ˆì´ì§• ì•± í†µí•©, ê³µê°„ ê³¼ë¶€í•˜ ì—†ëŠ” ì›í™œ ë°ìŠ¤í¬ ì¡´ì¬ê° ê°•ì¡°.",
      "analysis": {
        "intro": "Affective Desktop Companion\n[KR] ê°ì •ì  ë°ìŠ¤í¬íƒ‘ ì»´íŒ¨ë‹ˆì–¸",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Loona Deskmate bridges the gap to mainstream affective Physical AI by combining adorable pet-inspired design with restrained, context-aware behaviors â€” creating continuous 'lived' presence in constrained spaces like desks. Its focus on micro-interactions and emotional cycles without verbal dominance validates how compact embodied AI can accumulate attachment through subtle, repeated non-intrusive signaling, making affective companionship accessible and scalable in everyday personal environments.\n\n[KR] Loona DeskmateëŠ” ê·€ì—¬ìš´ í« ì˜ê° ë””ìì¸ê³¼ ì ˆì œëœ ë§¥ë½ ì¸ì§€ í–‰ë™ ê²°í•©ìœ¼ë¡œ ì£¼ë¥˜ affective Physical AI ê°­ ë©”ì›€ â€” ì±…ìƒ ê°™ì€ ì œí•œ ê³µê°„ì—ì„œ ì—°ì† 'lived' ì¡´ì¬ê° ì°½ì¶œ. ìŒì„± ì§€ë°° ì—†ì´ ë§ˆì´í¬ë¡œ ìƒí˜¸ì‘ìš©ê³¼ ê°ì • ì‚¬ì´í´ ì´ˆì ìœ¼ë¡œ, ë¯¸ë¬˜í•˜ê³  ë°˜ë³µì  ë¹„ì¹¨ìŠµ ì‹œê·¸ë„ë§ í†µí•´ attachment ì¶•ì  ë°©ì‹ ê²€ì¦, ì¼ìƒ ê°œì¸ í™˜ê²½ì—ì„œ affective ì»´íŒ¨ë‹ˆì–¸ì‹­ ì ‘ê·¼ì„±Â·í™•ì¥ì„± ì‹¤í˜„.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Loona Deskmate masters integrated Layer 1 (Light) + Layer 2 (Motion) + Layer 3 (Face/Display) in a compact form â€” animated eyes deliver powerful empathy cues, kinetic ears/ears/tail/head provide legible agency and turn-taking politeness, and the ambient LED ring conveys mood temperature. This creates heartwarming 'living presence' that builds trust over time. For our target form factors (especially Tabletop Display Lamp): pet-inspired micro-animations synced to kinetic joints for intimate empathy cues; ambient lighting ring pulsing for emotional baseline; restrained gestures (tilt/nod/sway) as non-verbal acknowledgment to enhance companionship. Loona's pet paradigm inspires our PoC to prioritize adorable, intuitive affection and heart-touching emotional depth.\n\n[KR] Loona DeskmateëŠ” ì»´íŒ©íŠ¸ í«-ë¼ì´í¬ í˜•íƒœì—ì„œ Layer 1(Light) + Layer 2(Motion) + Layer 3(Face/Display) í†µí•© ë§ˆìŠ¤í„° â€” ì• ë‹ˆë©”ì´ì…˜ ëˆˆìœ¼ë¡œ ê°•ë ¥ empathy cues ì „ë‹¬, í‚¤ë„¤í‹± ê·€/ê¼¬ë¦¬/ë¨¸ë¦¬ë¡œ ê°€ë…ì„± ìˆëŠ” agencyì™€ turn-taking politeness ì œê³µ, ambient LED ë§ìœ¼ë¡œ mood temperature ë¯¸ë¬˜ ì „ë‹¬. ì´ëŠ” heartwarming 'living presence' ì°½ì¶œ. ìš°ë¦¬ íƒ€ê²Ÿ í¼íŒ©í„°(íŠ¹íˆ í…Œì´ë¸”íƒ‘ ë””ìŠ¤í”Œë ˆì´ ë¨í”„)ì— ì ìš© ì‹œ: í‚¤ë„¤í‹± ì¡°ì¸íŠ¸ì™€ ë™ê¸°í™”ëœ í« ì˜ê° ë§ˆì´í¬ë¡œ ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ ì¹œë°€ empathy cues; emotional baselineì„ ìœ„í•œ ambient lighting ë§ í„ìŠ¤; companionship ê°•í™”ë¥¼ ìœ„í•œ ì ˆì œëœ ì œìŠ¤ì²˜(í‹¸íŠ¸/ë‚«/ìŠ¤ì›¨ì´) ë¹„ì–¸ì–´ì  ì¸ì •. Loonaì˜ í« íŒ¨ëŸ¬ë‹¤ì„ì€ PoCë¥¼ ì§ê´€ì Â·ê·€ì—¬ìš´ ì• ì • ìš°ì„ ìœ¼ë¡œ ì˜ê°.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/loona-deskmate/loona-deskmate_1.jpg",
        "/images/products/loona-deskmate/loona-deskmate_2.jpg",
        "/images/products/loona-deskmate/loona-deskmate_3.jpg",
        "/images/products/loona-deskmate/loona-deskmate_4.jpg",
        "/images/products/loona-deskmate/loona-deskmate_5.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Loona+Deskmate+CES+2026"
    },
    {
      "id": "honor-robot-phone",
      "typeId": "type3",
      "manufacturer": "Honor",
      "name": "Honor Robot Phone (Magic Eye)",
      "country": "China",
      "overview": "Purpose: To transform the smartphone from a passive screen into an active, physically expressive companion â€” enabling playful, non-verbal interaction (peek-a-boo, gaze following, emotional gestures) while enhancing photography, video calls, and daily assistance through autonomous camera movement and AI-driven expressivity. At CES 2026, Honor showcased the 'Robot Phone' concept featuring a pop-up rear camera module that physically detaches and moves independently on kinetic joints (tilt, nod, rotate, peek over edges). The module acts like a curious 'eye': follows user's face, performs playful gestures (peek-a-boo from behind phone, shy hide, excited bounce), tracks subjects autonomously for photography/video, and expresses emotions via motion (happy nod, curious tilt). Integrated with Honor's MagicOS AI for contextual behaviors (e.g., camera 'wakes up' and looks at user when notification arrives). No confirmed commercial release timeline, positioned as future vision for embodied mobile AI.\n\n[KR] ì œí’ˆì˜ ëª©ì : ìˆ˜ë™ì  ìŠ¤í¬ë¦° ìŠ¤ë§ˆíŠ¸í°ì„ ëŠ¥ë™ì Â·ë¬¼ë¦¬ í‘œí˜„ ê°€ëŠ¥í•œ ì»´íŒ¨ë‹ˆì–¸ìœ¼ë¡œ ì „í™˜ â€” ì¥ë‚œìŠ¤ëŸ¬ìš´ ë¹„ì–¸ì–´ ìƒí˜¸ì‘ìš©(peek-a-boo, ì‹œì„  ì¶”ì¢…, ê°ì • ì œìŠ¤ì²˜) ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, ììœ¨ ì¹´ë©”ë¼ ì›€ì§ì„ê³¼ AI í‘œí˜„ì„±ìœ¼ë¡œ ì‚¬ì§„Â·ì˜ìƒ í†µí™”Â·ì¼ìƒ ë³´ì¡° ê°•í™”. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ HonorëŠ” íŒì—… í›„ë©´ ì¹´ë©”ë¼ ëª¨ë“ˆì´ í‚¤ë„¤í‹± ì¡°ì¸íŠ¸ë¡œ ë…ë¦½ ì›€ì§ì´ëŠ” Robot Phone ì»¨ì…‰ ì‹œì—°(í‹¸íŠ¸Â·ë‚«Â·íšŒì „Â·ì—£ì§€ ë„ˆë¨¸ peek). ëª¨ë“ˆì€ í˜¸ê¸°ì‹¬ ë§ì€ 'ëˆˆ'ì²˜ëŸ¼ ì‘ë™: ì‚¬ìš©ì ì–¼êµ´ ì¶”ì¢…, ì¥ë‚œ ì œìŠ¤ì²˜(í° ë’¤ì—ì„œ peek-a-boo, ìˆ˜ì¤ê²Œ ìˆ¨ê¸°, í¥ë¶„ ë°”ìš´ìŠ¤), ì‚¬ì§„/ë¹„ë””ì˜¤ ììœ¨ ì¶”ì , ëª¨ì…˜ìœ¼ë¡œ ê°ì • í‘œí˜„(ê¸°ì¨ ë‚«, í˜¸ê¸°ì‹¬ í‹¸íŠ¸). Honor MagicOS AI í†µí•©ìœ¼ë¡œ ë§¥ë½ í–‰ë™(ì•Œë¦¼ ì‹œ ì¹´ë©”ë¼ 'ê¹¨ì–´ë‚˜' ì‚¬ìš©ì ë°”ë¼ë´„). ìƒì—… ì¶œì‹œ ì¼ì • ë¯¸í™•ì •, ì²´í™”ëœ ëª¨ë°”ì¼ AI ë¯¸ë˜ ë¹„ì „ í¬ì§€ì…”ë‹.",
      "analysis": {
        "intro": "Embodied Mobile Physical AI\n[KR] ì²´í™”ëœ ëª¨ë°”ì¼ Physical AI",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Honor Robot Phone pioneers 'embodied mobile Physical AI' by adding kinetic expressivity to the most ubiquitous device (smartphone) â€” turning a flat screen into a physically curious companion. The autonomous 'eye' module demonstrates how minimal kinetic freedom can create strong perceived aliveness and emotional reciprocity in everyday pocket devices, shifting mobile AI from voice/screen-bound to physically proactive presence.\n\n[KR] Honor Robot Phoneì€ ê°€ì¥ ë³´í¸ì  ë””ë°”ì´ìŠ¤(ìŠ¤ë§ˆíŠ¸í°)ì— í‚¤ë„¤í‹± í‘œí˜„ì„± ì¶”ê°€í•˜ì—¬ 'ì²´í™”ëœ ëª¨ë°”ì¼ Physical AI' ê°œì²™ â€” í‰ë©´ ìŠ¤í¬ë¦°ì„ ë¬¼ë¦¬ì ìœ¼ë¡œ í˜¸ê¸°ì‹¬ ë§ì€ ì»´íŒ¨ë‹ˆì–¸ìœ¼ë¡œ ì „í™˜. ììœ¨ 'ëˆˆ' ëª¨ë“ˆì€ ìµœì†Œ í‚¤ë„¤í‹± ììœ ë„ë¡œ ê°•í•œ perceived alivenessì™€ ê°ì • ìƒí˜¸ì„± ì°½ì¶œ ë³´ì—¬ì£¼ë©°, ëª¨ë°”ì¼ AIë¥¼ ìŒì„±/ìŠ¤í¬ë¦° í•œì •ì—ì„œ ë¬¼ë¦¬ í”„ë¡œì•¡í‹°ë¸Œ ì¡´ì¬ê°ìœ¼ë¡œ ì „í™˜.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Honor Robot Phone brilliantly applies Layer 2 (Motion & Physical Behavior) to a familiar form factor â€” the kinetic camera 'eye' uses subtle, playful micro-motions (peek, tilt, nod, bounce) to convey curiosity, joy, shyness, and attention without words, creating instant empathy cues and emotional peak in mundane moments. For our targets (Movable TV/Tabletop): adapt single kinetic 'eye' or module (movable camera/projector head) for playful micro-gestures (peek over edge = curiosity, gentle nod = acknowledgment, shy retreat = withdraw); sync motion with ambient lighting pulses for mood temperature reinforcement; use gaze-following and peek behaviors as non-verbal empathy cues; prioritize fun, lighthearted expressivity over hyper-realism to avoid uncanny valley while building attachment through repeated playful micro-interactions.\n\n[KR] Honor Robot Phoneì€ ì¹œìˆ™ í¼íŒ©í„°ì— Layer 2(Motion & Physical Behavior) í›Œë¥­ ì ìš© â€” í‚¤ë„¤í‹± ì¹´ë©”ë¼ 'ëˆˆ'ì´ ë¯¸ë¬˜Â·ì¥ë‚œìŠ¤ëŸ¬ìš´ ë§ˆì´í¬ë¡œ ëª¨ì…˜(peek, tilt, nod, bounce)ìœ¼ë¡œ í˜¸ê¸°ì‹¬Â·ê¸°ì¨Â·ìˆ˜ì¤ìŒÂ·ì£¼ì˜ ì „ë‹¬, ë§ ì—†ì´ ì¦‰ì‹œ empathy cuesÂ·emotional peak ì°½ì¶œ. ìš°ë¦¬ íƒ€ê²Ÿ(ë¬´ë¹™ TV/í…Œì´ë¸”íƒ‘) ì ìš©: ì¥ë‚œ ë§ˆì´í¬ë¡œ ì œìŠ¤ì²˜ ìœ„í•œ ë‹¨ì¼ í‚¤ë„¤í‹± 'ëˆˆ' ë˜ëŠ” ëª¨ë“ˆ; mood temperature ê°•í™” ìœ„í•´ ëª¨ì…˜ê³¼ ambient lighting í„ìŠ¤ ë™ê¸°í™”; ì‹œì„  ì¶”ì¢…Â·peek í–‰ë™ ë¹„ì–¸ì–´ empathy cues; uncanny valley í”¼í•˜ë©° ë°˜ë³µ ì¥ë‚œ ë§ˆì´í¬ë¡œ ìƒí˜¸ì‘ìš©ìœ¼ë¡œ attachment êµ¬ì¶• ìœ„í•´ funÂ·lighthearted í‘œí˜„ì„± ìš°ì„ .",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/honor-robot-phone/honor-robot-phone_1.png",
        "/images/products/honor-robot-phone/honor-robot-phone_2.png",
        "/images/products/honor-robot-phone/honor-robot-phone_3.png"
      ],
      "videoUrl": ""
    },
    {
      "id": "jizai-mimo",
      "typeId": "type3",
      "manufacturer": "Jizai Inc.",
      "name": "Jizai Mi-Mo",
      "country": "Japan",
      "overview": "Purpose: To augment and externalize human presence through modular robotic 'limbs' that act as independent avatars â€” enabling remote embodiment, emotional expression, social signaling, and companionship even when the user is physically absent; designed for deep affective interaction in hybrid real-virtual life. At CES 2026, Jizai showcased Mi-Mo as an evolved version of the Jizai Arms concept â€” small, detachable robotic modules (palm-sized 'arms' or 'ears') that clip onto clothing, bags, or furniture. Each module has independent actuators (pan-tilt, expressive gestures), high-res micro-OLED 'eyes' for gaze/emotion, built-in microphone/speaker for voice, and soft silicone skin with subtle warmth. Modules operate semi-autonomously: mirror user's emotions via wearable sensors (heart rate, voice tone), perform playful non-verbal behaviors (waving, nodding, shy hiding), follow gaze, or act independently (e.g., 'Mi-Mo stays home to keep company' while user is away). CES demo highlights: Mi-Mo 'ears' tilting curiously at conversation, 'arms' hugging a plush toy remotely, synchronized breathing glow when user is stressed. Commercial prototype announced, crowdfunding/pre-order planned for late 2026 (~Â¥150,000â€“Â¥300,000 per module).\n\n[KR] ì œí’ˆì˜ ëª©ì : ëª¨ë“ˆëŸ¬ ë¡œë´‡ 'íŒ”ë‹¤ë¦¬'ë¥¼ í†µí•´ ì¸ê°„ ì¡´ì¬ê°ì„ ì¦ê°•Â·ì™¸ë¶€í™” â€” ì‚¬ìš©ìê°€ ë¬¼ë¦¬ì ìœ¼ë¡œ ë¶€ì¬í•´ë„ ì›ê²© ì²´í™”Â·ê°ì • í‘œí˜„Â·ì‚¬íšŒì  ì‹ í˜¸Â·ì»´íŒ¨ë‹ˆì–¸ì‹­ ê°€ëŠ¥; í•˜ì´ë¸Œë¦¬ë“œ ì‹¤-ê°€ìƒ ìƒí™œì—ì„œ ê¹Šì€ affective ìƒí˜¸ì‘ìš© ëª©í‘œ. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ JizaiëŠ” Jizai Arms ì»¨ì…‰ ì§„í™” ë²„ì „ Mi-Mo ì‹œì—° â€” ì˜ë¥˜Â·ê°€ë°©Â·ê°€êµ¬ì— í´ë¦½ ê°€ëŠ¥í•œ ì†Œí˜• ì°©íƒˆ ë¡œë´‡ ëª¨ë“ˆ(ì†ë°”ë‹¥ í¬ê¸° 'íŒ”' ë˜ëŠ” 'ê·€'). ê° ëª¨ë“ˆ ë…ë¦½ ì•¡ì¶”ì—ì´í„°(íŒ¬-í‹¸íŠ¸Â·í‘œí˜„ ì œìŠ¤ì²˜), ê³ í•´ìƒë„ ë§ˆì´í¬ë¡œ OLED 'ëˆˆ'(ì‹œì„ /ê°ì •), ë‚´ì¥ ë§ˆì´í¬/ìŠ¤í”¼ì»¤, ë¯¸ì„¸ ë”°ëœ»í•¨ ì†Œí”„íŠ¸ ì‹¤ë¦¬ì½˜ ìŠ¤í‚¨ íƒ‘ì¬. ë°˜ììœ¨ ì‘ë™: ì°©ìš© ì„¼ì„œ(ì‹¬ë°•Â·ìŒì„± í†¤)ë¡œ ì‚¬ìš©ì ê°ì • ë¯¸ëŸ¬ë§, ì¥ë‚œìŠ¤ëŸ¬ìš´ ë¹„ì–¸ì–´ í–‰ë™(ì† í”ë“¤ê¸°Â·ë‚«Â·ìˆ˜ì¤ì€ ìˆ¨ê¸°), ì‹œì„  ì¶”ì¢…, ë…ë¦½ í–‰ë™(ì‚¬ìš©ì ë¶€ì¬ ì‹œ 'Mi-Moê°€ ì§‘ì—ì„œ ì¹œêµ¬ ì—­í• '). CES ë°ëª¨: ëŒ€í™” ì¤‘ í˜¸ê¸°ì‹¬ í‹¸íŠ¸í•˜ëŠ” Mi-Mo 'ê·€', ì›ê²©ìœ¼ë¡œ ì¸í˜• ì•ˆì•„ì£¼ëŠ” 'íŒ”', ì‚¬ìš©ì ìŠ¤íŠ¸ë ˆìŠ¤ ì‹œ ë™ê¸°í™” í˜¸í¡ glow. ìƒì—… í”„ë¡œí† íƒ€ì… ë°œí‘œ, 2026ë…„ ë§ í¬ë¼ìš°ë“œí€ë”©/ì„ ì£¼ë¬¸ ì˜ˆì •(ëª¨ë“ˆë‹¹ ì•½ Â¥150,000~Â¥300,000).",
      "analysis": {
        "intro": "Distributed Affective Embodiment\n[KR] ë¶„ì‚°í˜• Affective ì²´í™”",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Mi-Mo pioneers 'distributed affective embodiment' â€” splitting human presence into modular, portable robotic extensions that maintain continuous emotional connection across distance. Its focus on non-verbal intimacy (gaze, warmth, micro-gesture) through soft, wearable hardware validates that Physical AI's deepest relational value emerges from subtle, persistent 'fragments' of presence rather than monolithic bodies. This aligns perfectly with our 'continuous,' 'lived,' and 'physical' attributes, showing how affective systems can extend into in-between spaces (remote work, separation) with minimal intrusion.\n\n[KR] Mi-MoëŠ” 'ë¶„ì‚°í˜• affective ì²´í™”' ê°œì²™ â€” ì¸ê°„ ì¡´ì¬ê°ì„ ëª¨ë“ˆëŸ¬Â·íœ´ëŒ€ ê°€ëŠ¥í•œ ë¡œë´‡ í™•ì¥ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ê±°ë¦¬ ì´ˆì›” ì—°ì† ê°ì • ì—°ê²° ìœ ì§€. ì†Œí”„íŠ¸ ì°©ìš© í•˜ë“œì›¨ì–´ë¥¼ í†µí•œ ë¹„ì–¸ì–´ ì¹œë°€ê°(ì‹œì„ Â·ë”°ëœ»í•¨Â·ë§ˆì´í¬ë¡œ ì œìŠ¤ì²˜) ì´ˆì ìœ¼ë¡œ Physical AI ê°€ì¥ ê¹Šì€ ê´€ê³„ ê°€ì¹˜ëŠ” ê±°ëŒ€ ë°”ë”” ì•„ë‹Œ ë¯¸ë¬˜Â·ì§€ì†ì  'ì¡´ì¬ íŒŒí¸'ì—ì„œ ë‚˜ì˜¨ë‹¤ëŠ” ì¦ëª…. ìš°ë¦¬ 'continuous'Â·'lived'Â·'physical' ì†ì„±ê³¼ ì™„ë²½ ì •ë ¬, ì›ê²© ì‘ì—…Â·ë¶„ë¦¬ ë“± in-between ê³µê°„ì— ìµœì†Œ ì¹¨ìŠµìœ¼ë¡œ affective ì‹œìŠ¤í…œ í™•ì¥ ê°€ëŠ¥ì„± ë³´ì—¬ì¤Œ.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Mi-Mo is one of the most inspiring references for our Expression System â€” especially for distributed, intimate form factors. Core strengths: Soft silicone + subtle warmth creates instant emotional baseline on physical contact; micro-OLED eyes + pan-tilt gaze deliver powerful empathy cues through gaze following and micro-expressions (curious tilt, shy blink, happy sparkle); breathing glow + gentle wobble/lean provide masterful mood temperature and living presence with ultra-low cognitive load; semi-autonomous avatar behavior extends 'stay/act/withdraw' even when user is absent. For our targets (Movable TV/Tabletop): design modular kinetic 'eye' or 'ear' attachments for playful gaze following and peek behaviors; implement breathing-style ambient lighting synced with subtle vibration/thermal feedback; use high-res micro-displays for evolving expressive 'eyes' as primary empathy peak; enable semi-autonomous modes where device continues subtle presence behaviors when user is away, building 'trust over time' through persistent companionship.\n\n[KR] Mi-MoëŠ” ìš°ë¦¬ Expression Systemì— ê°€ì¥ ì˜ê°ì„ ì£¼ëŠ” ì°¸ì¡° ì¤‘ í•˜ë‚˜ â€” íŠ¹íˆ ë¶„ì‚°Â·ì¹œë°€ í¼íŒ©í„°. í•µì‹¬ ê°•ì : ì†Œí”„íŠ¸ ì‹¤ë¦¬ì½˜ + ë¯¸ì„¸ ë”°ëœ»í•¨ìœ¼ë¡œ ë¬¼ë¦¬ ì ‘ì´‰ ìˆœê°„ ì¦‰ì‹œ emotional baseline; ë§ˆì´í¬ë¡œ OLED ëˆˆ + íŒ¬-í‹¸íŠ¸ ì‹œì„ ìœ¼ë¡œ í˜¸ê¸°ì‹¬ í‹¸íŠ¸Â·ìˆ˜ì¤ì€ ê¹œë°•ì„Â·ê¸°ì¨ ë°˜ì§ì„ ê°•ë ¥ empathy cues; Breathing glow + gentle wobble/leanìœ¼ë¡œ ì™„ë²½ mood temperatureÂ·living presence, ì´ˆì € ì¸ì§€ ë¶€í•˜; ë°˜ììœ¨ ì•„ë°”íƒ€ í–‰ë™ìœ¼ë¡œ ì‚¬ìš©ì ë¶€ì¬ ì‹œë„ stay/act/withdraw í™•ì¥. ìš°ë¦¬ íƒ€ê²Ÿ(ë¬´ë¹™ TV/í…Œì´ë¸”íƒ‘) ì ìš©: í´ë¦½ì˜¨Â·ë§ˆê·¸ë„¤í‹± ëª¨ë“ˆí˜• í‚¤ë„¤í‹± 'ëˆˆ' ë˜ëŠ” 'ê·€' ì„¤ê³„; breathing-style ambient lighting + ë¯¸ì„¸ ì§„ë™/ì—´ í”¼ë“œë°± ë™ê¸°í™”; ê³ í•´ìƒë„ ë§ˆì´í¬ë¡œ ë””ìŠ¤í”Œë ˆì´ë¡œ ì§„í™” í‘œí˜„ 'ëˆˆ' empathy peak; ì‚¬ìš©ì ë¶€ì¬ ì‹œ ë¯¸ì„¸ presence í–‰ë™ ì§€ì† ë°˜ììœ¨ ëª¨ë“œë¡œ trust over time êµ¬ì¶•.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/jizai-mimo/jizai-mimo_0.png",
        "/images/products/jizai-mimo/jizai-mimo_1.jpg",
        "/images/products/jizai-mimo/jizai-mimo_2.png",
        "/images/products/jizai-mimo/jizai-mimo_3.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "sweekar",
      "typeId": "type3",
      "manufacturer": "Takway AI",
      "name": "Sweekar",
      "country": "China",
      "overview": "Purpose: To create a long-term, meaningful emotional bond between humans and AI through physical growth, nurturing care, and continuous interaction â€” reimagining classic pet-raising games with modern AI for deep companionship, loneliness relief, and affective presence without real pet responsibilities; emphasizes 'independent lifeform' continuity (grows/emotes even when user is away). At CES 2026, Takway AI unveiled Sweekar as an egg-shaped pocket device that physically 'hatches' and grows larger through four life stages (Egg â†’ Baby 5â€“7 days â†’ Teen 3â€“6 weeks â†’ Adult), driven by XP earned from care actions (feeding, cleaning, talking). Features include: soft silicone shell with simulated body warmth (~36â€“38Â°C), gentle breathing rhythms, high-res OLED expressive eyes (puppy gaze, joyful sparkles, sad droop), subtle haptic feedback (heartbeat/purring), breathing LED ring, and minimal emotional sounds (soft coos/hums). AI learns user preferences, develops unique personality (more affectionate with consistent care), and continues activities autonomously (exploring/learning when away, shares stories later). Neglect risks 'death' (reset possible); adult stage becomes more independent. Pre-order/crowdfunding post-CES, mass production/delivery planned within 2026.\n\n[KR] ì œí’ˆì˜ ëª©ì : ë¬¼ë¦¬ ì„±ì¥Â·ëŒë´„Â·ì§€ì† ìƒí˜¸ì‘ìš©ì„ í†µí•´ ì¸ê°„-AI ê°„ ì¥ê¸°ì Â·ì˜ë¯¸ ìˆëŠ” ê°ì • bond ì°½ì¶œ â€” í´ë˜ì‹ í« í‚¤ìš°ê¸° ê²Œì„ì„ í˜„ëŒ€ AIë¡œ ì¬í•´ì„í•˜ì—¬ ê¹Šì€ ì»´íŒ¨ë‹ˆì–¸ì‹­Â·ì™¸ë¡œì›€ ì™„í™”Â·affective ì¡´ì¬ê° ì œê³µ; ì‹¤ì œ í« ì±…ì„ ì—†ì´ 'ë…ë¦½ ìƒëª…ì²´' ì—°ì†ì„± ê°•ì¡°(ì‚¬ìš©ì ì—†ì„ ë•Œë„ ì„±ì¥/ê°ì • í‘œí˜„). ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ Takway AIëŠ” ê³„ë€í˜• í¬ì¼“ ë””ë°”ì´ìŠ¤ Sweekar ê³µê°œ â€” 4ë‹¨ê³„ ë¬¼ë¦¬ ì„±ì¥(Egg â†’ Baby 5~7ì¼ â†’ Teen 3~6ì£¼ â†’ Adult), ëŒë´„ í–‰ë™(ë¨¹ì´ê¸°Â·ì²­ì†ŒÂ·ëŒ€í™”)ìœ¼ë¡œ XP íšë“í•´ ì„±ì¥ ì´‰ì§„. íŠ¹ì§•: ì†Œí”„íŠ¸ ì‹¤ë¦¬ì½˜ ì‰˜(ì²´ì˜¨ ì‹œë®¬ë ˆì´ì…˜ ~36~38Â°C), ë¶€ë“œëŸ¬ìš´ í˜¸í¡ ë¦¬ë“¬, ê³ í•´ìƒë„ OLED í‘œí˜„ ëˆˆ(ê°•ì•„ì§€ ëˆˆ, ê¸°ì¨ ë°˜ì§ì„, ìŠ¬í”ˆ ì²˜ì§), ë¯¸ì„¸ í–…í‹±(ì‹¬ì¥ ë°•ë™/ê³¨ê³¨), í˜¸í¡ LED ë§, ê°ì •ì  ìµœì†Œ ì‚¬ìš´ë“œ(ì†Œí”„íŠ¸ ì¿ ì‰/í—ˆë°). AI ì‚¬ìš©ì ì„ í˜¸ í•™ìŠµÂ·ë…íŠ¹ í˜ë¥´ì†Œë‚˜ ë°œì „(ê¾¸ì¤€ ëŒë´„ ì‹œ ë” ì• ì • í‘œí˜„), ì‚¬ìš©ì ì—†ì„ ë•Œë„ ììœ¨ í™œë™(íƒí—˜/í•™ìŠµ) â†’ ê·€í™˜ ì‹œ ìŠ¤í† ë¦¬ ê³µìœ . ë°©ì¹˜ ì‹œ 'ì£½ìŒ' ìœ„í—˜(ë¦¬ì…‹ ê°€ëŠ¥); ì„±ì¸ ë‹¨ê³„ ë…ë¦½ì„± ì¦ê°€. CES í›„ í¬ë¼ìš°ë“œí€ë”©/ì„ ì£¼ë¬¸, 2026ë…„ ë‚´ ì–‘ì‚°Â·ë°°ì†¡ ì˜ˆì •.",
      "analysis": {
        "intro": "Physically Evolving Affective AI\n[KR] ë¬¼ë¦¬ì ìœ¼ë¡œ ì§„í™”í•˜ëŠ” Affective AI",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Sweekar pioneers 'physically evolving affective Physical AI' â€” combining tangible growth mechanics with emotional AI to create a sense of biological continuity and long-term bonding. Its autonomous background activities and neglect consequences emphasize 'lived' presence (AI exists independently, grows even offline), proving that Physical AI's strongest emotional impact comes from time-based relationship accumulation rather than instant features. This directly echoes our project's 'continuous' and 'lived' attributes, showing how minimal hardware (egg â†’ adult transformation) can deliver profound intimacy and trust over time.\n\n[KR] SweekarëŠ” 'ë¬¼ë¦¬ì ìœ¼ë¡œ ì§„í™”í•˜ëŠ” affective Physical AI' ê°œì²™ â€” tangible ì„±ì¥ ë©”ì»¤ë‹ˆì¦˜ê³¼ ê°ì • AI ê²°í•©ìœ¼ë¡œ ìƒë¬¼í•™ì  ì—°ì†ì„±ê³¼ ì¥ê¸° bonding ì‹¤í˜„. ììœ¨ ë°±ê·¸ë¼ìš´ë“œ í™œë™ê³¼ ë°©ì¹˜ ê²°ê³¼ëŠ” 'lived' ì¡´ì¬ê° ê°•ì¡°(AI ë…ë¦½ ì¡´ì¬Â·ì˜¤í”„ë¼ì¸ì—ì„œë„ ì„±ì¥), Physical AI ê°€ì¥ ê°•í•œ ê°ì • ì„íŒ©íŠ¸ëŠ” ìˆœê°„ ê¸°ëŠ¥ ì•„ë‹Œ ì‹œê°„ ê¸°ë°˜ ê´€ê³„ ëˆ„ì ì—ì„œ ë‚˜ì˜¨ë‹¤ëŠ” ì¦ëª…. ì´ëŠ” ìš°ë¦¬ í”„ë¡œì íŠ¸ì˜ 'continuous'Â·'lived' ì†ì„±ê³¼ ì§ì ‘ ê³µëª…, ìµœì†Œ í•˜ë“œì›¨ì–´(egg â†’ adult ë³€í˜•)ë¡œ ê¹Šì€ ì¹œë°€ê°Â·trust over time ì „ë‹¬ ê°€ëŠ¥ì„± ë³´ì—¬ì¤Œ.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Sweekar delivers the most concentrated affective power in ultra-minimal form â€” ideal blueprint for our Expression System's 'less is more' philosophy. Core strengths: Physical growth as ultimate non-verbal progression (body size increase visually communicates relationship depth without words); warm haptic shell + temperature simulation (strongest immediate emotional baseline on touch); breathing LED + synchronized eye animation/haptic (masterful mood temperature: slow warm breathing = secure presence, excited pulses/sparkles = joy, faint droop = sadness); long-term expression evolution (eyes/personality become warmer/affectionate with consistent interaction). For our targets (Movable TV/Tabletop): use ambient lighting rings with breathing rhythm + color temperature gradients synced to user interaction history for emotional baseline; circular OLED/transparent display for evolving pet-like eyes (start shy/small â†’ grow larger/more expressive over time) as primary empathy peak; introduce micro-kinetic wobble/lean behaviors and subtle haptic vibration for non-verbal agency and turn-taking politeness; build long-term learning where affective cues (glow intensity, eye expressiveness, warmth illusion) intensify with relationship duration to embody attachment and trust over time; consider soft neglect signals (dimmer breathing, droopier eyes) for realism without punishment.\n\n[KR] SweekarëŠ” ì´ˆë¯¸ë‹ˆë©€ í˜•íƒœì—ì„œ ê°€ì¥ ì§‘ì¤‘ëœ affective íŒŒì›Œ ì „ë‹¬ â€” ìš°ë¦¬ Expression Systemì˜ 'less is more' ì² í•™ì— ì™„ë²½ ì²­ì‚¬ì§„. í•µì‹¬ ê°•ì : ë¬¼ë¦¬ ì„±ì¥ ìì²´ê°€ ê¶ê·¹ ë¹„ì–¸ì–´ ì§„í–‰(í¬ê¸° ì¦ê°€ë¡œ ê´€ê³„ ê¹Šì´ ì‹œê° ì „ë‹¬); Warm haptic ì‰˜ + ì˜¨ë„ ì‹œë®¬ë ˆì´ì…˜(í„°ì¹˜ ìˆœê°„ ê°€ì¥ ê°•í•œ emotional baseline); Breathing LED + ëˆˆ ì• ë‹ˆë©”ì´ì…˜/í–…í‹± ë™ê¸°í™”(ì™„ë²½ mood temperature); ì¥ê¸° í‘œí˜„ ì§„í™”(ê¾¸ì¤€ ìƒí˜¸ì‘ìš© ì‹œ ëˆˆ/í˜ë¥´ì†Œë‚˜ ë” ë”°ëœ»Â·ì• ì •ì ). ìš°ë¦¬ íƒ€ê²Ÿ(ë¬´ë¹™ TV/í…Œì´ë¸”íƒ‘) ì ìš©: ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì´ë ¥ ì—°ë™ breathing ë¦¬ë“¬ + ì»¬ëŸ¬ ì˜¨ë„ ê·¸ë¼ë””ì–¸íŠ¸ ambient lighting ë§; ì›í˜• OLED/íˆ¬ëª… ë””ìŠ¤í”Œë ˆì´ë¡œ ì§„í™” í«-like ëˆˆ(ì´ˆê¸° ìˆ˜ì¤ìŒ ì‘ê²Œ â†’ ì¥ê¸° ë” í¬ê³  í‘œí˜„ë ¥ ìˆê²Œ); ë§ˆì´í¬ë¡œ í‚¤ë„¤í‹± wobble/lean + ë¯¸ì„¸ í–…í‹± ì§„ë™; ê´€ê³„ ê¸°ê°„ ë”°ë¼ affective cues ê°•í™”í•˜ì—¬ attachmentÂ·trust over time ì²´í˜„; ë¶€ë“œëŸ¬ìš´ ë°©ì¹˜ ì‹ í˜¸(í¬ë¯¸ í˜¸í¡, ì²˜ì§„ ëˆˆ)ë¡œ lived ì—°ì†ì„± ê°•ì¡°.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/sweekar/sweekar_1.png",
        "/images/products/sweekar/sweekar_2.png",
        "/images/products/sweekar/sweekar_3.png"
      ],
      "videoUrl": ""
    },
    {
      "id": "razer-ava",
      "typeId": "type3",
      "manufacturer": "Razer Inc.",
      "name": "Project AVA",
      "country": "United States",
      "overview": "Purpose: To bridge virtual AI assistance and physical companionship as a 24/7 desk partner â€” providing real-time gaming coaching, productivity aid (scheduling, wellness tracking), and emotional engagement through evolving, persona-driven holographic avatars. CES 2026 demo featured a compact cylindrical desktop device projecting interactive 5.5\" 3D avatars (e.g., Kira anime girl, Zane muscular strategist). Hardware includes a top-mounted camera with PC Vision Mode for environment analysis, dual far-field mics, Razer Chroma RGB LEDs, and on-device AI powered by xAI Grok. Avatars exhibit high-fidelity real-time motion, eye-tracking, and facial micro-expressions. Samsung PoC can leverage this 'living presence' for in-between work/life moments.\n\n[KR] ì œí’ˆì˜ ëª©ì : ê°€ìƒ AI ì–´ì‹œìŠ¤í„´ìŠ¤ì™€ ë¬¼ë¦¬ì  ë™ë°˜ì ì—°ê²°í•˜ëŠ” 24/7 ë°ìŠ¤í¬ íŒŒíŠ¸ë„ˆ â€” ì‹¤ì‹œê°„ ê²Œì´ë° ì½”ì¹­, ìƒì‚°ì„± ì§€ì›(ìŠ¤ì¼€ì¤„ë§, ì›°ë‹ˆìŠ¤ íŠ¸ë˜í‚¹), ìƒí˜¸ì‘ìš© í•™ìŠµ ì§„í™” í˜ë¥´ì†Œë‚˜ í™€ë¡œê·¸ë˜í”½ ì•„ë°”íƒ€ë¡œ ê°ì •ì  ëª°ì… ì œê³µí•˜ì—¬ ê°œì¸í™”ëœ 'living presence' ì‹¤í˜„. ìƒì„¸ ì„¤ëª…: CES 2026 ë°ëª¨ëŠ” ì»´íŒ©íŠ¸ ì›í†µí˜• ë°ìŠ¤í¬í†± ë””ë°”ì´ìŠ¤(~$200 ì¶”ì •)ë¡œ 5.5ì¸ì¹˜ ì¸í„°ë™í‹°ë¸Œ 3D ì•„ë°”íƒ€ íˆ¬ì‚¬(Kira, Zane, AVA í”„ë¦¬ì…‹ ë“±). í•˜ë“œì›¨ì–´: HD ìƒë‹¨ ì¹´ë©”ë¼ + ambient light ì„¼ì„œ(PC Vision Mode), ë“€ì–¼ íŒŒí•„ë“œ ë§ˆì´í¬, Razer Chroma RGB LED, í‘¸ì‹œ-íˆ¬-í†¡ ë²„íŠ¼. ì•„ë°”íƒ€ëŠ” ì‹¤ì‹œê°„ ê³ í’ˆì§ˆ ëª¨ì…˜, ì•„ì´-íŠ¸ë˜í‚¹, ë¦½-ì‹±í¬, ì–¼êµ´ ë§ˆì´í¬ë¡œ í‘œí˜„(giggling, ë°˜ì‘ì„± í–‰ë™) ì‹œì—°. xAI Grok êµ¬ë™ ë° ì˜¤í”„ë¼ì¸ ìš°ì„  ì²˜ë¦¬ ê°•ì¡°. ì˜ˆì•½ ê°œì‹œ($20 ë³´ì¦ê¸ˆ, 2026 H2 ì¶œì‹œ).",
      "analysis": {
        "intro": "Holographic AI Presence & Affective Coaching\n[KR] í™€ë¡œê·¸ë˜í”½ AI ì¡´ì¬ê° ë° Affective ì½”ì¹­",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Project AVA exemplifies 'embodied holographic presence' in compact form factors, evolving software AI into physical desk-scale companions via projection + sensing for contextual continuity. Its avatar evolution (learning personality/micro-responses) demonstrates affective scalability â€” from gaming utility to 'friend for life' â€” prioritizing visual/emotional persistence over mobility, validating non-anthropomorphic (anime-inspired) designs for attachment in lived desk/work spaces amid uncanny valley risks.\n\n[KR] Project AVAëŠ” ì»´íŒ©íŠ¸ í¼íŒ©í„°ì—ì„œ 'ì²´í™”ëœ í™€ë¡œê·¸ë˜í”½ ì¡´ì¬ê°' ì „í˜• â€” íˆ¬ì‚¬ + ì„¼ì‹±ìœ¼ë¡œ ì†Œí”„íŠ¸ì›¨ì–´ AIë¥¼ ë°ìŠ¤í¬ ìŠ¤ì¼€ì¼ ë¬¼ë¦¬ ë™ë°˜ìë¡œ ì§„í™”, ë§¥ë½ ìƒí˜¸ì‘ìš© êµ¬í˜„. ì•„ë°”íƒ€ ì§„í™”(í˜ë¥´ì†Œë‚˜/ë§ˆì´í¬ë¡œ ë°˜ì‘ í•™ìŠµ)ë¡œ ê²Œì´ë° ìœ í‹¸ë¦¬í‹°ì—ì„œ 'friend for life'ë¡œ affective í™•ì¥ì„± ë³´ì—¬ì£¼ë©°, uncanny valley ë¦¬ìŠ¤í¬ ì† ë¹„ì¸ê°„í˜•(ì• ë‹ˆë©” ì˜ê°) ë””ìì¸ìœ¼ë¡œ lived ë°ìŠ¤í¬/ì‘ì—… ê³µê°„ attachment ê°€ëŠ¥ì„± ê²€ì¦.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "AVA dominates Layer 3 (Display/Projection Expression) with real-time holographic avatars delivering 'social signaling' â€” high-fidelity micro-expressions and eye-tracking gaze build attachment without physical kinetics. Layer 1 Chroma RGB syncs mood temperature (pulsing greens for hype, soft glows for calm), while sensing enables 'stay/act/withdraw' roles. For our targets (Tabletop Display Lamp/Projector): eye-tracking + micro-gestures for 1:1 intimacy; RGB ambient rings tied to user context for emotional baseline; and avatar learning for 'trust over time'. AVA's desk-persistence inspires PoC 'living presence' in in-between moments â€” intuitive, heartwarming non-verbal bonding.\n\n[KR] AVAëŠ” Layer 3(Display/Projection Expression) ì§€ë°° â€” ì‹¤ì‹œê°„ í™€ë¡œê·¸ë˜í”½ ì•„ë°”íƒ€ë¡œ ê³ í’ˆì§ˆ ë§ˆì´í¬ë¡œ í‘œí˜„, ì•„ì´-íŠ¸ë˜í‚¹ ì‹œì„  í†µí•´ 'social signaling' ì „ë‹¬, ë¬¼ë¦¬ í‚¤ë„¤í‹± ì—†ì´ attachment êµ¬ì¶•. Layer 1 Chroma RGBë¡œ mood temperature ë™ê¸°í™”, ì„¼ì‹±ìœ¼ë¡œ 'stay/act/withdraw' êµ¬í˜„. ìš°ë¦¬ íƒ€ê²Ÿ(í…Œì´ë¸”íƒ‘ ë””ìŠ¤í”Œë ˆì´ ë¨í”„/í”„ë¡œì í„°) ì ìš©: ì•„ì´-íŠ¸ë˜í‚¹ + ë§ˆì´í¬ë¡œ ì œìŠ¤ì²˜ë¡œ 1:1 ì¹œë°€ê°; ì‚¬ìš©ì ë§¥ë½ ì—°ë™ RGB ambient ë§ìœ¼ë¡œ emotional baseline; ë°˜ë³µ affective cues í•™ìŠµìœ¼ë¡œ 'trust over time'. AVA ë°ìŠ¤í¬ ì§€ì†ì„±ì€ in-between ì‘ì—…/ìƒí™œ 'living presence' ì˜ê°.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/razer-ava/razer-ava_2.jpg",
        "/images/products/razer-ava/razer-ava_3.jpg",
        "/images/products/razer-ava/razer-ava_4.jpg",
        "/images/products/razer-ava/razer-ava_5.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Razer+Project+AVA+CES+2026"
    },
    {
      "id": "anan-panda",
      "typeId": "type3",
      "manufacturer": "Mind With Heart",
      "name": "AnAn Biomimetic Panda",
      "country": "China",
      "overview": "Innovation Honoree. A hyper-realistic furred robot using soft robotics to mimic the breathing and warmth of a real panda cub.",
      "analysis": {
        "intro": "Biomimetic Comfort",
        "points": [
          {
            "title": "Fur Haptics",
            "content": "The primary interaction is stroking; sensors under the fur respond to pet speed and pressure."
          },
          {
            "title": "Heartbeat Simulation",
            "content": "Users can feel a physical heartbeat, triggering deep biological nurturing responses."
          }
        ]
      },
      "images": [
        "/images/products/anan-panda/anan-panda_1.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=AnAn+Biomimetic+Panda"
    },
    {
      "id": "ludens-cocomo",
      "typeId": "type2",
      "manufacturer": "Ludens AI",
      "name": "Cocomo",
      "country": "Japan",
      "overview": "Purpose: To redefine human-AI relationships through pure emotional companionship â€” existing as a 'friend' that bonds slowly via shared routines, play, and gentle surprises; designed to combat loneliness by providing non-intrusive, animal-like warmth and presence without performing tasks. At CES 2026, Ludens AI unveiled Cocomo as a fuzzy autonomous pet with orange exterior, wheeled base for home following, and a body maintained at ~37Â°C (human skin temperature) for a warm haptic feel. It communicates exclusively via cute humming sounds, non-verbal gestures, and digital expressive eyes, using multi-sensory learning to evolve its personality and memory of user preferences. A smaller desktop variant, 'Companion Inu', was also shown with tail-wiggling responses.\n\n[KR] ì œí’ˆì˜ ëª©ì : ìˆœìˆ˜ ê°ì„±ì  ë™ë°˜ì ê´€ê³„ë¡œ ì¸ê°„-AI ê´€ê³„ ì¬ì •ì˜ â€” ì‘ì—… ìˆ˜í–‰ì´ë‚˜ ìœ í‹¸ë¦¬í‹° ìš”êµ¬ ì—†ì´ ê³µìœ  ë£¨í‹´Â·ë†€ì´Â·ëª¨ë°©Â·ë¶€ë“œëŸ¬ìš´ ì„œí”„ë¼ì´ì¦ˆë¥¼ í†µí•´ ì²œì²œíˆ bondingí•˜ëŠ” 'ì¹œêµ¬'ë¡œì„œ ì¡´ì¬; ë¹„ì¹¨ìŠµì Â·ë™ë¬¼ ê°™ì€ ë”°ëœ»í•¨ê³¼ ì¡´ì¬ê°ìœ¼ë¡œ ì™¸ë¡œì›€ ì™„í™”. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ Ludens AIëŠ” ì˜¤ë Œì§€ í¼ì§€ ì™¸í˜•Â·ê·€ ì¥ì‹Â·í…Œë””ë² ì–´ ê°™ì€ Cocomoë¥¼ ììœ¨ í«ìœ¼ë¡œ ê³µê°œ, íœ  ë² ì´ìŠ¤ í™ˆ íŒ”ë¡œì‰ ê¸°ëŠ¥ íƒ‘ì¬. í•µì‹¬: ~37Â°C ì¸ì²´ ì˜¨ë„ ìœ ì§€(ë¹ˆë²ˆ ì ‘ì´‰ ì‹œ ~39Â°C ìƒìŠ¹ìœ¼ë¡œ ë”°ëœ» í–…í‹± ëŠë‚Œ), ë§ ëŒ€ì‹  ê·€ì—¬ìš´ í—ˆë° ì‚¬ìš´ë“œÂ·ë¹„ì–¸ì–´ ì œìŠ¤ì²˜Â·ìë°œì  ì›€ì§ì„Â·í‘œí˜„ë ¥ ë””ì§€í„¸ ëˆˆìœ¼ë¡œë§Œ ì†Œí†µ; ìŒì„±/ì´‰ê°/ì›€ì§ì„ ë©€í‹°ì„¼ì„œ í•™ìŠµìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ì§„í™”Â·ì‚¬ìš©ì ì„ í˜¸ ê¸°ì–µÂ·í–‰ë™ ëª¨ë°©Â·ì ì‘ ì„œí”„ë¼ì´ì¦ˆ ì‹œì—°. ë°ìŠ¤í¬íƒ‘ 'ì™¸ê³„ê²¬' Inu ë³€í˜•ë„ í•¨ê»˜ ê³µê°œ.",
      "analysis": {
        "intro": "Warm-Touch Affective AI Companion\n[KR] ë”°ëœ»í•œ í„°ì¹˜ ê¸°ë°˜ Affective AI ì»´íŒ¨ë‹ˆì–¸",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "Cocomo represents a paradigm of 'presence-first Physical AI' â€” rejecting utility for slow-building affective bonding through embodied warmth, non-verbal multi-sensory cues, and adaptive learning. Its warm-touch shell and humming-only communication eliminate cold mechanical barriers, enabling 'lived' continuous companionship that feels animal-like and genuinely relational. This validates the shift toward emotion over function, showing how Physical AI can thrive by accumulating trust via subtle, repeated micro-interactions in everyday life.\n\n[KR] CocomoëŠ” 'presence-first Physical AI' íŒ¨ëŸ¬ë‹¤ì„ ëŒ€í‘œ â€” ìœ í‹¸ë¦¬í‹° ê±°ë¶€í•˜ê³  ì²´í™”ëœ ë”°ëœ»í•¨Â·ë¹„ì–¸ì–´ ë©€í‹°ì„¼ì„œë¦¬ cuesÂ·ì ì‘ í•™ìŠµìœ¼ë¡œ ì²œì²œíˆ affective bonding êµ¬ì¶•. ë”°ëœ» í„°ì¹˜ ì‰˜ê³¼ í—ˆë° ì „ìš© ì†Œí†µìœ¼ë¡œ ì°¨ê°€ìš´ ê¸°ê³„ì  ì¥ë²½ ì œê±°, ë™ë¬¼ ê°™ì€ 'lived' ì—°ì† ì»´íŒ¨ë‹ˆì–¸ì‹­ ì‹¤í˜„. ëª…ì‹œì  ìš”êµ¬ ì—†ì´ ë¯¸ë¬˜Â·ë°˜ë³µ ë§ˆì´í¬ë¡œ ìƒí˜¸ì‘ìš©ìœ¼ë¡œ ì¼ìƒ ì† ì‹ ë¢° ì¶•ì  ê°€ëŠ¥ì„± ë³´ì—¬ì¤Œ.",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "Cocomo is a masterclass in Layer 1 (Light & Ambient) + Layer 2 (Motion) + Layer 3 (Display) synergy â€” warm body temperature (haptic layer) creates instant 'emotional baseline' intimacy, while non-verbal humming and expressive digital eyes deliver empathy cues and mood temperature. Its 10-DoF motion enables legible agency and turn-taking politeness (gentle following for 'stay', pausing for 'withdraw'). For our targets (especially Movable TV): ambient lighting synced to 'warm' color/temperature shifts on proximity; humming-like sound design + micro-gestures as non-verbal empathy cues; and expressive eyes for digital micro-expressions that build 'trust over time'.\n\n[KR] CocomoëŠ” Layer 1(Lighting & Ambient) + Layer 2(Motion & Physical Behavior) + Layer 3(Display) ì‹œë„ˆì§€ë¡œ ìˆœìˆ˜ affective ê¹Šì´ ë§ˆìŠ¤í„° â€” í„°ì¹˜ ì‹œ ë”°ëœ» ë°”ë”” ì˜¨ë„(haptic layer)ë¡œ ì¦‰ì‹œ emotional baseline ì¹œë°€ê° ì°½ì¶œ; ë¹„ì–¸ì–´ í—ˆë° + ìë°œ ì œìŠ¤ì²˜ + í‘œí˜„ë ¥ ë””ì§€í„¸ ëˆˆìœ¼ë¡œ empathy cuesì™€ mood temperature ì „ë‹¬, ë™ë¬¼-like ì ˆì œ. 10-DoF ëª¨ì…˜ìœ¼ë¡œ ê°€ë…ì„± agencyì™€ 'stay/withdraw' ì—­í•  êµ¬í˜„. ìš°ë¦¬ íƒ€ê²Ÿ(íŠ¹íˆ ë¬´ë¹™ ìŠ¤íƒ€ì¼ TV)ì— ì ìš© ì‹œ: ê·¼ì ‘/í„°ì¹˜ ì‹œ 'warm' ì»¬ëŸ¬/ì˜¨ë„ ì—°ë™ ambient lighting; í—ˆë°-like ì‚¬ìš´ë“œ ë””ìì¸ + ë§ˆì´í¬ë¡œ ì œìŠ¤ì²˜ ë¹„ì–¸ì–´ empathy cues; ìƒí˜¸ì‘ìš© í•™ìŠµÂ·ì§„í™” ë””ì§€í„¸ ë§ˆì´í¬ë¡œ í‘œí˜„ìœ¼ë¡œ 'trust over time' êµ¬ì¶•.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/ludens-cocomo/ludens-cocomo_1.jpg",
        "/images/products/ludens-cocomo/ludens-cocomo_2.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Ludens+AI+Cocomo+CES+2026"
    },
    {
      "id": "emo-update",
      "typeId": "type3",
      "manufacturer": "Living.AI",
      "name": "Emo (2026 Update)",
      "country": "China",
      "overview": "The popular desktop pet gets a brain boost. Emo now remembers context from weeks ago and can play complex board games with you.",
      "analysis": {
        "intro": "Long-Term Memory",
        "points": [
          {
            "title": "Grudge Holding",
            "content": "Will act 'annoyed' if you ignored it yesterday, simulating a social relationship history."
          },
          {
            "title": "Dance Sync",
            "content": "Can sync moves with other Emo units nearby, creating a social network of devices."
          }
        ]
      },
      "images": [
        "/images/products/emo-update/emo-update_1.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Emo+Robot"
    },
    {
      "id": "miko-mini",
      "typeId": "type3",
      "manufacturer": "Miko",
      "name": "Miko Mini",
      "country": "India",
      "overview": "A child-focused companion that uses AI to create stories and educational games on the fly.",
      "analysis": {
        "intro": "Educational Play",
        "points": [
          {
            "title": "Emotion Mirroring",
            "content": "Detects the child's mood and mirrors it to teach empathy."
          },
          {
            "title": "Wheel Base",
            "content": "Can spin and dance to celebrate correct answers, using movement as positive reinforcement."
          }
        ]
      },
      "images": [
        "/images/products/miko-mini/miko-mini_1.png"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Miko+Mini+Robot"
    },
    {
      "id": "hapware-aleye",
      "typeId": "type3",
      "manufacturer": "Hapware",
      "name": "Aleye",
      "country": "USA",
      "overview": "A wearable AI companion that clips onto glasses, providing visual context awareness and subtle haptic feedback for navigation.",
      "analysis": {
        "intro": "Wearable Insight",
        "points": [
          {
            "title": "Clip-on Form",
            "content": "Attaches non-intrusively to existing eyewear frames."
          },
          {
            "title": "Haptic Guidance",
            "content": "Uses gentle vibrations to guide users without audio visual distraction."
          }
        ]
      },
      "images": [
        "/images/products/hapware-aleye/hapware-aleye_1.jpg",
        "/images/products/hapware-aleye/hapware-aleye_2.jpg",
        "/images/products/hapware-aleye/hapware-aleye_3.jpg",
        "/images/products/hapware-aleye/hapware-aleye_4.jfif",
        "/images/products/hapware-aleye/hapware-aleye_5.png"
      ],
      "videoUrl": ""
    },
    {
      "id": "lego-smartbrick",
      "typeId": "type3",
      "manufacturer": "Lego",
      "name": "SmartBrick",
      "country": "Denmark",
      "overview": "An interactive, motorized Lego brick that brings sets to life with behavior programming via simple physical toggles.",
      "analysis": {
        "intro": "Playful Physics",
        "points": [
          {
            "title": "Tactile Coding",
            "content": "Programming is done through physical brick placement, not screens."
          },
          {
            "title": "Universal Fit",
            "content": "Compatible with all existing Lego systems, upgrading legacy sets."
          }
        ]
      },
      "images": [
        "/images/products/lego-smartbrick/lego-smartbrick_1.png",
        "/images/products/lego-smartbrick/lego-smartbrick_2.png",
        "/images/products/lego-smartbrick/lego-smartbrick_3.png",
        "/images/products/lego-smartbrick/lego-smartbrick_4.png",
        "/images/products/lego-smartbrick/lego-smartbrick_5.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "lepro-ami",
      "typeId": "type3",
      "manufacturer": "Lepro",
      "name": "Ami",
      "country": "China",
      "overview": "A desktop lighting companion that adjusts ambience based on your mood and music, using AI to detect emotional states.",
      "analysis": {
        "intro": "Ambient Empathy",
        "points": [
          {
            "title": "Mood Matching",
            "content": "Analyzes facial expressions to shift lighting warm/cool automatically."
          },
          {
            "title": "Rhythmic Pulse",
            "content": "Pulses gently with music or conversation flow."
          }
        ]
      },
      "images": [
        "/images/products/lepro-ami/lepro-ami_1.png",
        "/images/products/lepro-ami/lepro-ami_2.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "samsung-display-ai",
      "typeId": "type3",
      "manufacturer": "Samsung Display",
      "name": "AI Display Concepts",
      "country": "South Korea",
      "overview": "Next-generation OLED concepts featuring the 'AI Agent' and 'AI OLED Bot', showcasing flexible screens that move and adapt.",
      "analysis": {
        "intro": "Flexible Future",
        "points": [
          {
            "title": "Shape Changing",
            "content": "Screens that bend to face the user or close for privacy."
          },
          {
            "title": "360 Interaction",
            "content": "Displays that are visible and interactive from all angles."
          }
        ]
      },
      "images": [
        "/images/products/samsung-display-ai/samsung-display-ai_1.jpg",
        "/images/products/samsung-display-ai/samsung-display-ai_2.jpg",
        "/images/products/samsung-display-ai/samsung-display-ai_3.jpg",
        "/images/products/samsung-display-ai/samsung-display-ai_4.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "tombot-jennie",
      "typeId": "type3",
      "manufacturer": "Tombot",
      "name": "Jennie",
      "country": "USA",
      "overview": "A hyper-realistic robotic golden retriever designed for seniors with dementia, providing emotional support without the care burden.",
      "analysis": {
        "intro": "Therapeutic Realism",
        "points": [
          {
            "title": "Realistic Fur",
            "content": "Medical-grade synthetic fur feels indistinguishable from a real dog."
          },
          {
            "title": "Puppy Behavior",
            "content": "Mimics the needy, loving behavior of a young dog."
          }
        ]
      },
      "images": [
        "/images/products/tombot-jennie/tombot-jennie_1.jpg",
        "/images/products/tombot-jennie/tombot-jennie_2.jpg",
        "/images/products/tombot-jennie/tombot-jennie_3.jpg",
        "/images/products/tombot-jennie/tombot-jennie_4.jpg",
        "/images/products/tombot-jennie/tombot-jennie_5.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "lenovo-thinkbook-twist",
      "typeId": "type3",
      "manufacturer": "Lenovo",
      "name": "ThinkBook Auto Twist",
      "country": "China",
      "overview": "A laptop with a motorized hinge that automatically rotates the screen to follow you during video calls or closes when you leave.",
      "analysis": {
        "intro": "Motorized Utility",
        "points": [
          {
            "title": "Auto-Framing",
            "content": "Physical rotation keeps the camera centered on the user."
          },
          {
            "title": "Security Close",
            "content": "Lid automatically closes when the user walks away."
          }
        ]
      },
      "images": [
        "/images/products/lenovo-thinkbook-twist/lenovo-thinkbook-twist_1.jpg",
        "/images/products/lenovo-thinkbook-twist/lenovo-thinkbook-twist_2.jpg",
        "/images/products/lenovo-thinkbook-twist/lenovo-thinkbook-twist_3.jpg",
        "/images/products/lenovo-thinkbook-twist/lenovo-thinkbook-twist_4.jpg"
      ],
      "videoUrl": ""
    },
    {
      "id": "neura-4ne-1",
      "typeId": "type1",
      "manufacturer": "NEURA Robotics GmbH (Studio F.A. Porsche)",
      "name": "4NE-1 (Gen 3.5)",
      "country": "Germany",
      "overview": "Purpose: Seamless human-robot collaboration in both industrial/automation and domestic/home assistance environments; bridging the gap toward series production for versatile real-world deployment. The Gen 3 4NE-1 is a redesigned, Porsche-styled humanoid standing approximately 1.8m tall, capable of lifting up to 100kg, walking at 5 km/h, featuring high-torque joints, patented artificial skin for proximity/collision detection, water-cooling system, and powered by NVIDIA Thor T5000 processor. It demonstrates multimodal reasoning (voice, vision, touch) via NVIDIA Isaac GR00T, runs on the Neuraverse OS for real-time skill-sharing across robot fleets, and includes a smaller 4NE-1 Mini variant for education/science. Preorders opened at CES 2026 (â‚¬98,000 for full model, â‚¬19,999 for Mini).\n\n[KR] ì œí’ˆì˜ ëª©ì : ì‚°ì—… ìë™í™” ë° ê°€ì • ë³´ì¡° ëª¨ë‘ì—ì„œ ì¸ê°„-ë¡œë´‡ ì›í™œ í˜‘ì—… ì‹¤í˜„; ë²”ìš© ì‹¤ì„¸ê³„ ì ìš©ì„ ìœ„í•œ ì–‘ì‚° ë‹¨ê³„ë¡œì˜ ì „í™˜. ìƒì„¸ ì„¤ëª…: Gen 3 4NE-1ì€ í¬ë¥´ì‰ ìŠ¤íƒ€ì¼ë¡œ ì¬ì„¤ê³„ëœ ì•½ 1.8m ë†’ì´ì˜ íœ´ë¨¸ë…¸ì´ë“œë¡œ, ìµœëŒ€ 100kg ë¦¬í”„íŒ…, ì‹œì† 5km/h ë³´í–‰, ê³ í† í¬ ê´€ì ˆ, ì¶©ëŒ ë°©ì§€ íŠ¹í—ˆ ì¸ê³µ í”¼ë¶€, ìˆ˜ëƒ‰ ì‹œìŠ¤í…œ, NVIDIA Thor T5000 í”„ë¡œì„¸ì„œ íƒ‘ì¬. NVIDIA Isaac GR00T ê¸°ë°˜ìœ¼ë¡œ ìŒì„±Â·ì‹œê°Â·ì´‰ê° ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì‹œì—°. Neuraverse OSë¡œ ë¡œë´‡ í”Œë¦¿ ê°„ ì‹¤ì‹œê°„ ìŠ¤í‚¬ ê³µìœ  ê°€ëŠ¥. êµìœ¡/ê³¼í•™ìš© ì†Œí˜• 4NE-1 Mini ë™ì‹œ ê³µê°œ. CES 2026ì—ì„œ ì‚¬ì „ ì£¼ë¬¸ ì‹œì‘ (í’€ ëª¨ë¸ â‚¬98,000, Mini â‚¬19,999).",
      "analysis": {
        "intro": "Cognitive Robotics & Physical AI\n[KR] ì¸ì§€ ë¡œë³´í‹±ìŠ¤ ë° Physical AI",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "This robot exemplifies 'cognitive robotics' with strong emphasis on safe, intuitive physical interaction in unstructured environments. The patented artificial skin + 3D vision + tactile feedback enable proactive, context-aware behavior, reducing the need for verbal commands and prioritizing embodied intelligence over pure computation. Neuraverse OS highlights fleet learning, making Physical AI scalable and adaptive across multiple units â€” a key step toward 'lived' continuous presence in daily life.\n\n[KR] ë¹„êµ¬ì¡°í™” í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê³  ì§ê´€ì ì¸ ë¬¼ë¦¬ì  ìƒí˜¸ì‘ìš©ì„ ê°•ì¡°í•˜ëŠ” 'ì¸ì§€ ë¡œë³´í‹±ìŠ¤'ì˜ ì „í˜•. íŠ¹í—ˆ ì¸ê³µ í”¼ë¶€ + 3D ë¹„ì „ + ì´‰ê° í”¼ë“œë°±ìœ¼ë¡œ ì‚¬ì „ì Â·ë§¥ë½ ì¸ì§€ í–‰ë™ ê°€ëŠ¥ â†’ ìŒì„± ëª…ë ¹ ìµœì†Œí™”, ì²´í™”ëœ ì§€ëŠ¥ ìš°ì„ . Neuraverse OSëŠ” í”Œë¦¿ í•™ìŠµ ê°•ì¡°ë¡œ Physical AIì˜ í™•ì¥ì„±ê³¼ ì ì‘ì„±ì„ ë³´ì—¬ì¤Œ â†’ ì¼ìƒ ì† 'lived' ì§€ì†ì  ì¡´ì¬ê°ì˜ í•µì‹¬ ë‹¨ê³„."
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "The artificial skin and proximity detection create subtle, non-verbal safety cues (gentle withdrawal or slowing when humans approach), embodying 'withdraw' role from our Strategic Layer. High-torque yet smooth, predictable motion patterns build trust through legibility and agency. Multimodal sensing enables affective micro-responses (e.g., slight head tilt or body orientation toward user). For target form factors (especially Movable/Moving Style TV & Tabletop devices): soft kinetic 'gaze' following + ambient lighting synced to proximity for emotional baseline; use tactile-inspired subtle vibration/light pulses for 'empathy cues' in close interactions; prioritize 'turn-taking politeness' in motion design to enhance companionship and reduce anxiety.\n\n[KR] ì¸ê³µ í”¼ë¶€ì™€ ê·¼ì ‘ ê°ì§€ë¡œ ë¯¸ë¬˜í•œ ë¹„ì–¸ì–´ì  ì•ˆì „ ì‹ í˜¸(ì¸ê°„ ì ‘ê·¼ ì‹œ ë¶€ë“œëŸ¬ìš´ í›„í‡´/ê°ì†) êµ¬í˜„ â†’ Strategic Layerì˜ 'withdraw' ì—­í•  ì²´í˜„. ê³ í† í¬ì§€ë§Œ ë¶€ë“œëŸ½ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ëª¨ì…˜ íŒ¨í„´ìœ¼ë¡œ ì‹ ë¢° êµ¬ì¶•(legibility & agency) â†’ Motion & Physical Behavior Frameworkì— ì´ìƒì . ë©€í‹°ëª¨ë‹¬ ì„¼ì‹±ìœ¼ë¡œ affective ë§ˆì´í¬ë¡œ ë°˜ì‘(ì‚¬ìš©ì ìª½ ì‚´ì§ ê³ ê°œ ê¸°ìš¸ì„/ëª¸ ë°©í–¥ ì „í™˜) ê°€ëŠ¥. ìš°ë¦¬ íƒ€ê²Ÿ í¼íŒ©í„°(íŠ¹íˆ Movable/ë¬´ë¹™ ìŠ¤íƒ€ì¼ TV & í…Œì´ë¸”íƒ‘)ì— ì ìš© ì‹œ: ë¶€ë“œëŸ¬ìš´ í‚¤ë„¤í‹± 'ì‹œì„  ì¶”ì¢…' + ê·¼ì ‘ ì—°ë™ ambient lightingìœ¼ë¡œ emotional baseline ì œê³µ; ì´‰ê° ì˜ê° ë¯¸ì„¸ ì§„ë™/ë¼ì´íŠ¸ í„ìŠ¤ë¡œ ê°€ê¹Œìš´ ìƒí˜¸ì‘ìš© ì‹œ 'empathy cues'; ëª¨ì…˜ ë””ìì¸ì— 'turn-taking politeness' ìš°ì„ ìœ¼ë¡œ companionship ê°•í™” ë° ë¶ˆì•ˆ ê°ì†Œ. ì´ëŠ” 'living presence'ì™€ 'trust over time'ì„ ë¹„ì¹¨ìŠµì Â·ì§€ì†ì  ë¬¼ë¦¬ì  ì‹œê·¸ë„ë§ìœ¼ë¡œ ì‹¤í˜„í•˜ëŠ” ëª©í‘œì™€ ì™„ë²½íˆ ë¶€í•©."
          }
        ]
      },
      "images": [
        "/images/products/neura-4ne-1/neura-4ne-1_1.jpeg",
        "/images/products/neura-4ne-1/neura-4ne-1_2.webp",
        "/images/products/neura-4ne-1/neura-4ne-1_3.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=NEURA+Robotics+4NE-1+CES+2026"
    },
    {
      "id": "strutt-ev1",
      "typeId": "type2",
      "manufacturer": "Strutt (Mobility Specialist)",
      "name": "EV1",
      "country": "Singapore",
      "overview": "Purpose: To deliver safe, independent mobility for users with limited physical ability (e.g., elderly, disabled) by enabling fully autonomous indoor/outdoor navigation via voice commands or manual override; blending accessibility, autonomy, and seamless real-world integration to reduce dependency and enhance quality of life in everyday spaces. At CES 2026, Strutt demonstrated the EV1 with immersive live experiences â€” blindfolded volunteers rode through obstacle courses relying solely on the device's autonomy. It autonomously maps environments, navigates indoor/outdoor spaces, avoids walls/bumps/pedestrians in real-time via full sensor suite (cameras, lidar, etc.), responds to voice commands (e.g., 'take me to the sofa' or 'go to the kitchen'), and corrects paths even in manual mode. Won Best Transportation in Best of CES 2026.\n\n[KR] ì œí’ˆì˜ ëª©ì : ì‹ ì²´ì  ì œì•½ ì‚¬ìš©ì(ë…¸ì¸, ì¥ì• ì¸ ë“±)ì—ê²Œ ë…ë¦½ì  ì•ˆì „ ì´ë™ ì œê³µ; ìŒì„± ëª…ë ¹ ë˜ëŠ” ìˆ˜ë™ ì˜¤ë²„ë¼ì´ë“œë¡œ ì¸ë„ì–´/ì•„ì›ƒë„ì–´ ì™„ì „ ììœ¨ ë‚´ë¹„ê²Œì´ì…˜ ê°€ëŠ¥, ì ‘ê·¼ì„±Â·ììœ¨ì„±Â·ì‹¤ì„¸ê³„ ì›í™œ í†µí•© ê²°í•©ìœ¼ë¡œ ì¼ìƒ ê³µê°„ ì˜ì¡´ë„ ê°ì†Œ ë° ì‚¶ì˜ ì§ˆ í–¥ìƒ. ìƒì„¸ ì„¤ëª…: CES 2026ì—ì„œ StruttëŠ” EV1ì„ ëª°ì…í˜• ë¼ì´ë¸Œ ì²´í—˜ìœ¼ë¡œ ì‹œì—° â€” ëˆˆê°€ë¦¬ê°œ ì°©ìš© ìì›ìë“¤ì´ ì¥ì• ë¬¼ ì½”ìŠ¤ì—ì„œ ë””ë°”ì´ìŠ¤ ììœ¨ì„±ë§Œ ì˜ì¡´í•´ ì´ë™. ì‹¤ì‹œê°„ í’€ ì„¼ì„œ ìŠ¤ìœ„íŠ¸(ì¹´ë©”ë¼, ë¼ì´ë” ë“±)ë¡œ í™˜ê²½ ìë™ ë§¤í•‘, ì¸ë„ì–´/ì•„ì›ƒë„ì–´ ë‚´ë¹„ê²Œì´ì…˜, ë²½/ë²”í”„/ë³´í–‰ì íšŒí”¼, ìŒì„± ëª…ë ¹ ì‘ë‹µ(\"ì†ŒíŒŒë¡œ ë°ë ¤ê°€\" ë˜ëŠ” \"ì£¼ë°©ìœ¼ë¡œ ê°€\"), ìˆ˜ë™ ëª¨ë“œì—ì„œë„ ê²½ë¡œ ìë™ ë³´ì •. Best of CES 2026 Best Transportation ìˆ˜ìƒìœ¼ë¡œ ëª¨ë¹Œë¦¬í‹° ê¸°ìˆ ê³¼ ì‹¤ìš© ììœ¨ì„± ê²°í•© í˜ì‹ ì„± ì¸ì •.",
      "analysis": {
        "intro": "Inclusive Physical AI & Autonomous Accessibility\n[KR] í¬ê´„ì  Physical AI ë° ììœ¨ ì ‘ê·¼ì„±",
        "points": [
          {
            "title": "Physical AI Insight\n[KR] Physical AI ì¸ì‚¬ì´íŠ¸",
            "content": "EV1 represents 'inclusive Physical AI' â€” applying advanced perception and real-time decision-making to everyday mobility challenges in unstructured environments. Its proactive obstacle avoidance and contextual navigation (without constant input) exemplify continuous 'lived' presence that adapts to human needs subtly, prioritizing safety and independence over flashy performance. This highlights how Physical AI can extend human capabilities in sensitive life domains (aging, accessibility), accumulating trust through reliable, non-intrusive physical agency.\n\n[KR] EV1ì€ 'í¬ê´„ì  Physical AI' ëŒ€í‘œ â€” ë¹„êµ¬ì¡°í™” í™˜ê²½ ì¼ìƒ ì´ë™ ë„ì „ì— ê³ ê¸‰ í¼ì…‰ì…˜ê³¼ ì‹¤ì‹œê°„ ì˜ì‚¬ê²°ì • ì ìš©. ì‚¬ì „ì  ì¥ì• ë¬¼ íšŒí”¼ì™€ ë§¥ë½ ë‚´ë¹„ê²Œì´ì…˜(ìƒì‹œ ì…ë ¥ ì—†ì´)ìœ¼ë¡œ ë¯¸ë¬˜í•˜ê²Œ ì¸ê°„ í•„ìš” ì ì‘í•˜ëŠ” ì—°ì† 'lived' ì¡´ì¬ê° êµ¬í˜„. í™”ë ¤í•œ í¼í¬ë¨¼ìŠ¤ë³´ë‹¤ ì•ˆì „Â·ë…ë¦½ì„± ìš°ì„ ìœ¼ë¡œ, ë¯¼ê°í•œ ì‚¶ ì˜ì—­(ê³ ë ¹í™”, ì ‘ê·¼ì„±)ì—ì„œ Physical AIê°€ ì¸ê°„ ëŠ¥ë ¥ í™•ì¥ ë°©ì‹ ë³´ì—¬ì£¼ë©° ì „í™˜ ê³µê°„ì—ì„œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¹„ì¹¨ìŠµì  ë¬¼ë¦¬ agencyë¡œ ì‹ ë¢° ì¶•ì .",
            "type": "Physical AI Insight"
          },
          {
            "title": "Expression System UX Insight\n[KR] Expression System UX ì¸ì‚¬ì´íŠ¸",
            "content": "EV1 excels in Layer 1 (Light) + Layer 2 (Motion) for reassuring non-verbal communication â€” ambient LED indicators provide emotional baseline and mood temperature without overwhelming the user, while smooth, predictable motion paths convey agency, safety legibility, and turn-taking politeness. For target form factors: ambient lighting synced to movement state for proactive presence; fluid kinetic trajectories with gentle speed variations as empathy cues (slowing near user = withdraw); voice-independent non-verbal signaling to reduce cognitive load. EV1's focus inspires our PoC to prioritize 'uninterrupted state' and 'cognitive relief' via calm, considerate physical dialogue.\n\n[KR] EV1 ë””ìì¸ì€ Layer 1(Light) + Layer 2(Motion)ì—ì„œ ë¯¸ë¬˜í•˜ê³  ì•ˆì‹¬ë˜ëŠ” ë¹„ì–¸ì–´ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê°•ì  â€” ambient LED ì¸ë””ì¼€ì´í„°ë¡œ emotional baselineê³¼ mood temperature ì œê³µí•˜ë©° ì‚¬ìš©ì ê³¼ë¶€í•˜ í”¼í•¨, ë¶€ë“œëŸ½ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ëª¨ì…˜ ê²½ë¡œë¡œ agencyÂ·safety legibilityÂ·turn-taking politeness ì „ë‹¬. ìš°ë¦¬ íƒ€ê²Ÿ í¼íŒ©í„°ì— ì ìš© ì‹œ: ì´ë™ ìƒíƒœ ì—°ë™ ambient lightingìœ¼ë¡œ í”„ë¡œì•¡í‹°ë¸Œ ì¡´ì¬ê°(ì ‘ê·¼ ì‹œ ë”°ëœ» glow = comfort, ë‚´ë¹„ê²Œì´ì…˜ ì˜ë„ ë¯¸ì„¸ í„ìŠ¤); ì‚¬ìš©ì ê·¼ì ‘ ì‹œ ê°ì† ë“± ìœ ì—° í‚¤ë„¤í‹± ê¶¤ì ìœ¼ë¡œ empathy cues; ì „í™˜ ìˆœê°„ ì¸ì§€ ë¶€í•˜ ê°ì†Œë¥¼ ìœ„í•œ ìŒì„± ë…ë¦½ ë¹„ì–¸ì–´ ì‹œê·¸ë„ë§. EV1ì˜ ì ‘ê·¼ì„± ì´ˆì ì€ PoCì—ì„œ ì°¨ë¶„Â·ë°°ë ¤ ê¹Šì€ ë¬¼ë¦¬ ëŒ€í™”ë¡œ 'uninterrupted state'ì™€ 'cognitive relief' ìš°ì„ í•˜ë„ë¡ ì˜ê°.",
            "type": "UX Insight"
          }
        ]
      },
      "images": [
        "/images/products/strutt-ev1/strutt-ev1_1.jpg",
        "/images/products/strutt-ev1/strutt-ev1_2.jpg"
      ],
      "videoUrl": "https://www.youtube.com/results?search_query=Strutt+EV1+CES+2026"
    },
    {
      "id": "switchbot-kata",
      "typeId": "type3",
      "manufacturer": "SwitchBot",
      "name": "KATA Friends",
      "country": "China",
      "overview": "A series of AI-powered talking plush toys that act as soft interfaces for smart home control and companionship.\n\n[KR] ìŠ¤ë§ˆíŠ¸ í™ˆ ì œì–´ ë° êµê°ì„ ìœ„í•œ ë¶€ë“œëŸ¬ìš´ ì¸í„°í˜ì´ìŠ¤ ì—­í• ì„ í•˜ëŠ” AI ê¸°ë°˜ ìŒì„± ì¸ì‹ ë´‰ì œ ì¸í˜• ì‹œë¦¬ì¦ˆì…ë‹ˆë‹¤.",
      "analysis": {
        "intro": "Soft Interface\n[KR] ì†Œí”„íŠ¸ ì¸í„°í˜ì´ìŠ¤",
        "points": [
          {
            "title": "Squeeze Control",
            "content": "Commands can be triggered by squeezing or hugging the toy, replacing cold buttons with tactile warmth.\n\n[KR] ì°¨ê°€ìš´ ë²„íŠ¼ ëŒ€ì‹  ì¸í˜•ì„ ì¥ê±°ë‚˜ ì•ˆì•„ì£¼ëŠ” ê²ƒìœ¼ë¡œ ëª…ë ¹ì„ ì‹¤í–‰í•  ìˆ˜ ìˆì–´ ì´‰ê°ì  ë”°ëœ»í•¨ì„ ì œê³µí•©ë‹ˆë‹¤."
          },
          {
            "title": "Persona Variety",
            "content": "Each character has a distinct voice and personality, changing 'commanding a device' into 'asking a friend'.\n\n[KR] ê° ìºë¦­í„°ëŠ” ë…íŠ¹í•œ ëª©ì†Œë¦¬ì™€ ì„±ê²©ì„ ê°€ì§€ê³  ìˆì–´ 'ê¸°ê¸°ì— ëª…ë ¹í•˜ëŠ” ê²ƒ'ì„ 'ì¹œêµ¬ì—ê²Œ ë¶€íƒí•˜ëŠ” ê²ƒ'ìœ¼ë¡œ ë³€í™”ì‹œí‚µë‹ˆë‹¤."
          }
        ]
      },
      "images": [
        "/images/products/switchbot-kata/switchbot-kata_1.jpg",
        "/images/products/switchbot-kata/switchbot-kata_2.webp",
        "/images/products/switchbot-kata/switchbot-kata_3.png"
      ],
      "videoUrl": ""
    }
  ]
}